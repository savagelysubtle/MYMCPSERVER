Directory structure:
└── savagelysubtle-mymcpserver/
    ├── README.md
    ├── INTEGRATION.md
    ├── pyproject.toml
    ├── requirements.txt
    ├── uv.lock
    ├── .env.local
    ├── .python-version
    ├── docs-obsidian/
    ├── src/
    │   ├── run_server.py
    │   ├── archive/
    │   │   ├── mymcpserver/
    │   │   │   ├── __init__.py
    │   │   │   ├── __main__.py
    │   │   │   ├── config.py
    │   │   │   ├── logging_config.py
    │   │   │   └── server.py
    │   │   └── mymcpserver_old/
    │   │       ├── __init__.py
    │   │       ├── __main__.py
    │   │       ├── logging_config.py
    │   │       └── server.py
    │   ├── mcp_core/
    │   │   ├── __init__.py
    │   │   ├── app.py
    │   │   ├── errors.py
    │   │   ├── health.py
    │   │   ├── registry.py
    │   │   ├── router.py
    │   │   ├── routes.py
    │   │   ├── adapters/
    │   │   │   ├── __init__.py
    │   │   │   ├── base_adapter.py
    │   │   │   ├── circuit_breaker.py
    │   │   │   ├── python_adapter.py
    │   │   │   ├── python_tool_adapter.py
    │   │   │   ├── ts_adapter.py
    │   │   │   ├── version.py
    │   │   │   └── testing/
    │   │   │       ├── __init__.py
    │   │   │       └── python_tool.py
    │   │   ├── config/
    │   │   │   ├── __init__.py
    │   │   │   └── config.py
    │   │   ├── logger/
    │   │   │   ├── __init__.py
    │   │   │   ├── config.py
    │   │   │   └── logger.py
    │   │   ├── metrics/
    │   │   │   ├── __init__.py
    │   │   │   ├── collectors.py
    │   │   │   └── exporters.py
    │   │   ├── models/
    │   │   │   ├── __init__.py
    │   │   │   ├── request.py
    │   │   │   └── response.py
    │   │   └── validation/
    │   │       ├── __init__.py
    │   │       ├── schemas.py
    │   │       └── validators.py
    │   ├── mcp_proxy/
    │   │   ├── __init__.py
    │   │   ├── __main__.py
    │   │   ├── errors.py
    │   │   ├── health.py
    │   │   ├── proxy_server.py
    │   │   ├── router.py
    │   │   ├── config/
    │   │   │   └── config.py
    │   │   └── transports/
    │   │       ├── __init__.py
    │   │       ├── base_transport.py
    │   │       ├── sse.py
    │   │       ├── stdio.py
    │   │       └── websocket.py
    │   ├── mymcpserver/
    │   │   ├── __init__.py
    │   │   └── server.py
    │   └── tool_servers/
    │       ├── python/
    │       │   └── server.py
    │       ├── python_tool_server/
    │       │   ├── __init__.py
    │       │   ├── health.py
    │       │   ├── requirements.txt
    │       │   ├── server.py
    │       │   ├── n1/
    │       │   │   ├── models.py
    │       │   │   └── tool.py
    │       │   └── n2/
    │       │       └── tool.py
    │       └── typescript_tool_server/
    │           ├── package.json
    │           ├── tsconfig.json
    │           └── src/
    │               ├── health.ts
    │               ├── index.ts
    │               └── logger.ts
    ├── template/
    │   └── mcp.json
    ├── tests/
    │   └── test_server.py
    └── .cursor/
        ├── mcp.json
        └── rules/
            ├── 0000-global-knowledge-management.mdc
            ├── 0010-Plan-ACT.mdc
            ├── 0020-windows-powershell.mdc
            ├── 0100-mcp-server-layout.mdc
            ├── 0150-Read-module-docs.mdc
            ├── 0200-project-locations.mdc
            ├── 1001-python-imports.mdc
            ├── 1002-python-style-guide.mdc
            ├── 1002-python-type-hinting.mdc
            ├── 4000-docs-obsidian-organization.mdc
            ├── 4100-obsidian-note-structure.mdc
            ├── 4200-obsidian-linking.mdc
            ├── 801-python-environment.mdc
            ├── 9000-rule-crafting.mdc
            ├── DOCS
            ├── GLOBAL
            ├── MCP
            ├── parameter-handling.mdc
            ├── powershell-error-handling.mdc
            └── powershell-module-exports.mdc

================================================
File: README.md
================================================
# MYMCPSERVER

A MCP server implementation for Obsidian integration that provides tools for managing and interacting with Obsidian vaults through the Model Context Protocol (MCP).

## Features

- Note management (create, read, update)
- Note searching and listing
- Template support
- Backlink tracking
- Frontmatter handling
- Async operations

## Requirements

- Python >= 3.13
- MCP >= 1.6.0
- PyYAML >= 6.0.1

## Installation

```bash
uv add PyYAML
```

## Usage

Run the server:

```bash
python -m mymcpserver
```



================================================
File: INTEGRATION.md
================================================
# MCP Architecture Integration Guide

This document explains how the mymcpserver package integrates with the planned MCP architecture described in the documentation. It provides a guide for developers to understand how the different components work together.

## Architecture Overview

The MCP (Machine Comprehension Platform) consists of several layers as described in the architecture documentation:

```mermaid
flowchart TD
    Client["MCP Client (Cursor)"] <-- SSE --> Proxy["Proxy Connection Server"]
    Proxy <-- stdio --> Core["MCP Core Layer"]
    Core -- Dispatch --> Adapter["Adapter/Registry Layer"]
    Adapter -- Route --> ToolServers["Tool Servers"]
```

## Components and Their Purpose

### 1. mymcpserver (Entry Point)

The `mymcpserver` package serves as the main entry point for the entire MCP system. It provides:

- Central configuration management
- Component initialization based on environment settings
- Support for different transport mechanisms (HTTP, stdio, SSE)
- Proper logging and error handling

### 2. Proxy Connection Server (src/mcp_proxy/)

This component handles the translation between different transport protocols:

- Receives requests from MCP clients via SSE, WebSockets, or HTTP
- Translates these requests to stdio for internal communication
- Returns responses back to clients in the appropriate format

### 3. MCP Core Layer (src/mcp_core/)

The central processing component of the system:

- Handles the business logic of processing MCP requests
- Uses the FastAPI framework for HTTP-based API
- Routes requests to the Adapter/Registry Layer
- Handles proper error responses and logging

### 4. Adapter/Registry Layer (src/mcp_core/adapters/)

This component manages tool registration and routing:

- Maintains a registry of available tools
- Versioning support for tools
- Circuit breaker pattern for fault tolerance
- Routes requests to appropriate tool servers

### 5. Tool Servers (src/tool_servers/)

Tool servers implement the actual functionality:

- Python Tool Server for Python-based tools
- TypeScript Tool Server for TypeScript/JavaScript tools
- Each tool server has its own set of tools with specific implementations

## Integration Points

### Starting the Server

The main entry point is through the `mymcpserver` package, which can be started using:

```bash
# Full mode (starts appropriate components based on transport)
uv run mymcpserver

# Start specific components
uv run mymcpserver --component proxy
uv run mymcpserver --component core

# Use different transport mechanisms
uv run mymcpserver --transport stdio
uv run mymcpserver --transport http
```

For more comprehensive control, use the `run_server.py` script:

```bash
# Full system
python src/run_server.py --mode full

# Specific components
python src/run_server.py --mode proxy --transport sse
python src/run_server.py --mode core --transport http
python src/run_server.py --mode tool --tool-server python
```

### Configuration

All components use the same configuration system, which reads from:

1. Environment variables
2. `.env` file
3. Command-line arguments
4. Default values

The configuration system supports different environments (development, production) and component-specific settings.

### Data Flow

1. **Client Request**: The MCP client (Cursor) sends a request
2. **Proxy Server**: Receives the request and translates to the appropriate format
3. **Core Layer**: Processes the request and routes it to the Adapter/Registry
4. **Adapter Layer**: Identifies and routes to the appropriate tool server
5. **Tool Server**: Executes the requested functionality
6. **Response Path**: The response follows the reverse path back to the client

## Cursor Integration

The MCP Server integrates with Cursor through the configuration in `.cursor/mcp.json`, which specifies:

- Command to start the server (`uv run mymcpserver`)
- Environment variables for server configuration
- Transport mechanism (stdio)
- Request/response size limits

## Development Workflow

1. **Setup Environment**:

   ```bash
   # Install dependencies
   uv sync
   ```

2. **Run the Server**:

   ```bash
   # Development mode
   uv run mymcpserver --transport stdio
   ```

3. **Testing**:

   ```bash
   # Run tests
   uv run -m pytest tests/
   ```

4. **Building**:
   ```bash
   # Create distribution package
   uv build
   ```

## Next Steps for Implementation

To complete the integration with the planned architecture:

1. **Implement Tool Servers**: Create and integrate the Python and TypeScript tool servers
2. **Enhance Proxy Server**: Complete the implementation of SSE and WebSocket transports
3. **Improve Adapter Layer**: Add more robust circuit breaker and versioning functionality
4. **Add Health Monitoring**: Implement comprehensive health checks across all components
5. **Create Metrics System**: Add detailed metrics collection and reporting

## Troubleshooting

- **Component Communication**: Check that the transport mechanism is configured correctly
- **Environment Variables**: Verify that all required variables are set in the `.env` file
- **Path Issues**: Ensure that the Python path includes the `src` directory
- **Permissions**: Check file and network access permissions

## Additional Resources

- See `docs-obsidian/user added for indexing later/mcpPlanning/final/filetree.md` for detailed file structure
- See `docs-obsidian/user added for indexing later/mcpPlanning/final/overview.md` for architectural overview



================================================
File: pyproject.toml
================================================
[project]
name            = "mymcpserver"
version         = "0.1.0"
description     = "The MCP server for all tools"
readme          = "README.md"
requires-python = ">=3.10"
dependencies    = ["httpx>=0.28.1", "mcp[cli]>=1.6.0", "pyyaml>=6.0.1", "pydantic>=2.0.0", "fastapi>=0.100.0", "uvicorn>=0.22.0", "asyncio>=3.4.3", "jsonschema>=4.17.3", "python-dotenv>=1.0.0"]
  [[project.authors]]
  name  = "savagelysubtle"
  email = "163227725+savagelysubtle@users.noreply.github.com"

  [project.urls]
  "Homepage"    = "https://github.com/savagelysubtle/mcp"
  "Bug Tracker" = "https://github.com/savagelysubtle/mcp/issues"

[build-system]
requires      = ["uv-build>=0.6.0,<0.7"]
build-backend = "uv_build"

  [project.scripts]
  mymcpserver = "mymcpserver:main"

[tool.uv]
# Valid UV-specific configuration options
required-version = ">=0.6.0"
# Fix configuration for handling file locking issues on Windows
cache-dir = "./.uv_cache"
index-url = "https://pypi.org/simple/"
# Add configuration to handle binary package issues
no-build-isolation-package = ["ruff"]

[tool.setuptools.packages.find]
where   = ["src"]
include = ["mymcpserver", "mcp_core", "mcp_proxy", "tool_servers"]

[tool.pytest.ini_options]
testpaths                          = ["tests"]
pythonpath                         = ["src"]
tmp_path_retention_count           = 2
tmp_path_retention_policy          = "failed"
addopts                            = "--basetemp=./tmp"
markers                            = ["asyncio: mark a test as an asyncio test", "metadata: mark a test relating to metadata extraction", "unit: mark a test as a unit test", "file_operations: mark a test relating to file operations", "tagging: mark a test relating to tagging", "search: mark a test relating to search functionality", "unit: Unit tests", "integration: Integration tests", "slow: Tests that take longer to run"]
asyncio_mode                       = "strict"
asyncio_default_fixture_loop_scope = "function"
filterwarnings                     = ["ignore::DeprecationWarning", "ignore::PendingDeprecationWarning"]
python_files                       = ["test_*.py"]
python_classes                     = ["Test*"]
python_functions                   = ["test_*"]

[tool.ruff]
include = ["pyproject.toml", "src/**/*.py", "scripts/**/*.py", "src/**/*.py"]

exclude = [".bzr", ".direnv", ".eggs", ".git", ".git-rewrite", ".hg", ".ipynb_checkpoints", ".mypy_cache", ".nox", ".pants.d", ".pyenv", ".pytest_cache", ".pytype", ".ruff_cache", ".svn", ".tox", ".venv", ".vscode", "__pypackages__", "_build", "buck-out", "build", "dist", "node_modules", "site-packages", "venv"]

# Same as Black.
line-length  = 88
indent-width = 4

  [tool.ruff.lint]
  select = [
    "E",   # pycodestyle errors
    "F",   # pyflakes
    "I",   # isort
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
    "UP",  # pyupgrade
    "N",   # pep8-naming
    "ANN", # flake8-annotations
    "S",   # flake8-bandit
    "A",   # flake8-builtins
  ]
  ignore = ["E501", "ANN101", "ANN102", "ANN401"]
  fixable = ["ALL"]
  unfixable = []
  dummy-variable-rgx = "^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$"

  # Include per-file-ignores directly in the lint section
  per-file-ignores = {"tests/**/*.py" = ["S101", "ANN401", "F821", "F823"], "*/__init__.py" = ["F401"]}

  [tool.ruff.format]
  quote-style                = "double"
  indent-style               = "space"
  skip-magic-trailing-comma  = false
  line-ending                = "auto"
  docstring-code-format      = false
  docstring-code-line-length = "dynamic"

[tool.markdownlint]
default = true
MD013   = false # Line length
MD033   = false # Inline HTML
MD036   = false # Emphasis used as header
MD041   = false # First line should be a top-level header
MD001   = false # Header levels should only increment by one level
MD026   = false # Trailing punctuation in header

# Migrated from cspell.config.yaml
[tool.cspell]
version                = "0.2"
ignore-paths           = []
dictionary-definitions = []
dictionaries           = []
words                  = []
ignore-words           = []
imports                = []



================================================
File: requirements.txt
================================================
fastapi==0.110.0
uvicorn==0.28.0
pydantic==2.6.0
python-dotenv==1.0.1
httpx==0.27.0
pytest==7.4.3
pytest-asyncio==0.23.2
mypy==1.8.0
black==24.1.1
isort==5.13.2
flake8==7.0.0


================================================
File: uv.lock
================================================
version = 1
revision = 1
requires-python = ">=3.10"

[[package]]
name = "annotated-types"
version = "0.7.0"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/ee/67/531ea369ba64dcff5ec9c3402f9f51bf748cec26dde048a2f973a4eea7f5/annotated_types-0.7.0.tar.gz", hash = "sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89", size = 16081 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl", hash = "sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53", size = 13643 },
]

[[package]]
name = "anyio"
version = "4.9.0"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "exceptiongroup", marker = "python_full_version < '3.11'" },
    { name = "idna" },
    { name = "sniffio" },
    { name = "typing-extensions", marker = "python_full_version < '3.13'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/95/7d/4c1bd541d4dffa1b52bd83fb8527089e097a106fc90b467a7313b105f840/anyio-4.9.0.tar.gz", hash = "sha256:673c0c244e15788651a4ff38710fea9675823028a6f08a5eda409e0c9840a028", size = 190949 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/a1/ee/48ca1a7c89ffec8b6a0c5d02b89c305671d5ffd8d3c94acf8b8c408575bb/anyio-4.9.0-py3-none-any.whl", hash = "sha256:9f76d541cad6e36af7beb62e978876f3b41e3e04f2c1fbf0884604c0a9c4d93c", size = 100916 },
]

[[package]]
name = "asyncio"
version = "3.4.3"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/da/54/054bafaf2c0fb8473d423743e191fcdf49b2c1fd5e9af3524efbe097bafd/asyncio-3.4.3.tar.gz", hash = "sha256:83360ff8bc97980e4ff25c964c7bd3923d333d177aa4f7fb736b019f26c7cb41", size = 204411 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/22/74/07679c5b9f98a7cb0fc147b1ef1cc1853bc07a4eb9cb5731e24732c5f773/asyncio-3.4.3-py3-none-any.whl", hash = "sha256:c4d18b22701821de07bd6aea8b53d21449ec0ec5680645e5317062ea21817d2d", size = 101767 },
]

[[package]]
name = "attrs"
version = "25.3.0"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/5a/b0/1367933a8532ee6ff8d63537de4f1177af4bff9f3e829baf7331f595bb24/attrs-25.3.0.tar.gz", hash = "sha256:75d7cefc7fb576747b2c81b4442d4d4a1ce0900973527c011d1030fd3bf4af1b", size = 812032 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/77/06/bb80f5f86020c4551da315d78b3ab75e8228f89f0162f2c3a819e407941a/attrs-25.3.0-py3-none-any.whl", hash = "sha256:427318ce031701fea540783410126f03899a97ffc6f61596ad581ac2e40e3bc3", size = 63815 },
]

[[package]]
name = "certifi"
version = "2025.1.31"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/1c/ab/c9f1e32b7b1bf505bf26f0ef697775960db7932abeb7b516de930ba2705f/certifi-2025.1.31.tar.gz", hash = "sha256:3d5da6925056f6f18f119200434a4780a94263f10d1c21d032a6f6b2baa20651", size = 167577 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/38/fc/bce832fd4fd99766c04d1ee0eead6b0ec6486fb100ae5e74c1d91292b982/certifi-2025.1.31-py3-none-any.whl", hash = "sha256:ca78db4565a652026a4db2bcdf68f2fb589ea80d0be70e03929ed730746b84fe", size = 166393 },
]

[[package]]
name = "click"
version = "8.1.8"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "colorama", marker = "sys_platform == 'win32'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b9/2e/0090cbf739cee7d23781ad4b89a9894a41538e4fcf4c31dcdd705b78eb8b/click-8.1.8.tar.gz", hash = "sha256:ed53c9d8990d83c2a27deae68e4ee337473f6330c040a31d4225c9574d16096a", size = 226593 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7e/d4/7ebdbd03970677812aac39c869717059dbb71a4cfc033ca6e5221787892c/click-8.1.8-py3-none-any.whl", hash = "sha256:63c132bbbed01578a06712a2d1f497bb62d9c1c0d329b7903a866228027263b2", size = 98188 },
]

[[package]]
name = "colorama"
version = "0.4.6"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/d8/53/6f443c9a4a8358a93a6792e2acffb9d9d5cb0a5cfd8802644b7b1c9a02e4/colorama-0.4.6.tar.gz", hash = "sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44", size = 27697 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl", hash = "sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6", size = 25335 },
]

[[package]]
name = "exceptiongroup"
version = "1.2.2"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/09/35/2495c4ac46b980e4ca1f6ad6db102322ef3ad2410b79fdde159a4b0f3b92/exceptiongroup-1.2.2.tar.gz", hash = "sha256:47c2edf7c6738fafb49fd34290706d1a1a2f4d1c6df275526b62cbb4aa5393cc", size = 28883 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/02/cc/b7e31358aac6ed1ef2bb790a9746ac2c69bcb3c8588b41616914eb106eaf/exceptiongroup-1.2.2-py3-none-any.whl", hash = "sha256:3111b9d131c238bec2f8f516e123e14ba243563fb135d3fe885990585aa7795b", size = 16453 },
]

[[package]]
name = "fastapi"
version = "0.115.12"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "pydantic" },
    { name = "starlette" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/f4/55/ae499352d82338331ca1e28c7f4a63bfd09479b16395dce38cf50a39e2c2/fastapi-0.115.12.tar.gz", hash = "sha256:1e2c2a2646905f9e83d32f04a3f86aff4a286669c6c950ca95b5fd68c2602681", size = 295236 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/50/b3/b51f09c2ba432a576fe63758bddc81f78f0c6309d9e5c10d194313bf021e/fastapi-0.115.12-py3-none-any.whl", hash = "sha256:e94613d6c05e27be7ffebdd6ea5f388112e5e430c8f7d6494a9d1d88d43e814d", size = 95164 },
]

[[package]]
name = "h11"
version = "0.14.0"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/f5/38/3af3d3633a34a3316095b39c8e8fb4853a28a536e55d347bd8d8e9a14b03/h11-0.14.0.tar.gz", hash = "sha256:8f19fbbe99e72420ff35c00b27a34cb9937e902a8b810e2c88300c6f0a3b699d", size = 100418 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl", hash = "sha256:e3fe4ac4b851c468cc8363d500db52c2ead036020723024a109d37346efaa761", size = 58259 },
]

[[package]]
name = "httpcore"
version = "1.0.7"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "certifi" },
    { name = "h11" },
]
sdist = { url = "https://files.pythonhosted.org/packages/6a/41/d7d0a89eb493922c37d343b607bc1b5da7f5be7e383740b4753ad8943e90/httpcore-1.0.7.tar.gz", hash = "sha256:8551cb62a169ec7162ac7be8d4817d561f60e08eaa485234898414bb5a8a0b4c", size = 85196 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/87/f5/72347bc88306acb359581ac4d52f23c0ef445b57157adedb9aee0cd689d2/httpcore-1.0.7-py3-none-any.whl", hash = "sha256:a3fff8f43dc260d5bd363d9f9cf1830fa3a458b332856f34282de498ed420edd", size = 78551 },
]

[[package]]
name = "httpx"
version = "0.28.1"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "anyio" },
    { name = "certifi" },
    { name = "httpcore" },
    { name = "idna" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b1/df/48c586a5fe32a0f01324ee087459e112ebb7224f646c0b5023f5e79e9956/httpx-0.28.1.tar.gz", hash = "sha256:75e98c5f16b0f35b567856f597f06ff2270a374470a5c2392242528e3e3e42fc", size = 141406 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl", hash = "sha256:d909fcccc110f8c7faf814ca82a9a4d816bc5a6dbfea25d6591d6985b8ba59ad", size = 73517 },
]

[[package]]
name = "httpx-sse"
version = "0.4.0"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/4c/60/8f4281fa9bbf3c8034fd54c0e7412e66edbab6bc74c4996bd616f8d0406e/httpx-sse-0.4.0.tar.gz", hash = "sha256:1e81a3a3070ce322add1d3529ed42eb5f70817f45ed6ec915ab753f961139721", size = 12624 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl", hash = "sha256:f329af6eae57eaa2bdfd962b42524764af68075ea87370a2de920af5341e318f", size = 7819 },
]

[[package]]
name = "idna"
version = "3.10"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/f1/70/7703c29685631f5a7590aa73f1f1d3fa9a380e654b86af429e0934a32f7d/idna-3.10.tar.gz", hash = "sha256:12f65c9b470abda6dc35cf8e63cc574b1c52b11df2c86030af0ac09b01b13ea9", size = 190490 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl", hash = "sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3", size = 70442 },
]

[[package]]
name = "jsonschema"
version = "4.23.0"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "attrs" },
    { name = "jsonschema-specifications" },
    { name = "referencing" },
    { name = "rpds-py" },
]
sdist = { url = "https://files.pythonhosted.org/packages/38/2e/03362ee4034a4c917f697890ccd4aec0800ccf9ded7f511971c75451deec/jsonschema-4.23.0.tar.gz", hash = "sha256:d71497fef26351a33265337fa77ffeb82423f3ea21283cd9467bb03999266bc4", size = 325778 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/69/4a/4f9dbeb84e8850557c02365a0eee0649abe5eb1d84af92a25731c6c0f922/jsonschema-4.23.0-py3-none-any.whl", hash = "sha256:fbadb6f8b144a8f8cf9f0b89ba94501d143e50411a1278633f56a7acf7fd5566", size = 88462 },
]

[[package]]
name = "jsonschema-specifications"
version = "2024.10.1"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "referencing" },
]
sdist = { url = "https://files.pythonhosted.org/packages/10/db/58f950c996c793472e336ff3655b13fbcf1e3b359dcf52dcf3ed3b52c352/jsonschema_specifications-2024.10.1.tar.gz", hash = "sha256:0f38b83639958ce1152d02a7f062902c41c8fd20d558b0c34344292d417ae272", size = 15561 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d1/0f/8910b19ac0670a0f80ce1008e5e751c4a57e14d2c4c13a482aa6079fa9d6/jsonschema_specifications-2024.10.1-py3-none-any.whl", hash = "sha256:a09a0680616357d9a0ecf05c12ad234479f549239d0f5b55f3deea67475da9bf", size = 18459 },
]

[[package]]
name = "markdown-it-py"
version = "3.0.0"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "mdurl" },
]
sdist = { url = "https://files.pythonhosted.org/packages/38/71/3b932df36c1a044d397a1f92d1cf91ee0a503d91e470cbd670aa66b07ed0/markdown-it-py-3.0.0.tar.gz", hash = "sha256:e3f60a94fa066dc52ec76661e37c851cb232d92f9886b15cb560aaada2df8feb", size = 74596 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl", hash = "sha256:355216845c60bd96232cd8d8c40e8f9765cc86f46880e43a8fd22dc1a1a8cab1", size = 87528 },
]

[[package]]
name = "mcp"
version = "1.6.0"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "anyio" },
    { name = "httpx" },
    { name = "httpx-sse" },
    { name = "pydantic" },
    { name = "pydantic-settings" },
    { name = "sse-starlette" },
    { name = "starlette" },
    { name = "uvicorn" },
]
sdist = { url = "https://files.pythonhosted.org/packages/95/d2/f587cb965a56e992634bebc8611c5b579af912b74e04eb9164bd49527d21/mcp-1.6.0.tar.gz", hash = "sha256:d9324876de2c5637369f43161cd71eebfd803df5a95e46225cab8d280e366723", size = 200031 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/10/30/20a7f33b0b884a9d14dd3aa94ff1ac9da1479fe2ad66dd9e2736075d2506/mcp-1.6.0-py3-none-any.whl", hash = "sha256:7bd24c6ea042dbec44c754f100984d186620d8b841ec30f1b19eda9b93a634d0", size = 76077 },
]

[package.optional-dependencies]
cli = [
    { name = "python-dotenv" },
    { name = "typer" },
]

[[package]]
name = "mdurl"
version = "0.1.2"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/d6/54/cfe61301667036ec958cb99bd3efefba235e65cdeb9c84d24a8293ba1d90/mdurl-0.1.2.tar.gz", hash = "sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba", size = 8729 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl", hash = "sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8", size = 9979 },
]

[[package]]
name = "mymcpserver"
version = "0.1.0"
source = { editable = "." }
dependencies = [
    { name = "asyncio" },
    { name = "fastapi" },
    { name = "httpx" },
    { name = "jsonschema" },
    { name = "mcp", extra = ["cli"] },
    { name = "pydantic" },
    { name = "python-dotenv" },
    { name = "pyyaml" },
    { name = "uvicorn" },
]

[package.metadata]
requires-dist = [
    { name = "asyncio", specifier = ">=3.4.3" },
    { name = "fastapi", specifier = ">=0.100.0" },
    { name = "httpx", specifier = ">=0.28.1" },
    { name = "jsonschema", specifier = ">=4.17.3" },
    { name = "mcp", extras = ["cli"], specifier = ">=1.6.0" },
    { name = "pydantic", specifier = ">=2.0.0" },
    { name = "python-dotenv", specifier = ">=1.0.0" },
    { name = "pyyaml", specifier = ">=6.0.1" },
    { name = "uvicorn", specifier = ">=0.22.0" },
]

[[package]]
name = "pydantic"
version = "2.11.1"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "annotated-types" },
    { name = "pydantic-core" },
    { name = "typing-extensions" },
    { name = "typing-inspection" },
]
sdist = { url = "https://files.pythonhosted.org/packages/93/a3/698b87a4d4d303d7c5f62ea5fbf7a79cab236ccfbd0a17847b7f77f8163e/pydantic-2.11.1.tar.gz", hash = "sha256:442557d2910e75c991c39f4b4ab18963d57b9b55122c8b2a9cd176d8c29ce968", size = 782817 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/cc/12/f9221a949f2419e2e23847303c002476c26fbcfd62dc7f3d25d0bec5ca99/pydantic-2.11.1-py3-none-any.whl", hash = "sha256:5b6c415eee9f8123a14d859be0c84363fec6b1feb6b688d6435801230b56e0b8", size = 442648 },
]

[[package]]
name = "pydantic-core"
version = "2.33.0"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b9/05/91ce14dfd5a3a99555fce436318cc0fd1f08c4daa32b3248ad63669ea8b4/pydantic_core-2.33.0.tar.gz", hash = "sha256:40eb8af662ba409c3cbf4a8150ad32ae73514cd7cb1f1a2113af39763dd616b3", size = 434080 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/29/43/0649ad07e66b36a3fb21442b425bd0348ac162c5e686b36471f363201535/pydantic_core-2.33.0-cp310-cp310-macosx_10_12_x86_64.whl", hash = "sha256:71dffba8fe9ddff628c68f3abd845e91b028361d43c5f8e7b3f8b91d7d85413e", size = 2042968 },
    { url = "https://files.pythonhosted.org/packages/a0/a6/975fea4774a459e495cb4be288efd8b041ac756a0a763f0b976d0861334b/pydantic_core-2.33.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:abaeec1be6ed535a5d7ffc2e6c390083c425832b20efd621562fbb5bff6dc518", size = 1860347 },
    { url = "https://files.pythonhosted.org/packages/aa/49/7858dadad305101a077ec4d0c606b6425a2b134ea8d858458a6d287fd871/pydantic_core-2.33.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:759871f00e26ad3709efc773ac37b4d571de065f9dfb1778012908bcc36b3a73", size = 1910060 },
    { url = "https://files.pythonhosted.org/packages/8d/4f/6522527911d9c5fe6d76b084d8b388d5c84b09d113247b39f91937500b34/pydantic_core-2.33.0-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:dcfebee69cd5e1c0b76a17e17e347c84b00acebb8dd8edb22d4a03e88e82a207", size = 1997129 },
    { url = "https://files.pythonhosted.org/packages/75/d0/06f396da053e3d73001ea4787e56b4d7132a87c0b5e2e15a041e808c35cd/pydantic_core-2.33.0-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1b1262b912435a501fa04cd213720609e2cefa723a07c92017d18693e69bf00b", size = 2140389 },
    { url = "https://files.pythonhosted.org/packages/f5/6b/b9ff5b69cd4ef007cf665463f3be2e481dc7eb26c4a55b2f57a94308c31a/pydantic_core-2.33.0-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:4726f1f3f42d6a25678c67da3f0b10f148f5655813c5aca54b0d1742ba821b8f", size = 2754237 },
    { url = "https://files.pythonhosted.org/packages/53/80/b4879de375cdf3718d05fcb60c9aa1f119d28e261dafa51b6a69c78f7178/pydantic_core-2.33.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e790954b5093dff1e3a9a2523fddc4e79722d6f07993b4cd5547825c3cbf97b5", size = 2007433 },
    { url = "https://files.pythonhosted.org/packages/46/24/54054713dc0af98a94eab37e0f4294dfd5cd8f70b2ca9dcdccd15709fd7e/pydantic_core-2.33.0-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:34e7fb3abe375b5c4e64fab75733d605dda0f59827752debc99c17cb2d5f3276", size = 2123980 },
    { url = "https://files.pythonhosted.org/packages/3a/4c/257c1cb89e14cfa6e95ebcb91b308eb1dd2b348340ff76a6e6fcfa9969e1/pydantic_core-2.33.0-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:ecb158fb9b9091b515213bed3061eb7deb1d3b4e02327c27a0ea714ff46b0760", size = 2087433 },
    { url = "https://files.pythonhosted.org/packages/0c/62/927df8a39ad78ef7b82c5446e01dec9bb0043e1ad71d8f426062f5f014db/pydantic_core-2.33.0-cp310-cp310-musllinux_1_1_armv7l.whl", hash = "sha256:4d9149e7528af8bbd76cc055967e6e04617dcb2a2afdaa3dea899406c5521faa", size = 2260242 },
    { url = "https://files.pythonhosted.org/packages/74/f2/389414f7c77a100954e84d6f52a82bd1788ae69db72364376d8a73b38765/pydantic_core-2.33.0-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:e81a295adccf73477220e15ff79235ca9dcbcee4be459eb9d4ce9a2763b8386c", size = 2258227 },
    { url = "https://files.pythonhosted.org/packages/53/99/94516313e15d906a1264bb40faf24a01a4af4e2ca8a7c10dd173b6513c5a/pydantic_core-2.33.0-cp310-cp310-win32.whl", hash = "sha256:f22dab23cdbce2005f26a8f0c71698457861f97fc6318c75814a50c75e87d025", size = 1925523 },
    { url = "https://files.pythonhosted.org/packages/7d/67/cc789611c6035a0b71305a1ec6ba196256ced76eba8375f316f840a70456/pydantic_core-2.33.0-cp310-cp310-win_amd64.whl", hash = "sha256:9cb2390355ba084c1ad49485d18449b4242da344dea3e0fe10babd1f0db7dcfc", size = 1951872 },
    { url = "https://files.pythonhosted.org/packages/f0/93/9e97af2619b4026596487a79133e425c7d3c374f0a7f100f3d76bcdf9c83/pydantic_core-2.33.0-cp311-cp311-macosx_10_12_x86_64.whl", hash = "sha256:a608a75846804271cf9c83e40bbb4dab2ac614d33c6fd5b0c6187f53f5c593ef", size = 2042784 },
    { url = "https://files.pythonhosted.org/packages/42/b4/0bba8412fd242729feeb80e7152e24f0e1a1c19f4121ca3d4a307f4e6222/pydantic_core-2.33.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:e1c69aa459f5609dec2fa0652d495353accf3eda5bdb18782bc5a2ae45c9273a", size = 1858179 },
    { url = "https://files.pythonhosted.org/packages/69/1f/c1c40305d929bd08af863df64b0a26203b70b352a1962d86f3bcd52950fe/pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b9ec80eb5a5f45a2211793f1c4aeddff0c3761d1c70d684965c1807e923a588b", size = 1909396 },
    { url = "https://files.pythonhosted.org/packages/0f/99/d2e727375c329c1e652b5d450fbb9d56e8c3933a397e4bd46e67c68c2cd5/pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:e925819a98318d17251776bd3d6aa9f3ff77b965762155bdad15d1a9265c4cfd", size = 1998264 },
    { url = "https://files.pythonhosted.org/packages/9c/2e/3119a33931278d96ecc2e9e1b9d50c240636cfeb0c49951746ae34e4de74/pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:5bf68bb859799e9cec3d9dd8323c40c00a254aabb56fe08f907e437005932f2b", size = 2140588 },
    { url = "https://files.pythonhosted.org/packages/35/bd/9267bd1ba55f17c80ef6cb7e07b3890b4acbe8eb6014f3102092d53d9300/pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:1b2ea72dea0825949a045fa4071f6d5b3d7620d2a208335207793cf29c5a182d", size = 2746296 },
    { url = "https://files.pythonhosted.org/packages/6f/ed/ef37de6478a412ee627cbebd73e7b72a680f45bfacce9ff1199de6e17e88/pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1583539533160186ac546b49f5cde9ffc928062c96920f58bd95de32ffd7bffd", size = 2005555 },
    { url = "https://files.pythonhosted.org/packages/dd/84/72c8d1439585d8ee7bc35eb8f88a04a4d302ee4018871f1f85ae1b0c6625/pydantic_core-2.33.0-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:23c3e77bf8a7317612e5c26a3b084c7edeb9552d645742a54a5867635b4f2453", size = 2124452 },
    { url = "https://files.pythonhosted.org/packages/a7/8f/cb13de30c6a3e303423751a529a3d1271c2effee4b98cf3e397a66ae8498/pydantic_core-2.33.0-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:a7a7f2a3f628d2f7ef11cb6188bcf0b9e1558151d511b974dfea10a49afe192b", size = 2087001 },
    { url = "https://files.pythonhosted.org/packages/83/d0/e93dc8884bf288a63fedeb8040ac8f29cb71ca52e755f48e5170bb63e55b/pydantic_core-2.33.0-cp311-cp311-musllinux_1_1_armv7l.whl", hash = "sha256:f1fb026c575e16f673c61c7b86144517705865173f3d0907040ac30c4f9f5915", size = 2261663 },
    { url = "https://files.pythonhosted.org/packages/4c/ba/4b7739c95efa0b542ee45fd872c8f6b1884ab808cf04ce7ac6621b6df76e/pydantic_core-2.33.0-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:635702b2fed997e0ac256b2cfbdb4dd0bf7c56b5d8fba8ef03489c03b3eb40e2", size = 2257786 },
    { url = "https://files.pythonhosted.org/packages/cc/98/73cbca1d2360c27752cfa2fcdcf14d96230e92d7d48ecd50499865c56bf7/pydantic_core-2.33.0-cp311-cp311-win32.whl", hash = "sha256:07b4ced28fccae3f00626eaa0c4001aa9ec140a29501770a88dbbb0966019a86", size = 1925697 },
    { url = "https://files.pythonhosted.org/packages/9a/26/d85a40edeca5d8830ffc33667d6fef329fd0f4bc0c5181b8b0e206cfe488/pydantic_core-2.33.0-cp311-cp311-win_amd64.whl", hash = "sha256:4927564be53239a87770a5f86bdc272b8d1fbb87ab7783ad70255b4ab01aa25b", size = 1949859 },
    { url = "https://files.pythonhosted.org/packages/7e/0b/5a381605f0b9870465b805f2c86c06b0a7c191668ebe4117777306c2c1e5/pydantic_core-2.33.0-cp311-cp311-win_arm64.whl", hash = "sha256:69297418ad644d521ea3e1aa2e14a2a422726167e9ad22b89e8f1130d68e1e9a", size = 1907978 },
    { url = "https://files.pythonhosted.org/packages/a9/c4/c9381323cbdc1bb26d352bc184422ce77c4bc2f2312b782761093a59fafc/pydantic_core-2.33.0-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:6c32a40712e3662bebe524abe8abb757f2fa2000028d64cc5a1006016c06af43", size = 2025127 },
    { url = "https://files.pythonhosted.org/packages/6f/bd/af35278080716ecab8f57e84515c7dc535ed95d1c7f52c1c6f7b313a9dab/pydantic_core-2.33.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:8ec86b5baa36f0a0bfb37db86c7d52652f8e8aa076ab745ef7725784183c3fdd", size = 1851687 },
    { url = "https://files.pythonhosted.org/packages/12/e4/a01461225809c3533c23bd1916b1e8c2e21727f0fea60ab1acbffc4e2fca/pydantic_core-2.33.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4deac83a8cc1d09e40683be0bc6d1fa4cde8df0a9bf0cda5693f9b0569ac01b6", size = 1892232 },
    { url = "https://files.pythonhosted.org/packages/51/17/3d53d62a328fb0a49911c2962036b9e7a4f781b7d15e9093c26299e5f76d/pydantic_core-2.33.0-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:175ab598fb457a9aee63206a1993874badf3ed9a456e0654273e56f00747bbd6", size = 1977896 },
    { url = "https://files.pythonhosted.org/packages/30/98/01f9d86e02ec4a38f4b02086acf067f2c776b845d43f901bd1ee1c21bc4b/pydantic_core-2.33.0-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:5f36afd0d56a6c42cf4e8465b6441cf546ed69d3a4ec92724cc9c8c61bd6ecf4", size = 2127717 },
    { url = "https://files.pythonhosted.org/packages/3c/43/6f381575c61b7c58b0fd0b92134c5a1897deea4cdfc3d47567b3ff460a4e/pydantic_core-2.33.0-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:0a98257451164666afafc7cbf5fb00d613e33f7e7ebb322fbcd99345695a9a61", size = 2680287 },
    { url = "https://files.pythonhosted.org/packages/01/42/c0d10d1451d161a9a0da9bbef023b8005aa26e9993a8cc24dc9e3aa96c93/pydantic_core-2.33.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ecc6d02d69b54a2eb83ebcc6f29df04957f734bcf309d346b4f83354d8376862", size = 2008276 },
    { url = "https://files.pythonhosted.org/packages/20/ca/e08df9dba546905c70bae44ced9f3bea25432e34448d95618d41968f40b7/pydantic_core-2.33.0-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:1a69b7596c6603afd049ce7f3835bcf57dd3892fc7279f0ddf987bebed8caa5a", size = 2115305 },
    { url = "https://files.pythonhosted.org/packages/03/1f/9b01d990730a98833113581a78e595fd40ed4c20f9693f5a658fb5f91eff/pydantic_core-2.33.0-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:ea30239c148b6ef41364c6f51d103c2988965b643d62e10b233b5efdca8c0099", size = 2068999 },
    { url = "https://files.pythonhosted.org/packages/20/18/fe752476a709191148e8b1e1139147841ea5d2b22adcde6ee6abb6c8e7cf/pydantic_core-2.33.0-cp312-cp312-musllinux_1_1_armv7l.whl", hash = "sha256:abfa44cf2f7f7d7a199be6c6ec141c9024063205545aa09304349781b9a125e6", size = 2241488 },
    { url = "https://files.pythonhosted.org/packages/81/22/14738ad0a0bf484b928c9e52004f5e0b81dd8dabbdf23b843717b37a71d1/pydantic_core-2.33.0-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:20d4275f3c4659d92048c70797e5fdc396c6e4446caf517ba5cad2db60cd39d3", size = 2248430 },
    { url = "https://files.pythonhosted.org/packages/e8/27/be7571e215ac8d321712f2433c445b03dbcd645366a18f67b334df8912bc/pydantic_core-2.33.0-cp312-cp312-win32.whl", hash = "sha256:918f2013d7eadea1d88d1a35fd4a1e16aaf90343eb446f91cb091ce7f9b431a2", size = 1908353 },
    { url = "https://files.pythonhosted.org/packages/be/3a/be78f28732f93128bd0e3944bdd4b3970b389a1fbd44907c97291c8dcdec/pydantic_core-2.33.0-cp312-cp312-win_amd64.whl", hash = "sha256:aec79acc183865bad120b0190afac467c20b15289050648b876b07777e67ea48", size = 1955956 },
    { url = "https://files.pythonhosted.org/packages/21/26/b8911ac74faa994694b76ee6a22875cc7a4abea3c381fdba4edc6c6bef84/pydantic_core-2.33.0-cp312-cp312-win_arm64.whl", hash = "sha256:5461934e895968655225dfa8b3be79e7e927e95d4bd6c2d40edd2fa7052e71b6", size = 1903259 },
    { url = "https://files.pythonhosted.org/packages/79/20/de2ad03ce8f5b3accf2196ea9b44f31b0cd16ac6e8cfc6b21976ed45ec35/pydantic_core-2.33.0-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:f00e8b59e1fc8f09d05594aa7d2b726f1b277ca6155fc84c0396db1b373c4555", size = 2032214 },
    { url = "https://files.pythonhosted.org/packages/f9/af/6817dfda9aac4958d8b516cbb94af507eb171c997ea66453d4d162ae8948/pydantic_core-2.33.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:1a73be93ecef45786d7d95b0c5e9b294faf35629d03d5b145b09b81258c7cd6d", size = 1852338 },
    { url = "https://files.pythonhosted.org/packages/44/f3/49193a312d9c49314f2b953fb55740b7c530710977cabe7183b8ef111b7f/pydantic_core-2.33.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ff48a55be9da6930254565ff5238d71d5e9cd8c5487a191cb85df3bdb8c77365", size = 1896913 },
    { url = "https://files.pythonhosted.org/packages/06/e0/c746677825b2e29a2fa02122a8991c83cdd5b4c5f638f0664d4e35edd4b2/pydantic_core-2.33.0-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:26a4ea04195638dcd8c53dadb545d70badba51735b1594810e9768c2c0b4a5da", size = 1986046 },
    { url = "https://files.pythonhosted.org/packages/11/ec/44914e7ff78cef16afb5e5273d480c136725acd73d894affdbe2a1bbaad5/pydantic_core-2.33.0-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:41d698dcbe12b60661f0632b543dbb119e6ba088103b364ff65e951610cb7ce0", size = 2128097 },
    { url = "https://files.pythonhosted.org/packages/fe/f5/c6247d424d01f605ed2e3802f338691cae17137cee6484dce9f1ac0b872b/pydantic_core-2.33.0-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:ae62032ef513fe6281ef0009e30838a01057b832dc265da32c10469622613885", size = 2681062 },
    { url = "https://files.pythonhosted.org/packages/f0/85/114a2113b126fdd7cf9a9443b1b1fe1b572e5bd259d50ba9d5d3e1927fa9/pydantic_core-2.33.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f225f3a3995dbbc26affc191d0443c6c4aa71b83358fd4c2b7d63e2f6f0336f9", size = 2007487 },
    { url = "https://files.pythonhosted.org/packages/e6/40/3c05ed28d225c7a9acd2b34c5c8010c279683a870219b97e9f164a5a8af0/pydantic_core-2.33.0-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:5bdd36b362f419c78d09630cbaebc64913f66f62bda6d42d5fbb08da8cc4f181", size = 2121382 },
    { url = "https://files.pythonhosted.org/packages/8a/22/e70c086f41eebd323e6baa92cc906c3f38ddce7486007eb2bdb3b11c8f64/pydantic_core-2.33.0-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:2a0147c0bef783fd9abc9f016d66edb6cac466dc54a17ec5f5ada08ff65caf5d", size = 2072473 },
    { url = "https://files.pythonhosted.org/packages/3e/84/d1614dedd8fe5114f6a0e348bcd1535f97d76c038d6102f271433cd1361d/pydantic_core-2.33.0-cp313-cp313-musllinux_1_1_armv7l.whl", hash = "sha256:c860773a0f205926172c6644c394e02c25421dc9a456deff16f64c0e299487d3", size = 2249468 },
    { url = "https://files.pythonhosted.org/packages/b0/c0/787061eef44135e00fddb4b56b387a06c303bfd3884a6df9bea5cb730230/pydantic_core-2.33.0-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:138d31e3f90087f42aa6286fb640f3c7a8eb7bdae829418265e7e7474bd2574b", size = 2254716 },
    { url = "https://files.pythonhosted.org/packages/ae/e2/27262eb04963201e89f9c280f1e10c493a7a37bc877e023f31aa72d2f911/pydantic_core-2.33.0-cp313-cp313-win32.whl", hash = "sha256:d20cbb9d3e95114325780f3cfe990f3ecae24de7a2d75f978783878cce2ad585", size = 1916450 },
    { url = "https://files.pythonhosted.org/packages/13/8d/25ff96f1e89b19e0b70b3cd607c9ea7ca27e1dcb810a9cd4255ed6abf869/pydantic_core-2.33.0-cp313-cp313-win_amd64.whl", hash = "sha256:ca1103d70306489e3d006b0f79db8ca5dd3c977f6f13b2c59ff745249431a606", size = 1956092 },
    { url = "https://files.pythonhosted.org/packages/1b/64/66a2efeff657b04323ffcd7b898cb0354d36dae3a561049e092134a83e9c/pydantic_core-2.33.0-cp313-cp313-win_arm64.whl", hash = "sha256:6291797cad239285275558e0a27872da735b05c75d5237bbade8736f80e4c225", size = 1908367 },
    { url = "https://files.pythonhosted.org/packages/52/54/295e38769133363d7ec4a5863a4d579f331728c71a6644ff1024ee529315/pydantic_core-2.33.0-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:7b79af799630af263eca9ec87db519426d8c9b3be35016eddad1832bac812d87", size = 1813331 },
    { url = "https://files.pythonhosted.org/packages/4c/9c/0c8ea02db8d682aa1ef48938abae833c1d69bdfa6e5ec13b21734b01ae70/pydantic_core-2.33.0-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:eabf946a4739b5237f4f56d77fa6668263bc466d06a8036c055587c130a46f7b", size = 1986653 },
    { url = "https://files.pythonhosted.org/packages/8e/4f/3fb47d6cbc08c7e00f92300e64ba655428c05c56b8ab6723bd290bae6458/pydantic_core-2.33.0-cp313-cp313t-win_amd64.whl", hash = "sha256:8a1d581e8cdbb857b0e0e81df98603376c1a5c34dc5e54039dcc00f043df81e7", size = 1931234 },
    { url = "https://files.pythonhosted.org/packages/44/77/85e173b715e1a277ce934f28d877d82492df13e564fa68a01c96f36a47ad/pydantic_core-2.33.0-pp310-pypy310_pp73-macosx_10_12_x86_64.whl", hash = "sha256:e2762c568596332fdab56b07060c8ab8362c56cf2a339ee54e491cd503612c50", size = 2040129 },
    { url = "https://files.pythonhosted.org/packages/33/e7/33da5f8a94bbe2191cfcd15bd6d16ecd113e67da1b8c78d3cc3478112dab/pydantic_core-2.33.0-pp310-pypy310_pp73-macosx_11_0_arm64.whl", hash = "sha256:5bf637300ff35d4f59c006fff201c510b2b5e745b07125458a5389af3c0dff8c", size = 1872656 },
    { url = "https://files.pythonhosted.org/packages/b4/7a/9600f222bea840e5b9ba1f17c0acc79b669b24542a78c42c6a10712c0aae/pydantic_core-2.33.0-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:62c151ce3d59ed56ebd7ce9ce5986a409a85db697d25fc232f8e81f195aa39a1", size = 1903731 },
    { url = "https://files.pythonhosted.org/packages/81/d2/94c7ca4e24c5dcfb74df92e0836c189e9eb6814cf62d2f26a75ea0a906db/pydantic_core-2.33.0-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9ee65f0cc652261744fd07f2c6e6901c914aa6c5ff4dcfaf1136bc394d0dd26b", size = 2083966 },
    { url = "https://files.pythonhosted.org/packages/b8/74/a0259989d220e8865ed6866a6d40539e40fa8f507e587e35d2414cc081f8/pydantic_core-2.33.0-pp310-pypy310_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:024d136ae44d233e6322027bbf356712b3940bee816e6c948ce4b90f18471b3d", size = 2118951 },
    { url = "https://files.pythonhosted.org/packages/13/4c/87405ed04d6d07597920b657f082a8e8e58bf3034178bb9044b4d57a91e2/pydantic_core-2.33.0-pp310-pypy310_pp73-musllinux_1_1_aarch64.whl", hash = "sha256:e37f10f6d4bc67c58fbd727108ae1d8b92b397355e68519f1e4a7babb1473442", size = 2079632 },
    { url = "https://files.pythonhosted.org/packages/5a/4c/bcb02970ef91d4cd6de7c6893101302637da456bc8b52c18ea0d047b55ce/pydantic_core-2.33.0-pp310-pypy310_pp73-musllinux_1_1_armv7l.whl", hash = "sha256:502ed542e0d958bd12e7c3e9a015bce57deaf50eaa8c2e1c439b512cb9db1e3a", size = 2250541 },
    { url = "https://files.pythonhosted.org/packages/a3/2b/dbe5450c4cd904be5da736dcc7f2357b828199e29e38de19fc81f988b288/pydantic_core-2.33.0-pp310-pypy310_pp73-musllinux_1_1_x86_64.whl", hash = "sha256:715c62af74c236bf386825c0fdfa08d092ab0f191eb5b4580d11c3189af9d330", size = 2255685 },
    { url = "https://files.pythonhosted.org/packages/ca/a6/ca1d35f695d81f639c5617fc9efb44caad21a9463383fa45364b3044175a/pydantic_core-2.33.0-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:bccc06fa0372151f37f6b69834181aa9eb57cf8665ed36405fb45fbf6cac3bae", size = 2082395 },
    { url = "https://files.pythonhosted.org/packages/2b/b2/553e42762e7b08771fca41c0230c1ac276f9e79e78f57628e1b7d328551d/pydantic_core-2.33.0-pp311-pypy311_pp73-macosx_10_12_x86_64.whl", hash = "sha256:5d8dc9f63a26f7259b57f46a7aab5af86b2ad6fbe48487500bb1f4b27e051e4c", size = 2041207 },
    { url = "https://files.pythonhosted.org/packages/85/81/a91a57bbf3efe53525ab75f65944b8950e6ef84fe3b9a26c1ec173363263/pydantic_core-2.33.0-pp311-pypy311_pp73-macosx_11_0_arm64.whl", hash = "sha256:30369e54d6d0113d2aa5aee7a90d17f225c13d87902ace8fcd7bbf99b19124db", size = 1873736 },
    { url = "https://files.pythonhosted.org/packages/9c/d2/5ab52e9f551cdcbc1ee99a0b3ef595f56d031f66f88e5ca6726c49f9ce65/pydantic_core-2.33.0-pp311-pypy311_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f3eb479354c62067afa62f53bb387827bee2f75c9c79ef25eef6ab84d4b1ae3b", size = 1903794 },
    { url = "https://files.pythonhosted.org/packages/2f/5f/a81742d3f3821b16f1265f057d6e0b68a3ab13a814fe4bffac536a1f26fd/pydantic_core-2.33.0-pp311-pypy311_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0310524c833d91403c960b8a3cf9f46c282eadd6afd276c8c5edc617bd705dc9", size = 2083457 },
    { url = "https://files.pythonhosted.org/packages/b5/2f/e872005bc0fc47f9c036b67b12349a8522d32e3bda928e82d676e2a594d1/pydantic_core-2.33.0-pp311-pypy311_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:eddb18a00bbb855325db27b4c2a89a4ba491cd6a0bd6d852b225172a1f54b36c", size = 2119537 },
    { url = "https://files.pythonhosted.org/packages/d3/13/183f13ce647202eaf3dada9e42cdfc59cbb95faedd44d25f22b931115c7f/pydantic_core-2.33.0-pp311-pypy311_pp73-musllinux_1_1_aarch64.whl", hash = "sha256:ade5dbcf8d9ef8f4b28e682d0b29f3008df9842bb5ac48ac2c17bc55771cc976", size = 2080069 },
    { url = "https://files.pythonhosted.org/packages/23/8b/b6be91243da44a26558d9c3a9007043b3750334136c6550551e8092d6d96/pydantic_core-2.33.0-pp311-pypy311_pp73-musllinux_1_1_armv7l.whl", hash = "sha256:2c0afd34f928383e3fd25740f2050dbac9d077e7ba5adbaa2227f4d4f3c8da5c", size = 2251618 },
    { url = "https://files.pythonhosted.org/packages/aa/c5/fbcf1977035b834f63eb542e74cd6c807177f383386175b468f0865bcac4/pydantic_core-2.33.0-pp311-pypy311_pp73-musllinux_1_1_x86_64.whl", hash = "sha256:7da333f21cd9df51d5731513a6d39319892947604924ddf2e24a4612975fb936", size = 2255374 },
    { url = "https://files.pythonhosted.org/packages/2f/f8/66f328e411f1c9574b13c2c28ab01f308b53688bbbe6ca8fb981e6cabc42/pydantic_core-2.33.0-pp311-pypy311_pp73-win_amd64.whl", hash = "sha256:4b6d77c75a57f041c5ee915ff0b0bb58eabb78728b69ed967bc5b780e8f701b8", size = 2082099 },
]

[[package]]
name = "pydantic-settings"
version = "2.8.1"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "pydantic" },
    { name = "python-dotenv" },
]
sdist = { url = "https://files.pythonhosted.org/packages/88/82/c79424d7d8c29b994fb01d277da57b0a9b09cc03c3ff875f9bd8a86b2145/pydantic_settings-2.8.1.tar.gz", hash = "sha256:d5c663dfbe9db9d5e1c646b2e161da12f0d734d422ee56f567d0ea2cee4e8585", size = 83550 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/0b/53/a64f03044927dc47aafe029c42a5b7aabc38dfb813475e0e1bf71c4a59d0/pydantic_settings-2.8.1-py3-none-any.whl", hash = "sha256:81942d5ac3d905f7f3ee1a70df5dfb62d5569c12f51a5a647defc1c3d9ee2e9c", size = 30839 },
]

[[package]]
name = "pygments"
version = "2.19.1"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/7c/2d/c3338d48ea6cc0feb8446d8e6937e1408088a72a39937982cc6111d17f84/pygments-2.19.1.tar.gz", hash = "sha256:61c16d2a8576dc0649d9f39e089b5f02bcd27fba10d8fb4dcc28173f7a45151f", size = 4968581 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/8a/0b/9fcc47d19c48b59121088dd6da2488a49d5f72dacf8262e2790a1d2c7d15/pygments-2.19.1-py3-none-any.whl", hash = "sha256:9ea1544ad55cecf4b8242fab6dd35a93bbce657034b0611ee383099054ab6d8c", size = 1225293 },
]

[[package]]
name = "python-dotenv"
version = "1.1.0"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/88/2c/7bb1416c5620485aa793f2de31d3df393d3686aa8a8506d11e10e13c5baf/python_dotenv-1.1.0.tar.gz", hash = "sha256:41f90bc6f5f177fb41f53e87666db362025010eb28f60a01c9143bfa33a2b2d5", size = 39920 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/1e/18/98a99ad95133c6a6e2005fe89faedf294a748bd5dc803008059409ac9b1e/python_dotenv-1.1.0-py3-none-any.whl", hash = "sha256:d7c01d9e2293916c18baf562d95698754b0dbbb5e74d457c45d4f6561fb9d55d", size = 20256 },
]

[[package]]
name = "pyyaml"
version = "6.0.2"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/54/ed/79a089b6be93607fa5cdaedf301d7dfb23af5f25c398d5ead2525b063e17/pyyaml-6.0.2.tar.gz", hash = "sha256:d584d9ec91ad65861cc08d42e834324ef890a082e591037abe114850ff7bbc3e", size = 130631 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/9b/95/a3fac87cb7158e231b5a6012e438c647e1a87f09f8e0d123acec8ab8bf71/PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:0a9a2848a5b7feac301353437eb7d5957887edbf81d56e903999a75a3d743086", size = 184199 },
    { url = "https://files.pythonhosted.org/packages/c7/7a/68bd47624dab8fd4afbfd3c48e3b79efe09098ae941de5b58abcbadff5cb/PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:29717114e51c84ddfba879543fb232a6ed60086602313ca38cce623c1d62cfbf", size = 171758 },
    { url = "https://files.pythonhosted.org/packages/49/ee/14c54df452143b9ee9f0f29074d7ca5516a36edb0b4cc40c3f280131656f/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8824b5a04a04a047e72eea5cec3bc266db09e35de6bdfe34c9436ac5ee27d237", size = 718463 },
    { url = "https://files.pythonhosted.org/packages/4d/61/de363a97476e766574650d742205be468921a7b532aa2499fcd886b62530/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:7c36280e6fb8385e520936c3cb3b8042851904eba0e58d277dca80a5cfed590b", size = 719280 },
    { url = "https://files.pythonhosted.org/packages/6b/4e/1523cb902fd98355e2e9ea5e5eb237cbc5f3ad5f3075fa65087aa0ecb669/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ec031d5d2feb36d1d1a24380e4db6d43695f3748343d99434e6f5f9156aaa2ed", size = 751239 },
    { url = "https://files.pythonhosted.org/packages/b7/33/5504b3a9a4464893c32f118a9cc045190a91637b119a9c881da1cf6b7a72/PyYAML-6.0.2-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:936d68689298c36b53b29f23c6dbb74de12b4ac12ca6cfe0e047bedceea56180", size = 695802 },
    { url = "https://files.pythonhosted.org/packages/5c/20/8347dcabd41ef3a3cdc4f7b7a2aff3d06598c8779faa189cdbf878b626a4/PyYAML-6.0.2-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:23502f431948090f597378482b4812b0caae32c22213aecf3b55325e049a6c68", size = 720527 },
    { url = "https://files.pythonhosted.org/packages/be/aa/5afe99233fb360d0ff37377145a949ae258aaab831bde4792b32650a4378/PyYAML-6.0.2-cp310-cp310-win32.whl", hash = "sha256:2e99c6826ffa974fe6e27cdb5ed0021786b03fc98e5ee3c5bfe1fd5015f42b99", size = 144052 },
    { url = "https://files.pythonhosted.org/packages/b5/84/0fa4b06f6d6c958d207620fc60005e241ecedceee58931bb20138e1e5776/PyYAML-6.0.2-cp310-cp310-win_amd64.whl", hash = "sha256:a4d3091415f010369ae4ed1fc6b79def9416358877534caf6a0fdd2146c87a3e", size = 161774 },
    { url = "https://files.pythonhosted.org/packages/f8/aa/7af4e81f7acba21a4c6be026da38fd2b872ca46226673c89a758ebdc4fd2/PyYAML-6.0.2-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:cc1c1159b3d456576af7a3e4d1ba7e6924cb39de8f67111c735f6fc832082774", size = 184612 },
    { url = "https://files.pythonhosted.org/packages/8b/62/b9faa998fd185f65c1371643678e4d58254add437edb764a08c5a98fb986/PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:1e2120ef853f59c7419231f3bf4e7021f1b936f6ebd222406c3b60212205d2ee", size = 172040 },
    { url = "https://files.pythonhosted.org/packages/ad/0c/c804f5f922a9a6563bab712d8dcc70251e8af811fce4524d57c2c0fd49a4/PyYAML-6.0.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5d225db5a45f21e78dd9358e58a98702a0302f2659a3c6cd320564b75b86f47c", size = 736829 },
    { url = "https://files.pythonhosted.org/packages/51/16/6af8d6a6b210c8e54f1406a6b9481febf9c64a3109c541567e35a49aa2e7/PyYAML-6.0.2-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5ac9328ec4831237bec75defaf839f7d4564be1e6b25ac710bd1a96321cc8317", size = 764167 },
    { url = "https://files.pythonhosted.org/packages/75/e4/2c27590dfc9992f73aabbeb9241ae20220bd9452df27483b6e56d3975cc5/PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3ad2a3decf9aaba3d29c8f537ac4b243e36bef957511b4766cb0057d32b0be85", size = 762952 },
    { url = "https://files.pythonhosted.org/packages/9b/97/ecc1abf4a823f5ac61941a9c00fe501b02ac3ab0e373c3857f7d4b83e2b6/PyYAML-6.0.2-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:ff3824dc5261f50c9b0dfb3be22b4567a6f938ccce4587b38952d85fd9e9afe4", size = 735301 },
    { url = "https://files.pythonhosted.org/packages/45/73/0f49dacd6e82c9430e46f4a027baa4ca205e8b0a9dce1397f44edc23559d/PyYAML-6.0.2-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:797b4f722ffa07cc8d62053e4cff1486fa6dc094105d13fea7b1de7d8bf71c9e", size = 756638 },
    { url = "https://files.pythonhosted.org/packages/22/5f/956f0f9fc65223a58fbc14459bf34b4cc48dec52e00535c79b8db361aabd/PyYAML-6.0.2-cp311-cp311-win32.whl", hash = "sha256:11d8f3dd2b9c1207dcaf2ee0bbbfd5991f571186ec9cc78427ba5bd32afae4b5", size = 143850 },
    { url = "https://files.pythonhosted.org/packages/ed/23/8da0bbe2ab9dcdd11f4f4557ccaf95c10b9811b13ecced089d43ce59c3c8/PyYAML-6.0.2-cp311-cp311-win_amd64.whl", hash = "sha256:e10ce637b18caea04431ce14fabcf5c64a1c61ec9c56b071a4b7ca131ca52d44", size = 161980 },
    { url = "https://files.pythonhosted.org/packages/86/0c/c581167fc46d6d6d7ddcfb8c843a4de25bdd27e4466938109ca68492292c/PyYAML-6.0.2-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:c70c95198c015b85feafc136515252a261a84561b7b1d51e3384e0655ddf25ab", size = 183873 },
    { url = "https://files.pythonhosted.org/packages/a8/0c/38374f5bb272c051e2a69281d71cba6fdb983413e6758b84482905e29a5d/PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:ce826d6ef20b1bc864f0a68340c8b3287705cae2f8b4b1d932177dcc76721725", size = 173302 },
    { url = "https://files.pythonhosted.org/packages/c3/93/9916574aa8c00aa06bbac729972eb1071d002b8e158bd0e83a3b9a20a1f7/PyYAML-6.0.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1f71ea527786de97d1a0cc0eacd1defc0985dcf6b3f17bb77dcfc8c34bec4dc5", size = 739154 },
    { url = "https://files.pythonhosted.org/packages/95/0f/b8938f1cbd09739c6da569d172531567dbcc9789e0029aa070856f123984/PyYAML-6.0.2-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:9b22676e8097e9e22e36d6b7bda33190d0d400f345f23d4065d48f4ca7ae0425", size = 766223 },
    { url = "https://files.pythonhosted.org/packages/b9/2b/614b4752f2e127db5cc206abc23a8c19678e92b23c3db30fc86ab731d3bd/PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:80bab7bfc629882493af4aa31a4cfa43a4c57c83813253626916b8c7ada83476", size = 767542 },
    { url = "https://files.pythonhosted.org/packages/d4/00/dd137d5bcc7efea1836d6264f049359861cf548469d18da90cd8216cf05f/PyYAML-6.0.2-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:0833f8694549e586547b576dcfaba4a6b55b9e96098b36cdc7ebefe667dfed48", size = 731164 },
    { url = "https://files.pythonhosted.org/packages/c9/1f/4f998c900485e5c0ef43838363ba4a9723ac0ad73a9dc42068b12aaba4e4/PyYAML-6.0.2-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:8b9c7197f7cb2738065c481a0461e50ad02f18c78cd75775628afb4d7137fb3b", size = 756611 },
    { url = "https://files.pythonhosted.org/packages/df/d1/f5a275fdb252768b7a11ec63585bc38d0e87c9e05668a139fea92b80634c/PyYAML-6.0.2-cp312-cp312-win32.whl", hash = "sha256:ef6107725bd54b262d6dedcc2af448a266975032bc85ef0172c5f059da6325b4", size = 140591 },
    { url = "https://files.pythonhosted.org/packages/0c/e8/4f648c598b17c3d06e8753d7d13d57542b30d56e6c2dedf9c331ae56312e/PyYAML-6.0.2-cp312-cp312-win_amd64.whl", hash = "sha256:7e7401d0de89a9a855c839bc697c079a4af81cf878373abd7dc625847d25cbd8", size = 156338 },
    { url = "https://files.pythonhosted.org/packages/ef/e3/3af305b830494fa85d95f6d95ef7fa73f2ee1cc8ef5b495c7c3269fb835f/PyYAML-6.0.2-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:efdca5630322a10774e8e98e1af481aad470dd62c3170801852d752aa7a783ba", size = 181309 },
    { url = "https://files.pythonhosted.org/packages/45/9f/3b1c20a0b7a3200524eb0076cc027a970d320bd3a6592873c85c92a08731/PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:50187695423ffe49e2deacb8cd10510bc361faac997de9efef88badc3bb9e2d1", size = 171679 },
    { url = "https://files.pythonhosted.org/packages/7c/9a/337322f27005c33bcb656c655fa78325b730324c78620e8328ae28b64d0c/PyYAML-6.0.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0ffe8360bab4910ef1b9e87fb812d8bc0a308b0d0eef8c8f44e0254ab3b07133", size = 733428 },
    { url = "https://files.pythonhosted.org/packages/a3/69/864fbe19e6c18ea3cc196cbe5d392175b4cf3d5d0ac1403ec3f2d237ebb5/PyYAML-6.0.2-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:17e311b6c678207928d649faa7cb0d7b4c26a0ba73d41e99c4fff6b6c3276484", size = 763361 },
    { url = "https://files.pythonhosted.org/packages/04/24/b7721e4845c2f162d26f50521b825fb061bc0a5afcf9a386840f23ea19fa/PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:70b189594dbe54f75ab3a1acec5f1e3faa7e8cf2f1e08d9b561cb41b845f69d5", size = 759523 },
    { url = "https://files.pythonhosted.org/packages/2b/b2/e3234f59ba06559c6ff63c4e10baea10e5e7df868092bf9ab40e5b9c56b6/PyYAML-6.0.2-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:41e4e3953a79407c794916fa277a82531dd93aad34e29c2a514c2c0c5fe971cc", size = 726660 },
    { url = "https://files.pythonhosted.org/packages/fe/0f/25911a9f080464c59fab9027482f822b86bf0608957a5fcc6eaac85aa515/PyYAML-6.0.2-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:68ccc6023a3400877818152ad9a1033e3db8625d899c72eacb5a668902e4d652", size = 751597 },
    { url = "https://files.pythonhosted.org/packages/14/0d/e2c3b43bbce3cf6bd97c840b46088a3031085179e596d4929729d8d68270/PyYAML-6.0.2-cp313-cp313-win32.whl", hash = "sha256:bc2fa7c6b47d6bc618dd7fb02ef6fdedb1090ec036abab80d4681424b84c1183", size = 140527 },
    { url = "https://files.pythonhosted.org/packages/fa/de/02b54f42487e3d3c6efb3f89428677074ca7bf43aae402517bc7cca949f3/PyYAML-6.0.2-cp313-cp313-win_amd64.whl", hash = "sha256:8388ee1976c416731879ac16da0aff3f63b286ffdd57cdeb95f3f2e085687563", size = 156446 },
]

[[package]]
name = "referencing"
version = "0.36.2"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "attrs" },
    { name = "rpds-py" },
    { name = "typing-extensions", marker = "python_full_version < '3.13'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/2f/db/98b5c277be99dd18bfd91dd04e1b759cad18d1a338188c936e92f921c7e2/referencing-0.36.2.tar.gz", hash = "sha256:df2e89862cd09deabbdba16944cc3f10feb6b3e6f18e902f7cc25609a34775aa", size = 74744 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c1/b1/3baf80dc6d2b7bc27a95a67752d0208e410351e3feb4eb78de5f77454d8d/referencing-0.36.2-py3-none-any.whl", hash = "sha256:e8699adbbf8b5c7de96d8ffa0eb5c158b3beafce084968e2ea8bb08c6794dcd0", size = 26775 },
]

[[package]]
name = "rich"
version = "13.9.4"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "markdown-it-py" },
    { name = "pygments" },
    { name = "typing-extensions", marker = "python_full_version < '3.11'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/ab/3a/0316b28d0761c6734d6bc14e770d85506c986c85ffb239e688eeaab2c2bc/rich-13.9.4.tar.gz", hash = "sha256:439594978a49a09530cff7ebc4b5c7103ef57baf48d5ea3184f21d9a2befa098", size = 223149 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl", hash = "sha256:6049d5e6ec054bf2779ab3358186963bac2ea89175919d699e378b99738c2a90", size = 242424 },
]

[[package]]
name = "rpds-py"
version = "0.24.0"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/0b/b3/52b213298a0ba7097c7ea96bee95e1947aa84cc816d48cebb539770cdf41/rpds_py-0.24.0.tar.gz", hash = "sha256:772cc1b2cd963e7e17e6cc55fe0371fb9c704d63e44cacec7b9b7f523b78919e", size = 26863 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/6a/21/cbc43b220c9deb536b07fbd598c97d463bbb7afb788851891252fc920742/rpds_py-0.24.0-cp310-cp310-macosx_10_12_x86_64.whl", hash = "sha256:006f4342fe729a368c6df36578d7a348c7c716be1da0a1a0f86e3021f8e98724", size = 377531 },
    { url = "https://files.pythonhosted.org/packages/42/15/cc4b09ef160483e49c3aab3b56f3d375eadf19c87c48718fb0147e86a446/rpds_py-0.24.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:2d53747da70a4e4b17f559569d5f9506420966083a31c5fbd84e764461c4444b", size = 362273 },
    { url = "https://files.pythonhosted.org/packages/8c/a2/67718a188a88dbd5138d959bed6efe1cc7413a4caa8283bd46477ed0d1ad/rpds_py-0.24.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e8acd55bd5b071156bae57b555f5d33697998752673b9de554dd82f5b5352727", size = 388111 },
    { url = "https://files.pythonhosted.org/packages/e5/e6/cbf1d3163405ad5f4a1a6d23f80245f2204d0c743b18525f34982dec7f4d/rpds_py-0.24.0-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:7e80d375134ddb04231a53800503752093dbb65dad8dabacce2c84cccc78e964", size = 394447 },
    { url = "https://files.pythonhosted.org/packages/21/bb/4fe220ccc8a549b38b9e9cec66212dc3385a82a5ee9e37b54411cce4c898/rpds_py-0.24.0-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:60748789e028d2a46fc1c70750454f83c6bdd0d05db50f5ae83e2db500b34da5", size = 448028 },
    { url = "https://files.pythonhosted.org/packages/a5/41/d2d6e0fd774818c4cadb94185d30cf3768de1c2a9e0143fc8bc6ce59389e/rpds_py-0.24.0-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:6e1daf5bf6c2be39654beae83ee6b9a12347cb5aced9a29eecf12a2d25fff664", size = 447410 },
    { url = "https://files.pythonhosted.org/packages/a7/a7/6d04d438f53d8bb2356bb000bea9cf5c96a9315e405b577117e344cc7404/rpds_py-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1b221c2457d92a1fb3c97bee9095c874144d196f47c038462ae6e4a14436f7bc", size = 389531 },
    { url = "https://files.pythonhosted.org/packages/23/be/72e6df39bd7ca5a66799762bf54d8e702483fdad246585af96723109d486/rpds_py-0.24.0-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:66420986c9afff67ef0c5d1e4cdc2d0e5262f53ad11e4f90e5e22448df485bf0", size = 420099 },
    { url = "https://files.pythonhosted.org/packages/8c/c9/ca100cd4688ee0aa266197a5cb9f685231676dd7d573041ca53787b23f4e/rpds_py-0.24.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:43dba99f00f1d37b2a0265a259592d05fcc8e7c19d140fe51c6e6f16faabeb1f", size = 564950 },
    { url = "https://files.pythonhosted.org/packages/05/98/908cd95686d33b3ac8ac2e582d7ae38e2c3aa2c0377bf1f5663bafd1ffb2/rpds_py-0.24.0-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:a88c0d17d039333a41d9bf4616bd062f0bd7aa0edeb6cafe00a2fc2a804e944f", size = 591778 },
    { url = "https://files.pythonhosted.org/packages/7b/ac/e143726f1dd3215efcb974b50b03bd08a8a1556b404a0a7872af6d197e57/rpds_py-0.24.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:cc31e13ce212e14a539d430428cd365e74f8b2d534f8bc22dd4c9c55b277b875", size = 560421 },
    { url = "https://files.pythonhosted.org/packages/60/28/add1c1d2fcd5aa354f7225d036d4492261759a22d449cff14841ef36a514/rpds_py-0.24.0-cp310-cp310-win32.whl", hash = "sha256:fc2c1e1b00f88317d9de6b2c2b39b012ebbfe35fe5e7bef980fd2a91f6100a07", size = 222089 },
    { url = "https://files.pythonhosted.org/packages/b0/ac/81f8066c6de44c507caca488ba336ae30d35d57f61fe10578824d1a70196/rpds_py-0.24.0-cp310-cp310-win_amd64.whl", hash = "sha256:c0145295ca415668420ad142ee42189f78d27af806fcf1f32a18e51d47dd2052", size = 234622 },
    { url = "https://files.pythonhosted.org/packages/80/e6/c1458bbfb257448fdb2528071f1f4e19e26798ed5ef6d47d7aab0cb69661/rpds_py-0.24.0-cp311-cp311-macosx_10_12_x86_64.whl", hash = "sha256:2d3ee4615df36ab8eb16c2507b11e764dcc11fd350bbf4da16d09cda11fcedef", size = 377679 },
    { url = "https://files.pythonhosted.org/packages/dd/26/ea4181ef78f58b2c167548c6a833d7dc22408e5b3b181bda9dda440bb92d/rpds_py-0.24.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:e13ae74a8a3a0c2f22f450f773e35f893484fcfacb00bb4344a7e0f4f48e1f97", size = 362571 },
    { url = "https://files.pythonhosted.org/packages/56/fa/1ec54dd492c64c280a2249a047fc3369e2789dc474eac20445ebfc72934b/rpds_py-0.24.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:cf86f72d705fc2ef776bb7dd9e5fbba79d7e1f3e258bf9377f8204ad0fc1c51e", size = 388012 },
    { url = "https://files.pythonhosted.org/packages/3a/be/bad8b0e0f7e58ef4973bb75e91c472a7d51da1977ed43b09989264bf065c/rpds_py-0.24.0-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:c43583ea8517ed2e780a345dd9960896afc1327e8cf3ac8239c167530397440d", size = 394730 },
    { url = "https://files.pythonhosted.org/packages/35/56/ab417fc90c21826df048fc16e55316ac40876e4b790104ececcbce813d8f/rpds_py-0.24.0-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:4cd031e63bc5f05bdcda120646a0d32f6d729486d0067f09d79c8db5368f4586", size = 448264 },
    { url = "https://files.pythonhosted.org/packages/b6/75/4c63862d5c05408589196c8440a35a14ea4ae337fa70ded1f03638373f06/rpds_py-0.24.0-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:34d90ad8c045df9a4259c47d2e16a3f21fdb396665c94520dbfe8766e62187a4", size = 446813 },
    { url = "https://files.pythonhosted.org/packages/e7/0c/91cf17dffa9a38835869797a9f041056091ebba6a53963d3641207e3d467/rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e838bf2bb0b91ee67bf2b889a1a841e5ecac06dd7a2b1ef4e6151e2ce155c7ae", size = 389438 },
    { url = "https://files.pythonhosted.org/packages/1b/b0/60e6c72727c978276e02851819f3986bc40668f115be72c1bc4d922c950f/rpds_py-0.24.0-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:04ecf5c1ff4d589987b4d9882872f80ba13da7d42427234fce8f22efb43133bc", size = 420416 },
    { url = "https://files.pythonhosted.org/packages/a1/d7/f46f85b9f863fb59fd3c534b5c874c48bee86b19e93423b9da8784605415/rpds_py-0.24.0-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:630d3d8ea77eabd6cbcd2ea712e1c5cecb5b558d39547ac988351195db433f6c", size = 565236 },
    { url = "https://files.pythonhosted.org/packages/2a/d1/1467620ded6dd70afc45ec822cdf8dfe7139537780d1f3905de143deb6fd/rpds_py-0.24.0-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:ebcb786b9ff30b994d5969213a8430cbb984cdd7ea9fd6df06663194bd3c450c", size = 592016 },
    { url = "https://files.pythonhosted.org/packages/5d/13/fb1ded2e6adfaa0c0833106c42feb290973f665300f4facd5bf5d7891d9c/rpds_py-0.24.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:174e46569968ddbbeb8a806d9922f17cd2b524aa753b468f35b97ff9c19cb718", size = 560123 },
    { url = "https://files.pythonhosted.org/packages/1e/df/09fc1857ac7cc2eb16465a7199c314cbce7edde53c8ef21d615410d7335b/rpds_py-0.24.0-cp311-cp311-win32.whl", hash = "sha256:5ef877fa3bbfb40b388a5ae1cb00636a624690dcb9a29a65267054c9ea86d88a", size = 222256 },
    { url = "https://files.pythonhosted.org/packages/ff/25/939b40bc4d54bf910e5ee60fb5af99262c92458f4948239e8c06b0b750e7/rpds_py-0.24.0-cp311-cp311-win_amd64.whl", hash = "sha256:e274f62cbd274359eff63e5c7e7274c913e8e09620f6a57aae66744b3df046d6", size = 234718 },
    { url = "https://files.pythonhosted.org/packages/1a/e0/1c55f4a3be5f1ca1a4fd1f3ff1504a1478c1ed48d84de24574c4fa87e921/rpds_py-0.24.0-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:d8551e733626afec514b5d15befabea0dd70a343a9f23322860c4f16a9430205", size = 366945 },
    { url = "https://files.pythonhosted.org/packages/39/1b/a3501574fbf29118164314dbc800d568b8c1c7b3258b505360e8abb3902c/rpds_py-0.24.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:0e374c0ce0ca82e5b67cd61fb964077d40ec177dd2c4eda67dba130de09085c7", size = 351935 },
    { url = "https://files.pythonhosted.org/packages/dc/47/77d3d71c55f6a374edde29f1aca0b2e547325ed00a9da820cabbc9497d2b/rpds_py-0.24.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d69d003296df4840bd445a5d15fa5b6ff6ac40496f956a221c4d1f6f7b4bc4d9", size = 390817 },
    { url = "https://files.pythonhosted.org/packages/4e/ec/1e336ee27484379e19c7f9cc170f4217c608aee406d3ae3a2e45336bff36/rpds_py-0.24.0-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:8212ff58ac6dfde49946bea57474a386cca3f7706fc72c25b772b9ca4af6b79e", size = 401983 },
    { url = "https://files.pythonhosted.org/packages/07/f8/39b65cbc272c635eaea6d393c2ad1ccc81c39eca2db6723a0ca4b2108fce/rpds_py-0.24.0-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:528927e63a70b4d5f3f5ccc1fa988a35456eb5d15f804d276709c33fc2f19bda", size = 451719 },
    { url = "https://files.pythonhosted.org/packages/32/05/05c2b27dd9c30432f31738afed0300659cb9415db0ff7429b05dfb09bbde/rpds_py-0.24.0-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a824d2c7a703ba6daaca848f9c3d5cb93af0505be505de70e7e66829affd676e", size = 442546 },
    { url = "https://files.pythonhosted.org/packages/7d/e0/19383c8b5d509bd741532a47821c3e96acf4543d0832beba41b4434bcc49/rpds_py-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:44d51febb7a114293ffd56c6cf4736cb31cd68c0fddd6aa303ed09ea5a48e029", size = 393695 },
    { url = "https://files.pythonhosted.org/packages/9d/15/39f14e96d94981d0275715ae8ea564772237f3fa89bc3c21e24de934f2c7/rpds_py-0.24.0-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:3fab5f4a2c64a8fb64fc13b3d139848817a64d467dd6ed60dcdd6b479e7febc9", size = 427218 },
    { url = "https://files.pythonhosted.org/packages/22/b9/12da7124905a680f690da7a9de6f11de770b5e359f5649972f7181c8bf51/rpds_py-0.24.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:9be4f99bee42ac107870c61dfdb294d912bf81c3c6d45538aad7aecab468b6b7", size = 568062 },
    { url = "https://files.pythonhosted.org/packages/88/17/75229017a2143d915f6f803721a6d721eca24f2659c5718a538afa276b4f/rpds_py-0.24.0-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:564c96b6076a98215af52f55efa90d8419cc2ef45d99e314fddefe816bc24f91", size = 596262 },
    { url = "https://files.pythonhosted.org/packages/aa/64/8e8a1d8bd1b6b638d6acb6d41ab2cec7f2067a5b8b4c9175703875159a7c/rpds_py-0.24.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:75a810b7664c17f24bf2ffd7f92416c00ec84b49bb68e6a0d93e542406336b56", size = 564306 },
    { url = "https://files.pythonhosted.org/packages/68/1c/a7eac8d8ed8cb234a9b1064647824c387753343c3fab6ed7c83481ed0be7/rpds_py-0.24.0-cp312-cp312-win32.whl", hash = "sha256:f6016bd950be4dcd047b7475fdf55fb1e1f59fc7403f387be0e8123e4a576d30", size = 224281 },
    { url = "https://files.pythonhosted.org/packages/bb/46/b8b5424d1d21f2f2f3f2d468660085318d4f74a8df8289e3dd6ad224d488/rpds_py-0.24.0-cp312-cp312-win_amd64.whl", hash = "sha256:998c01b8e71cf051c28f5d6f1187abbdf5cf45fc0efce5da6c06447cba997034", size = 239719 },
    { url = "https://files.pythonhosted.org/packages/9d/c3/3607abc770395bc6d5a00cb66385a5479fb8cd7416ddef90393b17ef4340/rpds_py-0.24.0-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:3d2d8e4508e15fc05b31285c4b00ddf2e0eb94259c2dc896771966a163122a0c", size = 367072 },
    { url = "https://files.pythonhosted.org/packages/d8/35/8c7ee0fe465793e3af3298dc5a9f3013bd63e7a69df04ccfded8293a4982/rpds_py-0.24.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:0f00c16e089282ad68a3820fd0c831c35d3194b7cdc31d6e469511d9bffc535c", size = 351919 },
    { url = "https://files.pythonhosted.org/packages/91/d3/7e1b972501eb5466b9aca46a9c31bcbbdc3ea5a076e9ab33f4438c1d069d/rpds_py-0.24.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:951cc481c0c395c4a08639a469d53b7d4afa252529a085418b82a6b43c45c240", size = 390360 },
    { url = "https://files.pythonhosted.org/packages/a2/a8/ccabb50d3c91c26ad01f9b09a6a3b03e4502ce51a33867c38446df9f896b/rpds_py-0.24.0-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:c9ca89938dff18828a328af41ffdf3902405a19f4131c88e22e776a8e228c5a8", size = 400704 },
    { url = "https://files.pythonhosted.org/packages/53/ae/5fa5bf0f3bc6ce21b5ea88fc0ecd3a439e7cb09dd5f9ffb3dbe1b6894fc5/rpds_py-0.24.0-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ed0ef550042a8dbcd657dfb284a8ee00f0ba269d3f2286b0493b15a5694f9fe8", size = 450839 },
    { url = "https://files.pythonhosted.org/packages/e3/ac/c4e18b36d9938247e2b54f6a03746f3183ca20e1edd7d3654796867f5100/rpds_py-0.24.0-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:2b2356688e5d958c4d5cb964af865bea84db29971d3e563fb78e46e20fe1848b", size = 441494 },
    { url = "https://files.pythonhosted.org/packages/bf/08/b543969c12a8f44db6c0f08ced009abf8f519191ca6985509e7c44102e3c/rpds_py-0.24.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:78884d155fd15d9f64f5d6124b486f3d3f7fd7cd71a78e9670a0f6f6ca06fb2d", size = 393185 },
    { url = "https://files.pythonhosted.org/packages/da/7e/f6eb6a7042ce708f9dfc781832a86063cea8a125bbe451d663697b51944f/rpds_py-0.24.0-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:6a4a535013aeeef13c5532f802708cecae8d66c282babb5cd916379b72110cf7", size = 426168 },
    { url = "https://files.pythonhosted.org/packages/38/b0/6cd2bb0509ac0b51af4bb138e145b7c4c902bb4b724d6fd143689d6e0383/rpds_py-0.24.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:84e0566f15cf4d769dade9b366b7b87c959be472c92dffb70462dd0844d7cbad", size = 567622 },
    { url = "https://files.pythonhosted.org/packages/64/b0/c401f4f077547d98e8b4c2ec6526a80e7cb04f519d416430ec1421ee9e0b/rpds_py-0.24.0-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:823e74ab6fbaa028ec89615ff6acb409e90ff45580c45920d4dfdddb069f2120", size = 595435 },
    { url = "https://files.pythonhosted.org/packages/9f/ec/7993b6e803294c87b61c85bd63e11142ccfb2373cf88a61ec602abcbf9d6/rpds_py-0.24.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:c61a2cb0085c8783906b2f8b1f16a7e65777823c7f4d0a6aaffe26dc0d358dd9", size = 563762 },
    { url = "https://files.pythonhosted.org/packages/1f/29/4508003204cb2f461dc2b83dd85f8aa2b915bc98fe6046b9d50d4aa05401/rpds_py-0.24.0-cp313-cp313-win32.whl", hash = "sha256:60d9b630c8025b9458a9d114e3af579a2c54bd32df601c4581bd054e85258143", size = 223510 },
    { url = "https://files.pythonhosted.org/packages/f9/12/09e048d1814195e01f354155fb772fb0854bd3450b5f5a82224b3a319f0e/rpds_py-0.24.0-cp313-cp313-win_amd64.whl", hash = "sha256:6eea559077d29486c68218178ea946263b87f1c41ae7f996b1f30a983c476a5a", size = 239075 },
    { url = "https://files.pythonhosted.org/packages/d2/03/5027cde39bb2408d61e4dd0cf81f815949bb629932a6c8df1701d0257fc4/rpds_py-0.24.0-cp313-cp313t-macosx_10_12_x86_64.whl", hash = "sha256:d09dc82af2d3c17e7dd17120b202a79b578d79f2b5424bda209d9966efeed114", size = 362974 },
    { url = "https://files.pythonhosted.org/packages/bf/10/24d374a2131b1ffafb783e436e770e42dfdb74b69a2cd25eba8c8b29d861/rpds_py-0.24.0-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:5fc13b44de6419d1e7a7e592a4885b323fbc2f46e1f22151e3a8ed3b8b920405", size = 348730 },
    { url = "https://files.pythonhosted.org/packages/7a/d1/1ef88d0516d46cd8df12e5916966dbf716d5ec79b265eda56ba1b173398c/rpds_py-0.24.0-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c347a20d79cedc0a7bd51c4d4b7dbc613ca4e65a756b5c3e57ec84bd43505b47", size = 387627 },
    { url = "https://files.pythonhosted.org/packages/4e/35/07339051b8b901ecefd449ebf8e5522e92bcb95e1078818cbfd9db8e573c/rpds_py-0.24.0-cp313-cp313t-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:20f2712bd1cc26a3cc16c5a1bfee9ed1abc33d4cdf1aabd297fe0eb724df4272", size = 394094 },
    { url = "https://files.pythonhosted.org/packages/dc/62/ee89ece19e0ba322b08734e95441952062391065c157bbd4f8802316b4f1/rpds_py-0.24.0-cp313-cp313t-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:aad911555286884be1e427ef0dc0ba3929e6821cbeca2194b13dc415a462c7fd", size = 449639 },
    { url = "https://files.pythonhosted.org/packages/15/24/b30e9f9e71baa0b9dada3a4ab43d567c6b04a36d1cb531045f7a8a0a7439/rpds_py-0.24.0-cp313-cp313t-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:0aeb3329c1721c43c58cae274d7d2ca85c1690d89485d9c63a006cb79a85771a", size = 438584 },
    { url = "https://files.pythonhosted.org/packages/28/d9/49f7b8f3b4147db13961e19d5e30077cd0854ccc08487026d2cb2142aa4a/rpds_py-0.24.0-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2a0f156e9509cee987283abd2296ec816225145a13ed0391df8f71bf1d789e2d", size = 391047 },
    { url = "https://files.pythonhosted.org/packages/49/b0/e66918d0972c33a259ba3cd7b7ff10ed8bd91dbcfcbec6367b21f026db75/rpds_py-0.24.0-cp313-cp313t-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:aa6800adc8204ce898c8a424303969b7aa6a5e4ad2789c13f8648739830323b7", size = 418085 },
    { url = "https://files.pythonhosted.org/packages/e1/6b/99ed7ea0a94c7ae5520a21be77a82306aac9e4e715d4435076ead07d05c6/rpds_py-0.24.0-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:a18fc371e900a21d7392517c6f60fe859e802547309e94313cd8181ad9db004d", size = 564498 },
    { url = "https://files.pythonhosted.org/packages/28/26/1cacfee6b800e6fb5f91acecc2e52f17dbf8b0796a7c984b4568b6d70e38/rpds_py-0.24.0-cp313-cp313t-musllinux_1_2_i686.whl", hash = "sha256:9168764133fd919f8dcca2ead66de0105f4ef5659cbb4fa044f7014bed9a1797", size = 590202 },
    { url = "https://files.pythonhosted.org/packages/a9/9e/57bd2f9fba04a37cef673f9a66b11ca8c43ccdd50d386c455cd4380fe461/rpds_py-0.24.0-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:5f6e3cec44ba05ee5cbdebe92d052f69b63ae792e7d05f1020ac5e964394080c", size = 561771 },
    { url = "https://files.pythonhosted.org/packages/9f/cf/b719120f375ab970d1c297dbf8de1e3c9edd26fe92c0ed7178dd94b45992/rpds_py-0.24.0-cp313-cp313t-win32.whl", hash = "sha256:8ebc7e65ca4b111d928b669713865f021b7773350eeac4a31d3e70144297baba", size = 221195 },
    { url = "https://files.pythonhosted.org/packages/2d/e5/22865285789f3412ad0c3d7ec4dc0a3e86483b794be8a5d9ed5a19390900/rpds_py-0.24.0-cp313-cp313t-win_amd64.whl", hash = "sha256:675269d407a257b8c00a6b58205b72eec8231656506c56fd429d924ca00bb350", size = 237354 },
    { url = "https://files.pythonhosted.org/packages/99/48/11dae46d0c7f7e156ca0971a83f89c510af0316cd5d42c771b7cef945f0c/rpds_py-0.24.0-pp310-pypy310_pp73-macosx_10_12_x86_64.whl", hash = "sha256:619ca56a5468f933d940e1bf431c6f4e13bef8e688698b067ae68eb4f9b30e3a", size = 378224 },
    { url = "https://files.pythonhosted.org/packages/33/18/e8398d255369e35d312942f3bb8ecaff013c44968904891be2ab63b3aa94/rpds_py-0.24.0-pp310-pypy310_pp73-macosx_11_0_arm64.whl", hash = "sha256:4b28e5122829181de1898c2c97f81c0b3246d49f585f22743a1246420bb8d399", size = 363252 },
    { url = "https://files.pythonhosted.org/packages/17/39/dd73ba691f4df3e6834bf982de214086ac3359ab3ac035adfb30041570e3/rpds_py-0.24.0-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e8e5ab32cf9eb3647450bc74eb201b27c185d3857276162c101c0f8c6374e098", size = 388871 },
    { url = "https://files.pythonhosted.org/packages/2f/2e/da0530b25cabd0feca2a759b899d2df325069a94281eeea8ac44c6cfeff7/rpds_py-0.24.0-pp310-pypy310_pp73-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:208b3a70a98cf3710e97cabdc308a51cd4f28aa6e7bb11de3d56cd8b74bab98d", size = 394766 },
    { url = "https://files.pythonhosted.org/packages/4c/ee/dd1c5040a431beb40fad4a5d7868acf343444b0bc43e627c71df2506538b/rpds_py-0.24.0-pp310-pypy310_pp73-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:bbc4362e06f950c62cad3d4abf1191021b2ffaf0b31ac230fbf0526453eee75e", size = 448712 },
    { url = "https://files.pythonhosted.org/packages/f5/ec/6b93ffbb686be948e4d91ec76f4e6757f8551034b2a8176dd848103a1e34/rpds_py-0.24.0-pp310-pypy310_pp73-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:ebea2821cdb5f9fef44933617be76185b80150632736f3d76e54829ab4a3b4d1", size = 447150 },
    { url = "https://files.pythonhosted.org/packages/55/d5/a1c23760adad85b432df074ced6f910dd28f222b8c60aeace5aeb9a6654e/rpds_py-0.24.0-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b9a4df06c35465ef4d81799999bba810c68d29972bf1c31db61bfdb81dd9d5bb", size = 390662 },
    { url = "https://files.pythonhosted.org/packages/a5/f3/419cb1f9bfbd3a48c256528c156e00f3349e3edce5ad50cbc141e71f66a5/rpds_py-0.24.0-pp310-pypy310_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:d3aa13bdf38630da298f2e0d77aca967b200b8cc1473ea05248f6c5e9c9bdb44", size = 421351 },
    { url = "https://files.pythonhosted.org/packages/98/8e/62d1a55078e5ede0b3b09f35e751fa35924a34a0d44d7c760743383cd54a/rpds_py-0.24.0-pp310-pypy310_pp73-musllinux_1_2_aarch64.whl", hash = "sha256:041f00419e1da7a03c46042453598479f45be3d787eb837af382bfc169c0db33", size = 566074 },
    { url = "https://files.pythonhosted.org/packages/fc/69/b7d1003166d78685da032b3c4ff1599fa536a3cfe6e5ce2da87c9c431906/rpds_py-0.24.0-pp310-pypy310_pp73-musllinux_1_2_i686.whl", hash = "sha256:d8754d872a5dfc3c5bf9c0e059e8107451364a30d9fd50f1f1a85c4fb9481164", size = 592398 },
    { url = "https://files.pythonhosted.org/packages/ea/a8/1c98bc99338c37faadd28dd667d336df7409d77b4da999506a0b6b1c0aa2/rpds_py-0.24.0-pp310-pypy310_pp73-musllinux_1_2_x86_64.whl", hash = "sha256:896c41007931217a343eff197c34513c154267636c8056fb409eafd494c3dcdc", size = 561114 },
    { url = "https://files.pythonhosted.org/packages/2b/41/65c91443685a4c7b5f1dd271beadc4a3e063d57c3269221548dd9416e15c/rpds_py-0.24.0-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:92558d37d872e808944c3c96d0423b8604879a3d1c86fdad508d7ed91ea547d5", size = 235548 },
    { url = "https://files.pythonhosted.org/packages/65/53/40bcc246a8354530d51a26d2b5b9afd1deacfb0d79e67295cc74df362f52/rpds_py-0.24.0-pp311-pypy311_pp73-macosx_10_12_x86_64.whl", hash = "sha256:f9e0057a509e096e47c87f753136c9b10d7a91842d8042c2ee6866899a717c0d", size = 378386 },
    { url = "https://files.pythonhosted.org/packages/80/b0/5ea97dd2f53e3618560aa1f9674e896e63dff95a9b796879a201bc4c1f00/rpds_py-0.24.0-pp311-pypy311_pp73-macosx_11_0_arm64.whl", hash = "sha256:d6e109a454412ab82979c5b1b3aee0604eca4bbf9a02693bb9df027af2bfa91a", size = 363440 },
    { url = "https://files.pythonhosted.org/packages/57/9d/259b6eada6f747cdd60c9a5eb3efab15f6704c182547149926c38e5bd0d5/rpds_py-0.24.0-pp311-pypy311_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fc1c892b1ec1f8cbd5da8de287577b455e388d9c328ad592eabbdcb6fc93bee5", size = 388816 },
    { url = "https://files.pythonhosted.org/packages/94/c1/faafc7183712f89f4b7620c3c15979ada13df137d35ef3011ae83e93b005/rpds_py-0.24.0-pp311-pypy311_pp73-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:9c39438c55983d48f4bb3487734d040e22dad200dab22c41e331cee145e7a50d", size = 395058 },
    { url = "https://files.pythonhosted.org/packages/6c/96/d7fa9d2a7b7604a61da201cc0306a355006254942093779d7121c64700ce/rpds_py-0.24.0-pp311-pypy311_pp73-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:9d7e8ce990ae17dda686f7e82fd41a055c668e13ddcf058e7fb5e9da20b57793", size = 448692 },
    { url = "https://files.pythonhosted.org/packages/96/37/a3146c6eebc65d6d8c96cc5ffdcdb6af2987412c789004213227fbe52467/rpds_py-0.24.0-pp311-pypy311_pp73-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:9ea7f4174d2e4194289cb0c4e172d83e79a6404297ff95f2875cf9ac9bced8ba", size = 446462 },
    { url = "https://files.pythonhosted.org/packages/1f/13/6481dfd9ac7de43acdaaa416e3a7da40bc4bb8f5c6ca85e794100aa54596/rpds_py-0.24.0-pp311-pypy311_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bb2954155bb8f63bb19d56d80e5e5320b61d71084617ed89efedb861a684baea", size = 390460 },
    { url = "https://files.pythonhosted.org/packages/61/e1/37e36bce65e109543cc4ff8d23206908649023549604fa2e7fbeba5342f7/rpds_py-0.24.0-pp311-pypy311_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:04f2b712a2206e13800a8136b07aaedc23af3facab84918e7aa89e4be0260032", size = 421609 },
    { url = "https://files.pythonhosted.org/packages/20/dd/1f1a923d6cd798b8582176aca8a0784676f1a0449fb6f07fce6ac1cdbfb6/rpds_py-0.24.0-pp311-pypy311_pp73-musllinux_1_2_aarch64.whl", hash = "sha256:eda5c1e2a715a4cbbca2d6d304988460942551e4e5e3b7457b50943cd741626d", size = 565818 },
    { url = "https://files.pythonhosted.org/packages/56/ec/d8da6df6a1eb3a418944a17b1cb38dd430b9e5a2e972eafd2b06f10c7c46/rpds_py-0.24.0-pp311-pypy311_pp73-musllinux_1_2_i686.whl", hash = "sha256:9abc80fe8c1f87218db116016de575a7998ab1629078c90840e8d11ab423ee25", size = 592627 },
    { url = "https://files.pythonhosted.org/packages/b3/14/c492b9c7d5dd133e13f211ddea6bb9870f99e4f73932f11aa00bc09a9be9/rpds_py-0.24.0-pp311-pypy311_pp73-musllinux_1_2_x86_64.whl", hash = "sha256:6a727fd083009bc83eb83d6950f0c32b3c94c8b80a9b667c87f4bd1274ca30ba", size = 560885 },
]

[[package]]
name = "shellingham"
version = "1.5.4"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/58/15/8b3609fd3830ef7b27b655beb4b4e9c62313a4e8da8c676e142cc210d58e/shellingham-1.5.4.tar.gz", hash = "sha256:8dbca0739d487e5bd35ab3ca4b36e11c4078f3a234bfce294b0a0291363404de", size = 10310 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl", hash = "sha256:7ecfff8f2fd72616f7481040475a65b2bf8af90a56c89140852d1120324e8686", size = 9755 },
]

[[package]]
name = "sniffio"
version = "1.3.1"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/a2/87/a6771e1546d97e7e041b6ae58d80074f81b7d5121207425c964ddf5cfdbd/sniffio-1.3.1.tar.gz", hash = "sha256:f4324edc670a0f49750a81b895f35c3adb843cca46f0530f79fc1babb23789dc", size = 20372 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl", hash = "sha256:2f6da418d1f1e0fddd844478f41680e794e6051915791a034ff65e5f100525a2", size = 10235 },
]

[[package]]
name = "sse-starlette"
version = "2.2.1"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "anyio" },
    { name = "starlette" },
]
sdist = { url = "https://files.pythonhosted.org/packages/71/a4/80d2a11af59fe75b48230846989e93979c892d3a20016b42bb44edb9e398/sse_starlette-2.2.1.tar.gz", hash = "sha256:54470d5f19274aeed6b2d473430b08b4b379ea851d953b11d7f1c4a2c118b419", size = 17376 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d9/e0/5b8bd393f27f4a62461c5cf2479c75a2cc2ffa330976f9f00f5f6e4f50eb/sse_starlette-2.2.1-py3-none-any.whl", hash = "sha256:6410a3d3ba0c89e7675d4c273a301d64649c03a5ef1ca101f10b47f895fd0e99", size = 10120 },
]

[[package]]
name = "starlette"
version = "0.46.1"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "anyio" },
]
sdist = { url = "https://files.pythonhosted.org/packages/04/1b/52b27f2e13ceedc79a908e29eac426a63465a1a01248e5f24aa36a62aeb3/starlette-0.46.1.tar.gz", hash = "sha256:3c88d58ee4bd1bb807c0d1acb381838afc7752f9ddaec81bbe4383611d833230", size = 2580102 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/a0/4b/528ccf7a982216885a1ff4908e886b8fb5f19862d1962f56a3fce2435a70/starlette-0.46.1-py3-none-any.whl", hash = "sha256:77c74ed9d2720138b25875133f3a2dae6d854af2ec37dceb56aef370c1d8a227", size = 71995 },
]

[[package]]
name = "typer"
version = "0.15.2"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "click" },
    { name = "rich" },
    { name = "shellingham" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/8b/6f/3991f0f1c7fcb2df31aef28e0594d8d54b05393a0e4e34c65e475c2a5d41/typer-0.15.2.tar.gz", hash = "sha256:ab2fab47533a813c49fe1f16b1a370fd5819099c00b119e0633df65f22144ba5", size = 100711 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7f/fc/5b29fea8cee020515ca82cc68e3b8e1e34bb19a3535ad854cac9257b414c/typer-0.15.2-py3-none-any.whl", hash = "sha256:46a499c6107d645a9c13f7ee46c5d5096cae6f5fc57dd11eccbbb9ae3e44ddfc", size = 45061 },
]

[[package]]
name = "typing-extensions"
version = "4.13.0"
source = { registry = "https://pypi.org/simple/" }
sdist = { url = "https://files.pythonhosted.org/packages/0e/3e/b00a62db91a83fff600de219b6ea9908e6918664899a2d85db222f4fbf19/typing_extensions-4.13.0.tar.gz", hash = "sha256:0a4ac55a5820789d87e297727d229866c9650f6521b64206413c4fbada24d95b", size = 106520 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e0/86/39b65d676ec5732de17b7e3c476e45bb80ec64eb50737a8dce1a4178aba1/typing_extensions-4.13.0-py3-none-any.whl", hash = "sha256:c8dd92cc0d6425a97c18fbb9d1954e5ff92c1ca881a309c45f06ebc0b79058e5", size = 45683 },
]

[[package]]
name = "typing-inspection"
version = "0.4.0"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/82/5c/e6082df02e215b846b4b8c0b887a64d7d08ffaba30605502639d44c06b82/typing_inspection-0.4.0.tar.gz", hash = "sha256:9765c87de36671694a67904bf2c96e395be9c6439bb6c87b5142569dcdd65122", size = 76222 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/31/08/aa4fdfb71f7de5176385bd9e90852eaf6b5d622735020ad600f2bab54385/typing_inspection-0.4.0-py3-none-any.whl", hash = "sha256:50e72559fcd2a6367a19f7a7e610e6afcb9fac940c650290eed893d61386832f", size = 14125 },
]

[[package]]
name = "uvicorn"
version = "0.34.0"
source = { registry = "https://pypi.org/simple/" }
dependencies = [
    { name = "click" },
    { name = "h11" },
    { name = "typing-extensions", marker = "python_full_version < '3.11'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/4b/4d/938bd85e5bf2edeec766267a5015ad969730bb91e31b44021dfe8b22df6c/uvicorn-0.34.0.tar.gz", hash = "sha256:404051050cd7e905de2c9a7e61790943440b3416f49cb409f965d9dcd0fa73e9", size = 76568 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/61/14/33a3a1352cfa71812a3a21e8c9bfb83f60b0011f5e36f2b1399d51928209/uvicorn-0.34.0-py3-none-any.whl", hash = "sha256:023dc038422502fa28a09c7a30bf2b6991512da7dcdb8fd35fe57cfc154126f4", size = 62315 },
]



================================================
File: .env.local
================================================
WORKSPACE_FOLDER=D:/Coding/Python_Projects/MYMCPSERVER
VAULT_PATH=D:/Coding/Python_Projects/MYMCPSERVER/docs-obsidian
PYTHONPATH=D:/Coding/Python_Projects/MYMCPSERVER/src
LOGS_PATH=D:/Coding/Python_Projects/MYMCPSERVER/logs
MCP_TRANSPORT=stdio
MCP_LOG_LEVEL=DEBUG
MCP_ENABLE_RICH_LOGGING=1
PYTHONUNBUFFERED=1


================================================
File: .python-version
================================================
3.13




================================================
File: src/run_server.py
================================================
#!/usr/bin/env python3
"""MCP System Runner.

This script provides a convenient way to start various components of the MCP
microservices architecture as described in the system documentation.

Usage:
    python run_server.py --mode [full|proxy|core|tool] --transport [http|stdio|sse]
"""

import argparse
import asyncio
import logging
import os
import subprocess
import sys
from pathlib import Path

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent))

from mymcpserver import main as mcp_main


def setup_logging() -> None:
    """Configure logging for the runner script."""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[logging.StreamHandler(), logging.FileHandler("mcp_runner.log")],
    )


def parse_args() -> argparse.Namespace:
    """Parse command-line arguments.

    Returns:
        argparse.Namespace: Parsed arguments
    """
    parser = argparse.ArgumentParser(description="MCP System Runner")
    parser.add_argument(
        "--mode",
        choices=["full", "proxy", "core", "tool"],
        default="full",
        help="Component(s) to start (default: full)",
    )
    parser.add_argument(
        "--transport",
        choices=["http", "stdio", "sse", "websocket"],
        default="http",
        help="Transport mechanism (default: http)",
    )
    parser.add_argument(
        "--host", default="127.0.0.1", help="Host to bind to (default: 127.0.0.1)"
    )
    parser.add_argument(
        "--port", type=int, default=8000, help="Port to bind to (default: 8000)"
    )
    parser.add_argument(
        "--tool-server",
        choices=["python", "typescript", "all"],
        default="all",
        help="Tool server to start (default: all)",
    )
    parser.add_argument(
        "--log-level",
        choices=["debug", "info", "warning", "error"],
        default="info",
        help="Logging level (default: info)",
    )

    return parser.parse_args()


async def run_core_process(transport: str, log_level: str, host: str, port: int) -> int:
    """Run the MCP Core Layer as a separate process.

    Args:
        transport: Transport mechanism
        log_level: Logging level
        host: Host to bind to
        port: Port to bind to

    Returns:
        int: Exit code
    """
    # Prepare environment variables
    env = os.environ.copy()
    env["MCP_TRANSPORT"] = transport
    env["MCP_LOG_LEVEL"] = log_level
    env["MCP_HOST"] = host
    env["MCP_PORT"] = str(port)
    env["MCP_COMPONENTS"] = "core"

    logging.info("Starting MCP Core Layer")

    # If using stdio transport, run directly
    if transport == "stdio":
        logging.info("MCP Core Layer running with stdio transport")

        # Process stdio messages
        # In a real implementation, this would be a loop to read from stdin
        # and write to stdout, communicating with the Core Layer's API

        return 0
    else:
        # Otherwise run via mcp_main
        return mcp_main()


async def run_proxy_process(
    transport: str, log_level: str, host: str, port: int
) -> int:
    """Run the MCP Proxy Connection Server as a separate process.

    Args:
        transport: Transport mechanism
        log_level: Logging level
        host: Host to bind to
        port: Port to bind to

    Returns:
        int: Exit code
    """
    # Prepare environment variables
    env = os.environ.copy()
    env["MCP_TRANSPORT"] = transport
    env["MCP_LOG_LEVEL"] = log_level
    env["MCP_HOST"] = host
    env["MCP_PORT"] = str(port)
    env["MCP_COMPONENTS"] = "proxy"

    logging.info("Starting MCP Proxy Connection Server")

    # If we're using stdio, we need to spawn the Core Layer process
    if transport == "stdio":
        # Import the actual module
        try:
            from mcp_proxy.__main__ import async_main

            # Run the proxy server asynchronously
            return await async_main()
        except ImportError as e:
            logging.error(f"Failed to import proxy modules: {e}")
            return 1
    else:
        # Otherwise run via mcp_main
        return mcp_main()


async def run_python_tool_server(host: str, port: int, log_level: str) -> int:
    """Run the Python Tool Server as a separate process.

    Args:
        host: Host to bind to
        port: Port to bind to
        log_level: Logging level

    Returns:
        int: Exit code
    """
    try:
        # Prepare environment variables
        env = os.environ.copy()
        env["HOST"] = host
        env["PORT"] = str(port)
        env["LOG_LEVEL"] = log_level.upper()

        # Construct path to the Python Tool Server
        tool_server_dir = Path(__file__).parent / "tool_servers" / "python_tool_server"
        server_script = tool_server_dir / "server.py"

        if not server_script.exists():
            logging.error(f"Python Tool Server script not found at {server_script}")
            return 1

        logging.info(f"Starting Python Tool Server at {host}:{port}")

        # Run the server as a subprocess
        process = subprocess.Popen(
            [sys.executable, str(server_script)],
            env=env,
            cwd=str(tool_server_dir),
        )

        # Wait for the process
        return_code = process.wait()
        return return_code
    except Exception as e:
        logging.error(f"Error running Python Tool Server: {e}")
        return 1


def run_mcp_server(args: argparse.Namespace) -> int:
    """Run the MCP server components based on command-line arguments.

    Args:
        args: Command-line arguments

    Returns:
        int: Exit code
    """
    try:
        if args.mode == "full":
            # Run all components
            logging.info("Starting MCP in full mode")

            # In full mode with stdio, we spawn the Proxy which in turn spawns Core
            if args.transport == "stdio":
                return asyncio.run(
                    run_proxy_process(
                        args.transport, args.log_level, args.host, args.port
                    )
                )
            else:
                # Start MCP main components
                mcp_process = mcp_main()

                # Also start tool servers if in full mode
                if args.tool_server == "python" or args.tool_server == "all":
                    logging.info("Starting Python Tool Server")
                    # Use a different port for the tool server
                    tool_port = args.port + 1
                    asyncio.run(
                        run_python_tool_server(args.host, tool_port, args.log_level)
                    )

                return mcp_process

        elif args.mode == "proxy":
            # Run only the proxy server
            return asyncio.run(
                run_proxy_process(args.transport, args.log_level, args.host, args.port)
            )

        elif args.mode == "core":
            # Run only the core server
            return asyncio.run(
                run_core_process(args.transport, args.log_level, args.host, args.port)
            )

        elif args.mode == "tool":
            # Run tool server(s)
            if args.tool_server == "python" or args.tool_server == "all":
                logging.info("Starting Python Tool Server")
                return asyncio.run(
                    run_python_tool_server(args.host, args.port, args.log_level)
                )

            if args.tool_server == "typescript" or args.tool_server == "all":
                logging.info("Starting TypeScript Tool Server")
                # This would start the TypeScript tool server
                # For now, just log since we haven't implemented it yet
                logging.warning("TypeScript Tool Server not yet implemented")

            return 0
        else:
            logging.error(f"Invalid mode: {args.mode}")
            return 1
    except KeyboardInterrupt:
        logging.info("Runner interrupted by user")
        return 0
    except Exception as e:
        logging.error(f"Error running MCP components: {e}")
        return 1


def main() -> int:
    """Main entry point.

    Returns:
        int: Exit code
    """
    setup_logging()
    args = parse_args()

    try:
        return run_mcp_server(args)
    except KeyboardInterrupt:
        logging.info("Runner interrupted by user")
        return 0
    except Exception as e:
        logging.error(f"Error running MCP components: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())



================================================
File: src/archive/mymcpserver/__init__.py
================================================
"""MCP Server package for Obsidian integration.

This package provides a FastMCP server that exposes Obsidian vault functionality
through the Model Context Protocol (MCP).
"""

from __future__ import annotations

__all__ = ["main", "server", "logger"]
__version__ = "0.1.0"

# Standard library imports
import asyncio
import logging
import os
from pathlib import Path

# Local imports
from . import server
from .logging_config import setup_logging

# Initialize logging at package level
logs_path = os.getenv("LOGS_PATH", "logs")
logs_path = os.path.expandvars(logs_path)

# Determine if we should enable stdout logging based on transport
# We disable stdout when using stdio transport to avoid interference
transport_mode = os.getenv("MCP_TRANSPORT", "stdio")
enable_stdout = transport_mode != "stdio"

# Set up logging with resolved path
setup_logging(
    log_level=os.getenv("MCP_LOG_LEVEL", "INFO"),
    enable_stdout=enable_stdout,
    cursor_format=True,
    log_dir=Path(logs_path),
)

# Create package-level logger
logger = logging.getLogger("mymcpserver")
logger.debug("Package initialization complete")


def main():
    """Main entry point for the package."""
    try:
        logger.info("Starting MCP server from package entry point")
        asyncio.run(server.main())
    except KeyboardInterrupt:
        logger.info("Server shutdown requested")
    except Exception as e:
        logger.error(f"Error running server: {e}", exc_info=True)
        raise



================================================
File: src/archive/mymcpserver/__main__.py
================================================
"""Entry point for the MCP server.

This module provides the main entry point when running the package as a module.
"""

import sys

# Import package components - logging will be initialized by __init__.py
from mymcpserver import logger
from mymcpserver.server import cli

if __name__ == "__main__":
    logger.info("Starting MCP server as module")
    try:
        cli()
        logger.info("MCP server completed successfully")
    except KeyboardInterrupt:
        logger.info("Server shutdown requested")
    except Exception as e:
        logger.error(f"Error running MCP server: {e}", exc_info=True)
        sys.exit(1)



================================================
File: src/archive/mymcpserver/config.py
================================================
"""Configuration management for the MCP server.

This module provides configuration handling and validation for the MCP server.
"""

from __future__ import annotations

__all__ = ["Config"]
__version__ = "0.1.0"

# Standard library imports
import logging
from pathlib import Path

# Third-party imports
from pydantic import BaseModel, Field, validator

# Get logger for this module
logger = logging.getLogger("mymcpserver.config")


class Config(BaseModel):
    """Main configuration class for the MCP server.

    Attributes:
        vault_path (Path): Path to the Obsidian vault
        log_level (str): Logging level for the server
    """

    vault_path: Path = Field(default=Path("docs-obsidian"))
    log_level: str = Field(default="INFO")

    @validator("vault_path")
    def validate_vault_path(cls, v: Path) -> Path:
        """Validate that the vault path exists and is a directory.

        Args:
            v (Path): The vault path to validate

        Returns:
            Path: The validated path

        Raises:
            ValueError: If path doesn't exist or isn't a directory
        """
        path = Path(v)
        if not path.exists():
            logger.error(f"Vault path does not exist: {path}")
            raise ValueError(f"Vault path does not exist: {path}")
        if not path.is_dir():
            logger.error(f"Vault path is not a directory: {path}")
            raise ValueError(f"Vault path is not a directory: {path}")

        logger.info(f"Validated vault path: {path}")
        return path

    @validator("log_level")
    def validate_log_level(cls, v: str) -> str:
        """Validate that the log level is valid.

        Args:
            v (str): The log level to validate

        Returns:
            str: The validated log level

        Raises:
            ValueError: If log level is not valid
        """
        valid_levels = {"DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"}
        if v.upper() not in valid_levels:
            logger.error(f"Invalid log level: {v}")
            raise ValueError(
                f"Invalid log level. Must be one of: {', '.join(valid_levels)}"
            )

        logger.info(f"Using log level: {v.upper()}")
        return v.upper()

    class Config:
        """Pydantic config class."""

        arbitrary_types_allowed = True

    def __init__(self, **data):
        """Initialize Config with logging."""
        logger.debug("Initializing configuration")
        super().__init__(**data)
        logger.info("Configuration initialized successfully")



================================================
File: src/archive/mymcpserver/logging_config.py
================================================
"""Centralized logging configuration for MYMCPSERVER.

This module provides a consistent logging setup across all components of the application.
Supports both file-based logging and stdout for Cursor's stdio Transport.
"""

from __future__ import annotations

__all__ = ["setup_logging"]
__version__ = "0.1.0"

# Standard library imports
import logging
import logging.handlers
import os
import sys
from pathlib import Path
from typing import Optional


def setup_logging(
    log_level: str = "INFO",
    log_dir: Optional[Path] = None,
    log_filename: str = "mymcpserver.log",
    enable_stdout: bool = True,
    cursor_format: bool = False,
) -> None:
    """Set up logging configuration for the application.

    Args:
        log_level: The logging level to use (default: INFO)
        log_dir: Directory to store log files (default: logs/ in project root)
        log_filename: Name of the log file (default: mymcpserver.log)
        enable_stdout: Whether to enable console output (default: True)
        cursor_format: Whether to use Cursor-specific format for stdio Transport (default: False)
    """
    # Create logs directory if it doesn't exist
    if log_dir is None:
        # Default to logs/ in the project root or src directory
        logs_path = os.getenv("LOGS_PATH", "logs")
        # Make sure to expand any variables in the path
        logs_path = os.path.expandvars(logs_path)
        log_dir = Path(logs_path)

    # Ensure log_dir is properly resolved without variable names
    try:
        log_dir = log_dir.resolve()
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file = log_dir / log_filename
    except Exception as e:
        fallback_dir = Path.cwd() / "logs"
        fallback_dir.mkdir(parents=True, exist_ok=True)
        log_file = fallback_dir / log_filename
        print(
            f"Warning: Could not use specified log directory: {e}. Using {fallback_dir} instead.",
            file=sys.stderr,
        )

    # Configure root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level)

    # Clear any existing handlers
    root_logger.handlers.clear()

    # Configure logging formats
    file_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    date_format = "%Y-%m-%d %H:%M:%S"

    # Use simpler format for Cursor stdio Transport
    stdout_format = "%(levelname)s: %(message)s" if cursor_format else file_format

    # Set up file handler with rotation
    try:
        file_handler = logging.handlers.RotatingFileHandler(
            log_file,
            maxBytes=10 * 1024 * 1024,  # 10MB
            backupCount=5,
            encoding="utf-8",
        )
        file_handler.setFormatter(logging.Formatter(file_format, date_format))
        root_logger.addHandler(file_handler)
    except Exception as e:
        print(f"Warning: Could not set up file logging: {e}", file=sys.stderr)

    # Set up stdout handler if enabled
    if enable_stdout:
        stdout_handler = logging.StreamHandler(sys.stdout)
        stdout_handler.setFormatter(logging.Formatter(stdout_format, date_format))
        root_logger.addHandler(stdout_handler)

    # Log initial setup
    root_logger.info(f"Logging initialized: {log_file}")
    root_logger.info(f"Log level: {log_level}")
    root_logger.info(f"Stdout enabled: {enable_stdout}")
    root_logger.info(f"Cursor format: {cursor_format}")



================================================
File: src/archive/mymcpserver/server.py
================================================
"""MCP Server implementation for Obsidian integration.

This module provides a FastMCP server that exposes Obsidian vault functionality
through the Model Context Protocol (MCP). Supports both stdio and SSE transports.
"""

from __future__ import annotations

__all__ = ["ObsidianTools", "mcp"]
__version__ = "0.1.0"

# Standard library imports
import argparse
import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, TypeVar

# Third-party imports
from dotenv import load_dotenv
from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel, Field, field_validator

# Handle imports for both module and direct script usage
try:
    from .logging_config import setup_logging
except ImportError:
    # Add parent directory to path for direct script usage
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from mymcpserver.logging_config import setup_logging

T = TypeVar("T")

# Load environment variables first
env_path = Path(__file__).parent.parent.parent / ".env.local"
load_dotenv(env_path)

# Check transport mode - must disable stdout logging when using stdio transport
transport_mode = os.getenv("MCP_TRANSPORT", "stdio")
enable_stdout = transport_mode != "stdio"

# Initialize logging with resolved path
logs_path = os.getenv("LOGS_PATH", "logs")
logs_path = os.path.expandvars(logs_path)
setup_logging(
    log_level=os.getenv("MCP_LOG_LEVEL", "DEBUG"),
    enable_stdout=enable_stdout,
    cursor_format=True,
    log_dir=Path(logs_path),
)

# Create logger for this module
logger = logging.getLogger("mymcpserver.server")
if not env_path.exists():
    logger.warning(f"No .env file found at {env_path}")

# Log transport mode decision
logger.info(f"Using transport mode: {transport_mode}, stdout logging: {enable_stdout}")

# Validate required environment variables
required_vars = ["VAULT_PATH", "PYTHONPATH", "LOGS_PATH"]
missing_vars = [var for var in required_vars if not os.getenv(var)]
if missing_vars:
    raise ValueError(
        f"Missing required environment variables: {', '.join(missing_vars)}"
    )

# Create MCP server instance at module level with stdio transport
mcp = FastMCP("ObsidianMCP", transport=os.getenv("MCP_TRANSPORT", "stdio"))


class Note(BaseModel):
    """Represents a note in the vault."""

    title: str = Field(..., description="The title of the note")
    content: str = Field(..., description="The content of the note")
    created_at: datetime = Field(
        default_factory=datetime.now, description="When the note was created"
    )
    updated_at: datetime = Field(
        default_factory=datetime.now, description="When the note was last updated"
    )
    tags: Set[str] = Field(
        default_factory=set, description="Tags associated with the note"
    )

    model_config = {"json_encoders": {datetime: lambda v: v.isoformat()}}


class ServerConfig(BaseModel):
    """Configuration for the MCP server transport."""

    host: str = Field(default="localhost")
    port: int = Field(default=8000)
    transport: str = Field(default="stdio")

    @field_validator("transport")
    def validate_transport(cls, v: str) -> str:
        """Validate transport type."""
        if v not in ["stdio", "sse"]:
            raise ValueError(f"Invalid transport type: {v}. Must be 'stdio' or 'sse'")
        return v


class ObsidianConfig(BaseModel):
    """Configuration model for Obsidian integration."""

    vault_path: Path = Field(
        default_factory=lambda: Path(
            os.path.expandvars(os.environ.get("VAULT_PATH", "docs-obsidian"))
        ).resolve()
    )
    excluded_folders: Set[str] = Field(
        default_factory=lambda: {".git", ".obsidian", "node_modules"}
    )
    supported_extensions: Set[str] = Field(default_factory=lambda: {"md", "markdown"})
    template_folder: str = Field(default="templates")

    @field_validator("vault_path")
    def validate_vault_path(cls, v: Path) -> Path:
        """Validate that the vault path exists and is a directory."""
        path = Path(v)
        if not path.exists():
            logger.warning(f"Vault path does not exist: {path}")
            path.mkdir(parents=True, exist_ok=True)
            logger.info(f"Created vault directory: {path}")
        elif not path.is_dir():
            raise ValueError(f"Vault path is not a directory: {path}")

        logger.info(f"Using vault path: {path}")
        return path


class ObsidianTools:
    """Tools for interacting with Obsidian vault."""

    def __init__(self, config: ObsidianConfig):
        self.config = config
        self.logger = logging.getLogger("mymcpserver.server")
        self.notes: Dict[str, Note] = {}
        self._load_notes()

    def _load_notes(self) -> None:
        """Load notes from the vault."""
        try:
            vault_path = self.config.vault_path
            self.logger.debug(f"Loading notes from vault: {vault_path}")

            if not vault_path.exists():
                self.logger.warning(f"Vault path does not exist: {vault_path}")
                return

            for file in vault_path.rglob("*"):
                if file.suffix[1:] in self.config.supported_extensions:
                    relative_path = str(file.relative_to(vault_path))
                    if not any(
                        excluded in relative_path
                        for excluded in self.config.excluded_folders
                    ):
                        try:
                            with open(file, "r", encoding="utf-8") as f:
                                content = f.read()
                                self.notes[relative_path] = Note(
                                    title=file.stem,
                                    content=content,
                                    created_at=datetime.fromtimestamp(
                                        file.stat().st_ctime
                                    ),
                                    updated_at=datetime.fromtimestamp(
                                        file.stat().st_mtime
                                    ),
                                )
                                self.logger.debug(f"Loaded note: {relative_path}")
                        except Exception as e:
                            self.logger.error(f"Error loading note {file}: {e}")
                            continue

            self.logger.info(f"Loaded {len(self.notes)} notes from vault")
        except Exception as e:
            self.logger.error(f"Error loading notes: {e}", exc_info=True)

    async def get_notes(self, paths: List[str]) -> Dict[str, Any]:
        """Get contents of specified notes."""
        try:
            results = {}
            for path in paths:
                if path in self.notes:
                    results[path] = self.notes[path].model_dump()
                else:
                    note_path = self.config.vault_path / path
                    if note_path.exists() and note_path.is_file():
                        content = await self._read_file(note_path)
                        note = Note(title=note_path.stem, content=content)
                        self.notes[path] = note
                        results[path] = note.model_dump()
            return {
                "content": [{"type": "text", "text": json.dumps(results, indent=2)}]
            }
        except Exception as e:
            self.logger.error(f"Error reading notes: {e}")
            return {"error": str(e)}

    async def search_notes(self, query: str) -> Dict[str, Any]:
        """Search for notes by name or content."""
        try:
            results = []
            for path, note in self.notes.items():
                if (
                    query.lower() in note.title.lower()
                    or query.lower() in note.content.lower()
                ):
                    results.append(note.model_dump())
            return {
                "content": [{"type": "text", "text": json.dumps(results, indent=2)}]
            }
        except Exception as e:
            self.logger.error(f"Error searching notes: {e}")
            return {"error": str(e)}

    async def save_note(
        self, path: str, content: str, tags: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Save a note to the vault."""
        try:
            note_path = self.config.vault_path / path
            note_path.parent.mkdir(parents=True, exist_ok=True)

            with open(note_path, "w", encoding="utf-8") as f:
                f.write(content)

            note = Note(title=note_path.stem, content=content, tags=set(tags or []))
            self.notes[path] = note

            return {
                "content": [
                    {"type": "text", "text": f"Note saved successfully: {path}"}
                ]
            }
        except Exception as e:
            self.logger.error(f"Error saving note: {e}")
            return {"error": str(e)}

    async def _read_file(self, path: Path) -> str:
        """Read file contents."""
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            self.logger.error(f"Error reading file {path}: {e}")
            raise


# Initialize Obsidian tools
config = ObsidianConfig()
tools = ObsidianTools(config)


@mcp.tool()
async def read_notes(paths: List[str]) -> Dict[str, Any]:
    """Read the contents of multiple notes."""
    return await tools.get_notes(paths)


@mcp.tool()
async def search_notes(query: str) -> Dict[str, Any]:
    """Search for notes by name or content."""
    return await tools.search_notes(query)


@mcp.tool()
async def save_note(
    path: str, content: str, tags: Optional[List[str]] = None
) -> Dict[str, Any]:
    """Save a note to the vault."""
    return await tools.save_note(path, content, tags)


async def main(server_config: Optional[ServerConfig] = None) -> None:
    """Main entry point for the MCP server.

    Args:
        server_config: Optional server configuration for transport settings.
                      If None, defaults will be used.
    """
    try:
        # Initialize server configuration
        if server_config is None:
            server_config = ServerConfig()

        logger.info("Starting MCP server")

        # Configure server based on transport
        if server_config.transport == "stdio":
            logger.info("Using stdio transport")
            os.environ["MCP_TRANSPORT"] = "stdio"
        else:  # SSE transport
            logger.info(
                f"Using SSE transport on {server_config.host}:{server_config.port}"
            )
            os.environ["MCP_TRANSPORT"] = "sse"
            os.environ["MCP_HOST"] = server_config.host
            os.environ["MCP_PORT"] = str(server_config.port)

        # Start the server
        logger.info("Starting server...")

        # Run the server with proper error handling
        try:
            mcp.run()
            logger.info("MCP server started successfully")
        except KeyboardInterrupt:
            logger.info("Server shutdown requested")
        except Exception as e:
            logger.error(f"Server error during run: {e}", exc_info=True)
            raise

    except Exception as e:
        logger.error(f"Failed to start MCP server: {e}", exc_info=True)
        raise


def cli() -> None:
    """Command-line interface for the MCP server."""
    parser = argparse.ArgumentParser(
        description="Start the MCP server with specified transport"
    )
    parser.add_argument(
        "--transport",
        choices=["stdio", "sse"],
        default="stdio",
        help="Transport type (stdio or sse)",
    )
    parser.add_argument(
        "--host",
        default="localhost",
        help="Host for SSE transport (default: localhost)",
    )
    parser.add_argument(
        "--port", type=int, default=8000, help="Port for SSE transport (default: 8000)"
    )

    args = parser.parse_args()
    config = ServerConfig(transport=args.transport, host=args.host, port=args.port)

    try:
        asyncio.run(main(config))
    except KeyboardInterrupt:
        logger.info("Server shutdown requested")
    except Exception as e:
        logger.error(f"Server error: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    cli()



================================================
File: src/archive/mymcpserver_old/__init__.py
================================================
"""MCP Server package for Obsidian integration.

This package provides a FastMCP server that exposes Obsidian vault functionality
through the Model Context Protocol (MCP).
"""

from __future__ import annotations

__all__ = ["main", "server", "logger"]
__version__ = "0.1.0"

# Standard library imports
import asyncio
import logging
import os
from pathlib import Path

# Local imports
from . import server
from .logging_config import setup_logging

# Initialize logging at package level
logs_path = os.getenv("LOGS_PATH", "logs")
logs_path = os.path.expandvars(logs_path)

# Determine if we should enable stdout logging based on transport
# We disable stdout when using stdio transport to avoid interference
transport_mode = os.getenv("MCP_TRANSPORT", "stdio")
enable_stdout = transport_mode != "stdio"

# Set up logging with resolved path
setup_logging(
    log_level=os.getenv("MCP_LOG_LEVEL", "INFO"),
    enable_stdout=enable_stdout,
    cursor_format=True,
    log_dir=Path(logs_path),
)

# Create package-level logger
logger = logging.getLogger("mymcpserver")
logger.debug("Package initialization complete")


def main():
    """Main entry point for the package."""
    try:
        logger.info("Starting MCP server from package entry point")
        asyncio.run(server.main())
    except KeyboardInterrupt:
        logger.info("Server shutdown requested")
    except Exception as e:
        logger.error(f"Error running server: {e}", exc_info=True)
        raise



================================================
File: src/archive/mymcpserver_old/__main__.py
================================================
"""Entry point for the MCP server.

This module provides the main entry point when running the package as a module.
"""

import sys

# Import package components - logging will be initialized by __init__.py
from mymcpserver import logger
from mymcpserver.server import cli

if __name__ == "__main__":
    logger.info("Starting MCP server as module")
    try:
        cli()
        logger.info("MCP server completed successfully")
    except KeyboardInterrupt:
        logger.info("Server shutdown requested")
    except Exception as e:
        logger.error(f"Error running MCP server: {e}", exc_info=True)
        sys.exit(1)



================================================
File: src/archive/mymcpserver_old/logging_config.py
================================================
"""Centralized logging configuration for MYMCPSERVER.

This module provides a consistent logging setup across all components of the application.
Supports both file-based logging and stdout for Cursor's stdio Transport.
"""

from __future__ import annotations

__all__ = ["setup_logging"]
__version__ = "0.1.0"

# Standard library imports
import logging
import logging.handlers
import os
import sys
from pathlib import Path
from typing import Optional


def setup_logging(
    log_level: str = "INFO",
    log_dir: Optional[Path] = None,
    log_filename: str = "mymcpserver.log",
    enable_stdout: bool = True,
    cursor_format: bool = False,
) -> None:
    """Set up logging configuration for the application.

    Args:
        log_level: The logging level to use (default: INFO)
        log_dir: Directory to store log files (default: logs/ in project root)
        log_filename: Name of the log file (default: mymcpserver.log)
        enable_stdout: Whether to enable console output (default: True)
        cursor_format: Whether to use Cursor-specific format for stdio Transport (default: False)
    """
    # Create logs directory if it doesn't exist
    if log_dir is None:
        # Default to logs/ in the project root or src directory
        logs_path = os.getenv("LOGS_PATH", "logs")
        # Make sure to expand any variables in the path
        logs_path = os.path.expandvars(logs_path)
        log_dir = Path(logs_path)

    # Ensure log_dir is properly resolved without variable names
    try:
        log_dir = log_dir.resolve()
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file = log_dir / log_filename
    except Exception as e:
        fallback_dir = Path.cwd() / "logs"
        fallback_dir.mkdir(parents=True, exist_ok=True)
        log_file = fallback_dir / log_filename
        print(
            f"Warning: Could not use specified log directory: {e}. Using {fallback_dir} instead.",
            file=sys.stderr,
        )

    # Configure root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level)

    # Clear any existing handlers
    root_logger.handlers.clear()

    # Configure logging formats
    file_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    date_format = "%Y-%m-%d %H:%M:%S"

    # Use simpler format for Cursor stdio Transport
    stdout_format = "%(levelname)s: %(message)s" if cursor_format else file_format

    # Set up file handler with rotation
    try:
        file_handler = logging.handlers.RotatingFileHandler(
            log_file,
            maxBytes=10 * 1024 * 1024,  # 10MB
            backupCount=5,
            encoding="utf-8",
        )
        file_handler.setFormatter(logging.Formatter(file_format, date_format))
        root_logger.addHandler(file_handler)
    except Exception as e:
        print(f"Warning: Could not set up file logging: {e}", file=sys.stderr)

    # Set up stdout handler if enabled
    if enable_stdout:
        stdout_handler = logging.StreamHandler(sys.stdout)
        stdout_handler.setFormatter(logging.Formatter(stdout_format, date_format))
        root_logger.addHandler(stdout_handler)

    # Log initial setup
    root_logger.info(f"Logging initialized: {log_file}")
    root_logger.info(f"Log level: {log_level}")
    root_logger.info(f"Stdout enabled: {enable_stdout}")
    root_logger.info(f"Cursor format: {cursor_format}")



================================================
File: src/archive/mymcpserver_old/server.py
================================================
"""MCP Server implementation for Obsidian integration.

This module provides a FastMCP server that exposes Obsidian vault functionality
through the Model Context Protocol (MCP). Supports both stdio and SSE transports.
"""

from __future__ import annotations

__all__ = ["ObsidianTools", "mcp"]
__version__ = "0.1.0"

# Standard library imports
import argparse
import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, TypeVar

# Third-party imports
from dotenv import load_dotenv
from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel, Field, field_validator

# Handle imports for both module and direct script usage
try:
    from .logging_config import setup_logging
except ImportError:
    # Add parent directory to path for direct script usage
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from mymcpserver.logging_config import setup_logging

T = TypeVar("T")

# Load environment variables first
env_path = Path(__file__).parent.parent.parent / ".env.local"
load_dotenv(env_path)

# Check transport mode - must disable stdout logging when using stdio transport
transport_mode = os.getenv("MCP_TRANSPORT", "stdio")
enable_stdout = transport_mode != "stdio"

# Initialize logging with resolved path
logs_path = os.getenv("LOGS_PATH", "logs")
logs_path = os.path.expandvars(logs_path)
setup_logging(
    log_level=os.getenv("MCP_LOG_LEVEL", "DEBUG"),
    enable_stdout=enable_stdout,
    cursor_format=True,
    log_dir=Path(logs_path),
)

# Create logger for this module
logger = logging.getLogger("mymcpserver.server")
if not env_path.exists():
    logger.warning(f"No .env file found at {env_path}")

# Log transport mode decision
logger.info(f"Using transport mode: {transport_mode}, stdout logging: {enable_stdout}")

# Validate required environment variables
required_vars = ["VAULT_PATH", "PYTHONPATH", "LOGS_PATH"]
missing_vars = [var for var in required_vars if not os.getenv(var)]
if missing_vars:
    raise ValueError(
        f"Missing required environment variables: {', '.join(missing_vars)}"
    )

# Create MCP server instance at module level with stdio transport
mcp = FastMCP("ObsidianMCP", transport=os.getenv("MCP_TRANSPORT", "stdio"))


class Note(BaseModel):
    """Represents a note in the vault."""

    title: str = Field(..., description="The title of the note")
    content: str = Field(..., description="The content of the note")
    created_at: datetime = Field(
        default_factory=datetime.now, description="When the note was created"
    )
    updated_at: datetime = Field(
        default_factory=datetime.now, description="When the note was last updated"
    )
    tags: Set[str] = Field(
        default_factory=set, description="Tags associated with the note"
    )

    model_config = {"json_encoders": {datetime: lambda v: v.isoformat()}}


class ServerConfig(BaseModel):
    """Configuration for the MCP server transport."""

    host: str = Field(default="localhost")
    port: int = Field(default=8000)
    transport: str = Field(default="stdio")

    @field_validator("transport")
    def validate_transport(cls, v: str) -> str:
        """Validate transport type."""
        if v not in ["stdio", "sse"]:
            raise ValueError(f"Invalid transport type: {v}. Must be 'stdio' or 'sse'")
        return v


class ObsidianConfig(BaseModel):
    """Configuration model for Obsidian integration."""

    vault_path: Path = Field(
        default_factory=lambda: Path(
            os.path.expandvars(os.environ.get("VAULT_PATH", "docs-obsidian"))
        ).resolve()
    )
    excluded_folders: Set[str] = Field(
        default_factory=lambda: {".git", ".obsidian", "node_modules"}
    )
    supported_extensions: Set[str] = Field(default_factory=lambda: {"md", "markdown"})
    template_folder: str = Field(default="templates")

    @field_validator("vault_path")
    def validate_vault_path(cls, v: Path) -> Path:
        """Validate that the vault path exists and is a directory."""
        path = Path(v)
        if not path.exists():
            logger.warning(f"Vault path does not exist: {path}")
            path.mkdir(parents=True, exist_ok=True)
            logger.info(f"Created vault directory: {path}")
        elif not path.is_dir():
            raise ValueError(f"Vault path is not a directory: {path}")

        logger.info(f"Using vault path: {path}")
        return path


class ObsidianTools:
    """Tools for interacting with Obsidian vault."""

    def __init__(self, config: ObsidianConfig):
        self.config = config
        self.logger = logging.getLogger("mymcpserver.server")
        self.notes: Dict[str, Note] = {}
        self._load_notes()

    def _load_notes(self) -> None:
        """Load notes from the vault."""
        try:
            vault_path = self.config.vault_path
            self.logger.debug(f"Loading notes from vault: {vault_path}")

            if not vault_path.exists():
                self.logger.warning(f"Vault path does not exist: {vault_path}")
                return

            for file in vault_path.rglob("*"):
                if file.suffix[1:] in self.config.supported_extensions:
                    relative_path = str(file.relative_to(vault_path))
                    if not any(
                        excluded in relative_path
                        for excluded in self.config.excluded_folders
                    ):
                        try:
                            with open(file, "r", encoding="utf-8") as f:
                                content = f.read()
                                self.notes[relative_path] = Note(
                                    title=file.stem,
                                    content=content,
                                    created_at=datetime.fromtimestamp(
                                        file.stat().st_ctime
                                    ),
                                    updated_at=datetime.fromtimestamp(
                                        file.stat().st_mtime
                                    ),
                                )
                                self.logger.debug(f"Loaded note: {relative_path}")
                        except Exception as e:
                            self.logger.error(f"Error loading note {file}: {e}")
                            continue

            self.logger.info(f"Loaded {len(self.notes)} notes from vault")
        except Exception as e:
            self.logger.error(f"Error loading notes: {e}", exc_info=True)

    async def get_notes(self, paths: List[str]) -> Dict[str, Any]:
        """Get contents of specified notes."""
        try:
            results = {}
            for path in paths:
                if path in self.notes:
                    results[path] = self.notes[path].model_dump()
                else:
                    note_path = self.config.vault_path / path
                    if note_path.exists() and note_path.is_file():
                        content = await self._read_file(note_path)
                        note = Note(title=note_path.stem, content=content)
                        self.notes[path] = note
                        results[path] = note.model_dump()
            return {
                "content": [{"type": "text", "text": json.dumps(results, indent=2)}]
            }
        except Exception as e:
            self.logger.error(f"Error reading notes: {e}")
            return {"error": str(e)}

    async def search_notes(self, query: str) -> Dict[str, Any]:
        """Search for notes by name or content."""
        try:
            results = []
            for path, note in self.notes.items():
                if (
                    query.lower() in note.title.lower()
                    or query.lower() in note.content.lower()
                ):
                    results.append(note.model_dump())
            return {
                "content": [{"type": "text", "text": json.dumps(results, indent=2)}]
            }
        except Exception as e:
            self.logger.error(f"Error searching notes: {e}")
            return {"error": str(e)}

    async def save_note(
        self, path: str, content: str, tags: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Save a note to the vault."""
        try:
            note_path = self.config.vault_path / path
            note_path.parent.mkdir(parents=True, exist_ok=True)

            with open(note_path, "w", encoding="utf-8") as f:
                f.write(content)

            note = Note(title=note_path.stem, content=content, tags=set(tags or []))
            self.notes[path] = note

            return {
                "content": [
                    {"type": "text", "text": f"Note saved successfully: {path}"}
                ]
            }
        except Exception as e:
            self.logger.error(f"Error saving note: {e}")
            return {"error": str(e)}

    async def _read_file(self, path: Path) -> str:
        """Read file contents."""
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            self.logger.error(f"Error reading file {path}: {e}")
            raise


# Initialize Obsidian tools
config = ObsidianConfig()
tools = ObsidianTools(config)


@mcp.tool()
async def read_notes(paths: List[str]) -> Dict[str, Any]:
    """Read the contents of multiple notes."""
    return await tools.get_notes(paths)


@mcp.tool()
async def search_notes(query: str) -> Dict[str, Any]:
    """Search for notes by name or content."""
    return await tools.search_notes(query)


@mcp.tool()
async def save_note(
    path: str, content: str, tags: Optional[List[str]] = None
) -> Dict[str, Any]:
    """Save a note to the vault."""
    return await tools.save_note(path, content, tags)


async def main(server_config: Optional[ServerConfig] = None) -> None:
    """Main entry point for the MCP server.

    Args:
        server_config: Optional server configuration for transport settings.
                      If None, defaults will be used.
    """
    try:
        # Initialize server configuration
        if server_config is None:
            server_config = ServerConfig()

        logger.info("Starting MCP server")

        # Configure server based on transport
        if server_config.transport == "stdio":
            logger.info("Using stdio transport")
            os.environ["MCP_TRANSPORT"] = "stdio"
        else:  # SSE transport
            logger.info(
                f"Using SSE transport on {server_config.host}:{server_config.port}"
            )
            os.environ["MCP_TRANSPORT"] = "sse"
            os.environ["MCP_HOST"] = server_config.host
            os.environ["MCP_PORT"] = str(server_config.port)

        # Start the server
        logger.info("Starting server...")

        # Run the server with proper error handling
        try:
            mcp.run()
            logger.info("MCP server started successfully")
        except KeyboardInterrupt:
            logger.info("Server shutdown requested")
        except Exception as e:
            logger.error(f"Server error during run: {e}", exc_info=True)
            raise

    except Exception as e:
        logger.error(f"Failed to start MCP server: {e}", exc_info=True)
        raise


def cli() -> None:
    """Command-line interface for the MCP server."""
    parser = argparse.ArgumentParser(
        description="Start the MCP server with specified transport"
    )
    parser.add_argument(
        "--transport",
        choices=["stdio", "sse"],
        default="stdio",
        help="Transport type (stdio or sse)",
    )
    parser.add_argument(
        "--host",
        default="localhost",
        help="Host for SSE transport (default: localhost)",
    )
    parser.add_argument(
        "--port", type=int, default=8000, help="Port for SSE transport (default: 8000)"
    )

    args = parser.parse_args()
    config = ServerConfig(transport=args.transport, host=args.host, port=args.port)

    try:
        asyncio.run(main(config))
    except KeyboardInterrupt:
        logger.info("Server shutdown requested")
    except Exception as e:
        logger.error(f"Server error: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    cli()



================================================
File: src/mcp_core/__init__.py
================================================
"""MCP Core Layer."""

from .config.config import CoreConfig, get_core_config
from .errors import (
    AdapterError,
    AuthenticationError,
    ConfigurationError,
    MCPError,
    ToolError,
    TransportError,
    ValidationError,
)
from .health import (
    CoreHealth,
    HealthCheck,
    HealthStatus,
    SystemHealth,
    ToolServerHealth,
)
from .logger.logger import StructuredLogger, log_execution_time

__version__ = "1.0.0"

# Create default logger instance
logger = StructuredLogger("mcp_core")

__all__ = [
    "CoreConfig",
    "get_core_config",
    "MCPError",
    "ConfigurationError",
    "TransportError",
    "ToolError",
    "AdapterError",
    "ValidationError",
    "AuthenticationError",
    "StructuredLogger",
    "log_execution_time",
    "HealthStatus",
    "HealthCheck",
    "SystemHealth",
    "CoreHealth",
    "ToolServerHealth",
    "logger",
]



================================================
File: src/mcp_core/app.py
================================================
"""MCP Core application entry point."""

import os
from contextlib import asynccontextmanager

from fastapi import FastAPI

from .adapters.python_adapter import PythonAdapter
from .adapters.ts_adapter import TypeScriptAdapter
from .config import get_core_config
from .health import CoreHealth, SystemHealth
from .logger import logger
from .registry import ToolRegistry
from .router import Router
from .routes import router as tools_router


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifecycle manager."""
    # Load configuration
    config = get_core_config()

    # Initialize components
    registry = ToolRegistry()
    router = Router(registry)
    health_checker = SystemHealth([CoreHealth()])

    # Register dummy adapters for testing
    # In a real implementation, these would be loaded from configuration
    # or discovered dynamically

    # Python adapter example
    python_adapter = PythonAdapter(
        module_path="mcp_core.adapters.testing.python_tool",
        function_name="execute_tool",
        load_module=False,  # Don't load immediately as this is just a dummy
    )
    registry.register_tool(
        tool_name="python-example",
        adapter=python_adapter,
        version="1.0.0",
        description="Example Python tool",
        tags=["example", "python"],
    )

    # TypeScript adapter example
    ts_adapter = TypeScriptAdapter(
        server_path=os.path.join(
            os.path.dirname(__file__), "adapters", "testing", "ts-tools"
        ),
        tool_name="typescript-example",
        server_port=3001,
    )
    registry.register_tool(
        tool_name="typescript-example",
        adapter=ts_adapter,
        version="1.0.0",
        description="Example TypeScript tool",
        tags=["example", "typescript"],
    )

    # Store in app state
    app.state.config = config
    app.state.registry = registry
    app.state.registry_router = (
        router  # This is the router that will be used by the API routes
    )
    app.state.health = health_checker

    logger.info("MCP Core starting up")

    try:
        # Initialize adapters
        await python_adapter.initialize()
        await ts_adapter.initialize()
        yield
    finally:
        # Perform cleanup
        await registry.shutdown()
        logger.info("MCP Core shutting down")


# Create FastAPI application
app = FastAPI(
    title="MCP Core",
    description="Model Context Protocol Core Layer",
    version="1.0.0",
    lifespan=lifespan,
)

# Include routers
app.include_router(tools_router, prefix="/api/v1")



================================================
File: src/mcp_core/errors.py
================================================
from typing import Dict, Optional


class MCPError(Exception):
    """Base error for MCP system."""

    def __init__(self, code: str, message: str, details: Optional[Dict] = None):
        self.code = code
        self.message = message
        self.details = details or {}
        super().__init__(message)


class ConfigurationError(MCPError):
    """Configuration-related errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__("CONFIG_ERROR", message, details)


class TransportError(MCPError):
    """Transport layer errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__("TRANSPORT_ERROR", message, details)


class ToolError(MCPError):
    """Tool-related errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__("TOOL_ERROR", message, details)


class AdapterError(MCPError):
    """Adapter-related errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__("ADAPTER_ERROR", message, details)


class CircuitBreakerError(AdapterError):
    """Circuit breaker related errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(message, details)
        self.code = "CIRCUIT_BREAKER_ERROR"


class ValidationError(MCPError):
    """Validation-related errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__("VALIDATION_ERROR", message, details)


class AuthenticationError(MCPError):
    """Authentication-related errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__("AUTH_ERROR", message, details)



================================================
File: src/mcp_core/health.py
================================================
import time
from abc import ABC, abstractmethod
from enum import Enum
from typing import Dict, List

from .logger import logger


class HealthStatus(Enum):
    """Health status enumeration."""

    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"


class HealthCheck(ABC):
    """Base health check interface."""

    @abstractmethod
    async def check_health(self) -> Dict:
        """Perform health check."""
        pass


class SystemHealth(HealthCheck):
    """System-wide health monitoring."""

    def __init__(self, components: List[HealthCheck]):
        self.components = components
        self.start_time = time.time()

    async def check_health(self) -> Dict:
        """Check health of all components."""
        status = HealthStatus.HEALTHY
        results = {}

        for component in self.components:
            try:
                component_health = await component.check_health()
                results[component.__class__.__name__] = component_health

                if component_health["status"] == HealthStatus.UNHEALTHY:
                    status = HealthStatus.UNHEALTHY
                elif (
                    component_health["status"] == HealthStatus.DEGRADED
                    and status != HealthStatus.UNHEALTHY
                ):
                    status = HealthStatus.DEGRADED
            except Exception as e:
                logger.error(
                    "Health check failed",
                    component=component.__class__.__name__,
                    error=str(e),
                )
                results[component.__class__.__name__] = {
                    "status": HealthStatus.UNHEALTHY,
                    "error": str(e),
                }
                status = HealthStatus.UNHEALTHY

        return {
            "status": status,
            "uptime": time.time() - self.start_time,
            "components": results,
        }


class CoreHealth(HealthCheck):
    """MCP Core health check."""

    async def check_health(self) -> Dict:
        """Check core component health."""
        try:
            # Check critical services
            await self.check_database()
            await self.check_cache()

            return {
                "status": HealthStatus.HEALTHY,
                "details": {"database": "connected", "cache": "connected"},
            }
        except Exception as e:
            logger.error("Core health check failed", error=str(e))
            return {"status": HealthStatus.UNHEALTHY, "error": str(e)}

    async def check_database(self):
        """Check database connection."""
        # Implement database health check
        pass

    async def check_cache(self):
        """Check cache connection."""
        # Implement cache health check
        pass


class ToolServerHealth(HealthCheck):
    """Tool server health check."""

    async def check_health(self) -> Dict:
        """Check tool server health."""
        try:
            # Check tool availability
            tools = await self.check_tools()

            return {
                "status": HealthStatus.HEALTHY,
                "details": {"active_tools": len(tools), "tools": tools},
            }
        except Exception as e:
            logger.error("Tool server health check failed", error=str(e))
            return {"status": HealthStatus.UNHEALTHY, "error": str(e)}

    async def check_tools(self) -> List[str]:
        """Check available tools."""
        # Implement tool availability check
        return []



================================================
File: src/mcp_core/registry.py
================================================
"""Tool registry for MCP Core.

This module provides the central registry for managing tool registrations and versions.
"""

import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Set

from .adapters.base_adapter import BaseAdapter
from .adapters.circuit_breaker import CircuitBreaker
from .errors import AdapterError, CircuitBreakerError
from .logger import logger


@dataclass
class ToolMetadata:
    """Metadata for a registered tool."""

    tool_name: str
    adapter_type: str  # Type of adapter (e.g., python, typescript)
    version: str
    description: str = ""
    created_at: float = field(default_factory=time.time)
    updated_at: float = field(default_factory=time.time)
    is_active: bool = True
    tags: Set[str] = field(default_factory=set)
    circuit_breaker_enabled: bool = True
    circuit_breaker_threshold: int = 5
    recovery_timeout: float = 30.0
    health_check_interval: float = 60.0
    metadata: Dict[str, Any] = field(default_factory=dict)


class ToolRegistry:
    """Registry for MCP tools.

    This registry manages tool registrations, provides version control,
    and handles adapter selection.
    """

    def __init__(self):
        """Initialize the tool registry."""
        self.tools: Dict[
            str, Dict[str, BaseAdapter]
        ] = {}  # tool_name -> version -> adapter
        self.metadata: Dict[
            str, Dict[str, ToolMetadata]
        ] = {}  # tool_name -> version -> metadata
        self.circuit_breakers: Dict[
            str, CircuitBreaker
        ] = {}  # tool_name:version -> circuit breaker
        self.latest_versions: Dict[str, str] = {}  # tool_name -> latest version

    def register_tool(
        self,
        tool_name: str,
        adapter: BaseAdapter,
        version: str,
        metadata: Optional[Dict[str, Any]] = None,
        make_latest: bool = True,
        **kwargs,
    ) -> None:
        """Register a tool with the registry.

        Args:
            tool_name: Name of the tool
            adapter: Adapter instance for the tool
            version: Tool version
            metadata: Additional metadata for the tool
            make_latest: Whether to make this the latest version
            **kwargs: Additional metadata fields

        Raises:
            AdapterError: If the tool already exists with the same version
        """
        # Check if tool exists with this version
        if tool_name in self.tools and version in self.tools[tool_name]:
            raise AdapterError(f"Tool {tool_name} v{version} already registered")

        # Initialize tool entry if needed
        if tool_name not in self.tools:
            self.tools[tool_name] = {}
            self.metadata[tool_name] = {}

        # Register the adapter
        self.tools[tool_name][version] = adapter

        # Create circuit breaker
        circuit_name = f"{tool_name}:{version}"
        failure_threshold = kwargs.get("circuit_breaker_threshold", 5)
        recovery_timeout = kwargs.get("recovery_timeout", 30.0)

        self.circuit_breakers[circuit_name] = CircuitBreaker(
            name=circuit_name,
            failure_threshold=failure_threshold,
            recovery_timeout=recovery_timeout,
        )

        # Store metadata
        tool_metadata = ToolMetadata(
            tool_name=tool_name,
            adapter_type=adapter.__class__.__name__,
            version=version,
            description=kwargs.get("description", ""),
            tags=set(kwargs.get("tags", [])),
            circuit_breaker_enabled=kwargs.get("circuit_breaker_enabled", True),
            circuit_breaker_threshold=failure_threshold,
            recovery_timeout=recovery_timeout,
            health_check_interval=kwargs.get("health_check_interval", 60.0),
            metadata=metadata or {},
        )

        self.metadata[tool_name][version] = tool_metadata

        # Update latest version if requested
        if make_latest or tool_name not in self.latest_versions:
            self.latest_versions[tool_name] = version

        logger.info(
            f"Registered tool {tool_name} v{version}",
            tool=tool_name,
            version=version,
            adapter=adapter.__class__.__name__,
        )

    def get_tool(self, tool_name: str, version: Optional[str] = None) -> BaseAdapter:
        """Get a tool adapter by name and version.

        Args:
            tool_name: Name of the tool
            version: Tool version (uses latest if None)

        Returns:
            BaseAdapter: Tool adapter

        Raises:
            AdapterError: If tool not found
        """
        if tool_name not in self.tools:
            raise AdapterError(f"Tool {tool_name} not found")

        # Use latest version if not specified
        if version is None:
            version = self.latest_versions.get(tool_name)
            if version is None:
                raise AdapterError(f"No versions found for tool {tool_name}")

        # Check if version exists
        if version not in self.tools[tool_name]:
            raise AdapterError(f"Version {version} not found for tool {tool_name}")

        return self.tools[tool_name][version]

    def get_metadata(
        self, tool_name: str, version: Optional[str] = None
    ) -> ToolMetadata:
        """Get metadata for a tool.

        Args:
            tool_name: Name of the tool
            version: Tool version (uses latest if None)

        Returns:
            ToolMetadata: Tool metadata

        Raises:
            AdapterError: If tool not found
        """
        if tool_name not in self.metadata:
            raise AdapterError(f"Tool {tool_name} not found")

        # Use latest version if not specified
        if version is None:
            version = self.latest_versions.get(tool_name)
            if version is None:
                raise AdapterError(f"No versions found for tool {tool_name}")

        # Check if version exists
        if version not in self.metadata[tool_name]:
            raise AdapterError(f"Version {version} not found for tool {tool_name}")

        return self.metadata[tool_name][version]

    def list_tools(self) -> List[Dict[str, Any]]:
        """List all registered tools.

        Returns:
            List[Dict[str, Any]]: List of tool metadata
        """
        result = []
        for tool_name, versions in self.metadata.items():
            for version, metadata in versions.items():
                is_latest = self.latest_versions.get(tool_name) == version
                result.append(
                    {
                        "tool_name": tool_name,
                        "version": version,
                        "is_latest": is_latest,
                        "description": metadata.description,
                        "adapter_type": metadata.adapter_type,
                    }
                )

        return result

    def list_versions(self, tool_name: str) -> List[str]:
        """List all versions for a tool.

        Args:
            tool_name: Name of the tool

        Returns:
            List[str]: List of versions

        Raises:
            AdapterError: If tool not found
        """
        if tool_name not in self.tools:
            raise AdapterError(f"Tool {tool_name} not found")

        return list(self.tools[tool_name].keys())

    def get_circuit_breaker(
        self, tool_name: str, version: Optional[str] = None
    ) -> CircuitBreaker:
        """Get circuit breaker for a tool.

        Args:
            tool_name: Name of the tool
            version: Tool version (uses latest if None)

        Returns:
            CircuitBreaker: Circuit breaker instance

        Raises:
            AdapterError: If tool not found
        """
        # Get the appropriate version
        if version is None:
            version = self.latest_versions.get(tool_name)
            if version is None:
                raise AdapterError(f"No versions found for tool {tool_name}")

        circuit_name = f"{tool_name}:{version}"
        if circuit_name not in self.circuit_breakers:
            raise AdapterError(f"Circuit breaker not found for {tool_name} v{version}")

        return self.circuit_breakers[circuit_name]

    async def execute_tool(
        self,
        tool_name: str,
        parameters: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None,
        version: Optional[str] = None,
        use_circuit_breaker: bool = True,
    ) -> Dict[str, Any]:
        """Execute a tool with circuit breaker protection.

        Args:
            tool_name: Name of the tool
            parameters: Tool parameters
            context: Execution context
            version: Tool version (uses latest if None)
            use_circuit_breaker: Whether to use circuit breaker

        Returns:
            Dict[str, Any]: Tool result

        Raises:
            AdapterError: If adapter execution fails
            CircuitBreakerError: If circuit breaker is open
        """
        # Get the appropriate version
        if version is None:
            version = self.latest_versions.get(tool_name)
            if version is None:
                raise AdapterError(f"No versions found for tool {tool_name}")

        # Get tool and metadata
        adapter = self.get_tool(tool_name, version)
        metadata = self.get_metadata(tool_name, version)

        # Check if circuit breaker is enabled
        if use_circuit_breaker and metadata.circuit_breaker_enabled:
            circuit_breaker = self.get_circuit_breaker(tool_name, version)

            # Execute with circuit breaker
            try:
                return await circuit_breaker.execute(
                    adapter.execute, tool_name, parameters, context
                )
            except CircuitBreakerError:
                # Propagate circuit breaker errors
                raise
            except Exception as e:
                # Wrap other exceptions
                raise AdapterError(f"Error executing tool {tool_name}: {str(e)}") from e
        else:
            # Execute directly without circuit breaker
            try:
                return await adapter.execute(tool_name, parameters, context)
            except Exception as e:
                raise AdapterError(f"Error executing tool {tool_name}: {str(e)}") from e

    async def shutdown(self) -> None:
        """Shutdown all adapters.

        Raises:
            AdapterError: If shutdown fails
        """
        errors = []

        # Shutdown all adapters
        for tool_name, versions in self.tools.items():
            for version, adapter in versions.items():
                try:
                    await adapter.shutdown()
                except Exception as e:
                    errors.append(
                        f"Error shutting down {tool_name} v{version}: {str(e)}"
                    )

        if errors:
            raise AdapterError(f"Errors during shutdown: {', '.join(errors)}")

        # Clear registries
        self.tools.clear()
        self.metadata.clear()
        self.circuit_breakers.clear()
        self.latest_versions.clear()



================================================
File: src/mcp_core/router.py
================================================
"""Request routing for MCP Core.

This module provides the Router component that routes incoming requests
to the appropriate tool adapters registered in the adapter registry.
"""

from typing import Any

from .errors import AdapterError, CircuitBreakerError
from .logger import logger
from .registry import ToolRegistry


class Router:
    """Routes incoming requests to appropriate adapters.

    The Router uses the ToolRegistry to find the appropriate adapter for
    a given tool request, and applies circuit breaking for fault tolerance.
    """

    def __init__(self, registry: ToolRegistry):
        """Initialize the router.

        Args:
            registry: Tool registry containing registered adapters
        """
        self.registry = registry
        logger.info("Router initialized")

    async def route_request(
        self,
        tool_name: str,
        parameters: dict[str, Any],
        context: dict[str, Any] | None = None,
        version: str | None = None,
        use_circuit_breaker: bool = True,
    ) -> dict[str, Any]:
        """Route a request to the appropriate adapter.

        Args:
            tool_name: Name of the tool to execute
            parameters: Tool parameters
            context: Optional execution context
            version: Tool version (uses latest if None)
            use_circuit_breaker: Whether to use circuit breaker

        Returns:
            Dict[str, Any]: Result from the adapter

        Raises:
            AdapterError: If adapter not found or execution fails
            CircuitBreakerError: If circuit breaker is open
        """
        try:
            # Use the registry to execute the tool
            # The registry handles adapter selection, circuit breaking, etc.
            result = await self.registry.execute_tool(
                tool_name=tool_name,
                parameters=parameters,
                context=context,
                version=version,
                use_circuit_breaker=use_circuit_breaker,
            )

            return result
        except (AdapterError, CircuitBreakerError) as e:
            # Log and re-raise errors
            logger.error(
                f"Error routing request to {tool_name}",
                tool=tool_name,
                version=version or "latest",
                error=str(e),
            )
            raise

    async def list_available_tools(self) -> list[dict[str, Any]]:
        """List all available tools and versions.

        Returns:
            List[Dict[str, Any]]: List of tool metadata
        """
        return self.registry.list_tools()

    async def get_tool_metadata(
        self, tool_name: str, version: str | None = None
    ) -> dict[str, Any]:
        """Get metadata for a specific tool.

        Args:
            tool_name: Name of the tool
            version: Tool version (uses latest if None)

        Returns:
            Dict[str, Any]: Tool metadata

        Raises:
            AdapterError: If tool not found
        """
        metadata = self.registry.get_metadata(tool_name, version)
        return {
            "tool_name": metadata.tool_name,
            "version": metadata.version,
            "adapter_type": metadata.adapter_type,
            "description": metadata.description,
            "created_at": metadata.created_at,
            "updated_at": metadata.updated_at,
            "is_active": metadata.is_active,
            "tags": list(metadata.tags),
            "circuit_breaker_enabled": metadata.circuit_breaker_enabled,
            "health_check_interval": metadata.health_check_interval,
        }

    async def get_tool_health(
        self, tool_name: str, version: str | None = None
    ) -> dict[str, Any]:
        """Get health information for a specific tool.

        Args:
            tool_name: Name of the tool
            version: Tool version (uses latest if None)

        Returns:
            Dict[str, Any]: Health information

        Raises:
            AdapterError: If tool not found
        """
        try:
            adapter = self.registry.get_tool(tool_name, version)
            health = await adapter.health_check()

            # Get circuit breaker state
            circuit_breaker = self.registry.get_circuit_breaker(tool_name, version)
            circuit_state = circuit_breaker.get_state()

            return {
                "tool_name": tool_name,
                "version": version
                or self.registry.latest_versions.get(tool_name, "unknown"),
                "status": health.get("status", "unknown"),
                "circuit_state": circuit_state["state"],
                "failure_count": circuit_state["failure_count"],
                "last_failure_time": circuit_state["last_failure_time"],
                "details": health,
            }
        except Exception as e:
            return {
                "tool_name": tool_name,
                "version": version or "unknown",
                "status": "error",
                "error": str(e),
            }



================================================
File: src/mcp_core/routes.py
================================================
"""API routes for MCP Core."""

from typing import Any

from fastapi import APIRouter, Depends, HTTPException, Request, status
from pydantic import BaseModel, Field

from .errors import AdapterError, CircuitBreakerError
from .logger import logger
from .router import Router


class ToolRequest(BaseModel):
    """Tool execution request model."""

    tool_name: str = Field(..., description="Name of the tool to execute")
    parameters: dict[str, Any] = Field(
        default_factory=dict, description="Tool parameters"
    )
    context: dict[str, Any] | None = Field(
        default=None, description="Optional execution context"
    )
    version: str | None = Field(default=None, description="Tool version")
    use_circuit_breaker: bool = Field(
        default=True, description="Whether to use circuit breaker"
    )


class ToolResponse(BaseModel):
    """Tool execution response model."""

    status: str = Field(..., description="Execution status")
    result: dict[str, Any] | None = Field(default=None, description="Execution result")
    error: str | None = Field(default=None, description="Error message if failed")


class ToolInfo(BaseModel):
    """Tool information model."""

    tool_name: str = Field(..., description="Tool name")
    version: str = Field(..., description="Tool version")
    adapter_type: str = Field(..., description="Type of adapter")
    description: str = Field("", description="Tool description")
    is_latest: bool = Field(False, description="Whether this is the latest version")
    is_active: bool = Field(True, description="Whether the tool is active")
    tags: list[str] = Field(default_factory=list, description="Tool tags")


# Create router
router = APIRouter(tags=["tools"])


async def get_router(request: Request) -> Router:
    """Dependency to get the Router from request state.

    Args:
        request: FastAPI request

    Returns:
        Router: Core router instance
    """
    return request.app.state.registry_router


@router.post("/tools", response_model=ToolResponse)
async def execute_tool(request: ToolRequest, router: Router = Depends(get_router)):
    """Execute a tool.

    Args:
        request: Tool execution request
        router: Router dependency

    Returns:
        ToolResponse: Execution response
    """
    try:
        result = await router.route_request(
            tool_name=request.tool_name,
            parameters=request.parameters,
            context=request.context,
            version=request.version,
            use_circuit_breaker=request.use_circuit_breaker,
        )

        return ToolResponse(status="success", result=result)
    except CircuitBreakerError as e:
        logger.warning(
            f"Circuit breaker error for tool {request.tool_name}",
            tool=request.tool_name,
            error=str(e),
        )
        return ToolResponse(status="circuit_open", error=str(e))
    except AdapterError as e:
        logger.error(
            f"Adapter error for tool {request.tool_name}",
            tool=request.tool_name,
            error=str(e),
        )
        return ToolResponse(status="error", error=str(e))
    except Exception as e:
        logger.error(
            f"Unexpected error executing tool {request.tool_name}",
            tool=request.tool_name,
            error=str(e),
            traceback=True,  # Add traceback flag to indicate this is an exception
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Unexpected error: {str(e)}",
        )


@router.get("/tools", response_model=list[ToolInfo])
async def list_tools(router: Router = Depends(get_router)):
    """List all available tools.

    Args:
        router: Router dependency

    Returns:
        List[ToolInfo]: List of available tools
    """
    tools = await router.list_available_tools()
    return tools


@router.get("/tools/{tool_name}", response_model=dict[str, Any])
async def get_tool_info(
    tool_name: str, version: str | None = None, router: Router = Depends(get_router)
):
    """Get detailed information about a tool.

    Args:
        tool_name: Tool name
        version: Tool version (optional)
        router: Router dependency

    Returns:
        Dict[str, Any]: Tool metadata
    """
    try:
        return await router.get_tool_metadata(tool_name, version)
    except AdapterError as e:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=str(e),
        )


@router.get("/tools/{tool_name}/health", response_model=dict[str, Any])
async def get_tool_health(
    tool_name: str, version: str | None = None, router: Router = Depends(get_router)
):
    """Get health information for a tool.

    Args:
        tool_name: Tool name
        version: Tool version (optional)
        router: Router dependency

    Returns:
        Dict[str, Any]: Health information
    """
    health = await router.get_tool_health(tool_name, version)
    if health.get("status") == "error" and "error" in health:
        # Return a 200 with error details rather than a 404 or 500
        # This allows clients to properly display health status
        return health

    return health



================================================
File: src/mcp_core/adapters/__init__.py
================================================
"""Adapters package for MCP tool integration."""

from .base_adapter import BaseAdapter
from .python_adapter import PythonAdapter
from .python_tool_adapter import PythonToolAdapter
from .ts_adapter import TSAdapter

__all__ = ["BaseAdapter", "PythonAdapter", "PythonToolAdapter", "TSAdapter"]



================================================
File: src/mcp_core/adapters/base_adapter.py
================================================
"""Base adapter interface for MCP tools."""

from abc import ABC, abstractmethod
from typing import Any, Dict, Optional


class BaseAdapter(ABC):
    """Base class for tool adapters."""

    @abstractmethod
    async def initialize(self) -> None:
        """Initialize the adapter.

        This method should prepare the adapter for usage, such as
        loading necessary resources or establishing connections.

        Raises:
            AdapterError: If initialization fails
        """
        pass

    @abstractmethod
    async def shutdown(self) -> None:
        """Shutdown the adapter.

        This method should clean up resources used by the adapter,
        such as closing connections or stopping background tasks.

        Raises:
            AdapterError: If shutdown fails
        """
        pass

    @abstractmethod
    async def execute(
        self,
        tool_name: str,
        parameters: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """Execute a tool with the adapter.

        Args:
            tool_name: Name of the tool to execute
            parameters: Parameters to pass to the tool
            context: Optional execution context

        Returns:
            Dict[str, Any]: Result of tool execution

        Raises:
            AdapterError: If execution fails
        """
        pass

    @abstractmethod
    async def health_check(self) -> Dict[str, Any]:
        """Check the health of the adapter.

        Returns:
            Dict[str, Any]: Health status information

        Raises:
            AdapterError: If health check fails
        """
        pass



================================================
File: src/mcp_core/adapters/circuit_breaker.py
================================================
"""Circuit breaker pattern for MCP tool adapters."""

import asyncio
import time
from enum import Enum
from typing import Any, Callable, Dict, TypeVar, cast

from ..errors import CircuitBreakerError
from ..logger import logger

T = TypeVar("T")


class CircuitState(Enum):
    """Circuit breaker states."""

    CLOSED = "closed"  # Normal operation, requests pass through
    OPEN = "open"  # Failing, requests are blocked
    HALF_OPEN = "half-open"  # Testing if service is recovered


class CircuitBreaker:
    """Circuit breaker for protecting adapter calls."""

    def __init__(
        self,
        name: str,
        failure_threshold: int = 5,
        recovery_timeout: float = 30.0,
        half_open_max_calls: int = 1,
    ):
        """Initialize circuit breaker.

        Args:
            name: Circuit breaker name
            failure_threshold: Number of failures before opening
            recovery_timeout: Seconds to wait before trying recovery
            half_open_max_calls: Max calls allowed in half-open state
        """
        self.name = name
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.half_open_max_calls = half_open_max_calls

        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.last_failure_time = 0.0
        self.half_open_calls = 0

        logger.info(
            f"Circuit breaker {name} initialized",
            circuit=name,
            state=self.state.value,
            threshold=failure_threshold,
        )

    async def execute(self, func: Callable[..., T], *args: Any, **kwargs: Any) -> T:
        """Execute a function with circuit breaker protection.

        Args:
            func: Function to execute
            *args: Function positional arguments
            **kwargs: Function keyword arguments

        Returns:
            T: Function result

        Raises:
            CircuitBreakerError: If circuit is open or function fails
        """
        if self.state == CircuitState.OPEN:
            if time.time() - self.last_failure_time > self.recovery_timeout:
                # Try recovery
                logger.info(
                    f"Circuit {self.name} attempting recovery",
                    circuit=self.name,
                    prev_state=self.state.value,
                    new_state=CircuitState.HALF_OPEN.value,
                )
                self.state = CircuitState.HALF_OPEN
                self.half_open_calls = 0
            else:
                # Circuit still open
                raise CircuitBreakerError(
                    f"Circuit {self.name} is open",
                    details={
                        "circuit": self.name,
                        "state": self.state.value,
                        "retry_after": self.recovery_timeout
                        - (time.time() - self.last_failure_time),
                    },
                )

        if (
            self.state == CircuitState.HALF_OPEN
            and self.half_open_calls >= self.half_open_max_calls
        ):
            # Too many calls in half-open state
            raise CircuitBreakerError(
                f"Circuit {self.name} is half-open and at capacity",
                details={
                    "circuit": self.name,
                    "state": self.state.value,
                    "max_calls": self.half_open_max_calls,
                },
            )

        # Increment half-open call counter if needed
        if self.state == CircuitState.HALF_OPEN:
            self.half_open_calls += 1

        try:
            # Execute the function
            result = (
                await func(*args, **kwargs)
                if asyncio.iscoroutinefunction(func)
                else func(*args, **kwargs)
            )

            # Success handling
            if self.state == CircuitState.HALF_OPEN:
                # Recovery successful
                logger.info(
                    f"Circuit {self.name} recovered",
                    circuit=self.name,
                    prev_state=self.state.value,
                    new_state=CircuitState.CLOSED.value,
                )
                self.state = CircuitState.CLOSED
                self.failure_count = 0

            return cast(T, result)
        except Exception as e:
            # Failure handling
            self.failure_count += 1
            self.last_failure_time = time.time()

            if self.state == CircuitState.HALF_OPEN or (
                self.state == CircuitState.CLOSED
                and self.failure_count >= self.failure_threshold
            ):
                # Open the circuit
                prev_state = self.state
                self.state = CircuitState.OPEN
                logger.warning(
                    f"Circuit {self.name} opened",
                    circuit=self.name,
                    prev_state=prev_state.value,
                    new_state=self.state.value,
                    failures=self.failure_count,
                    recovery_timeout=self.recovery_timeout,
                )

            # Re-raise the exception
            raise CircuitBreakerError(
                f"Circuit {self.name} operation failed: {str(e)}",
                details={
                    "circuit": self.name,
                    "state": self.state.value,
                    "failure_count": self.failure_count,
                    "original_error": str(e),
                },
            ) from e

    def reset(self) -> None:
        """Reset the circuit breaker to closed state."""
        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.last_failure_time = 0.0
        self.half_open_calls = 0

        logger.info(
            f"Circuit {self.name} reset", circuit=self.name, state=self.state.value
        )

    def get_state(self) -> Dict[str, Any]:
        """Get circuit breaker state information.

        Returns:
            Dict[str, Any]: State information
        """
        return {
            "name": self.name,
            "state": self.state.value,
            "failure_count": self.failure_count,
            "last_failure_time": self.last_failure_time,
            "failure_threshold": self.failure_threshold,
            "recovery_timeout": self.recovery_timeout,
            "half_open_calls": self.half_open_calls,
            "half_open_max_calls": self.half_open_max_calls,
        }



================================================
File: src/mcp_core/adapters/python_adapter.py
================================================
"""Python adapter for MCP tools."""

import asyncio
import importlib
import inspect
from typing import Any, Dict, Optional

from ..errors import AdapterError
from ..logger import logger
from .base_adapter import BaseAdapter


class PythonAdapter(BaseAdapter):
    """Adapter for Python-based tools."""

    def __init__(self, module_path: str, function_name: str, load_module: bool = True):
        """Initialize Python adapter.

        Args:
            module_path: Import path to the Python module
            function_name: Name of the function to execute
            load_module: Whether to load the module immediately
        """
        self.module_path = module_path
        self.function_name = function_name
        self.module = None
        self.function = None

        if load_module:
            try:
                self._load_module()
            except Exception as e:
                logger.error(
                    f"Failed to load module {module_path}",
                    module=module_path,
                    error=str(e),
                )

    def _load_module(self) -> None:
        """Load the Python module.

        Raises:
            AdapterError: If module or function cannot be loaded
        """
        try:
            self.module = importlib.import_module(self.module_path)
            self.function = getattr(self.module, self.function_name, None)

            if self.function is None:
                raise AdapterError(
                    f"Function {self.function_name} not found in module {self.module_path}"
                )

            logger.info(
                f"Loaded module {self.module_path} function {self.function_name}",
                module=self.module_path,
                function=self.function_name,
            )
        except ImportError as e:
            raise AdapterError(
                f"Failed to import module {self.module_path}: {str(e)}"
            ) from e
        except AttributeError as e:
            raise AdapterError(
                f"Failed to get function {self.function_name} from module {self.module_path}: {str(e)}"
            ) from e

    async def execute(
        self,
        tool_name: str,
        parameters: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """Execute the Python function.

        Args:
            tool_name: Name of the tool to execute
            parameters: Tool parameters
            context: Optional execution context

        Returns:
            Dict[str, Any]: Function execution result

        Raises:
            AdapterError: If execution fails
        """
        if self.function is None:
            try:
                self._load_module()
            except Exception as e:
                raise AdapterError(f"Failed to load module: {str(e)}") from e

        try:
            # Check if the function is async
            if inspect.iscoroutinefunction(self.function):
                result = await self.function(**parameters)
            else:
                # Run in executor if not async
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    None, lambda: self.function(**parameters)
                )

            # Ensure result is a dict
            if not isinstance(result, dict):
                result = {"result": result}

            return result
        except Exception as e:
            logger.error(
                f"Error executing {tool_name}",
                tool=tool_name,
                function=self.function_name,
                error=str(e),
            )
            raise AdapterError(f"Error executing {tool_name}: {str(e)}") from e

    async def health_check(self) -> Dict[str, Any]:
        """Check adapter health.

        Returns:
            Dict[str, Any]: Health check result

        Raises:
            AdapterError: If health check fails
        """
        try:
            if self.module is None:
                self._load_module()

            return {
                "status": "healthy",
                "module": self.module_path,
                "function": self.function_name,
                "loaded": self.module is not None and self.function is not None,
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "module": self.module_path,
                "function": self.function_name,
                "error": str(e),
            }

    async def initialize(self) -> None:
        """Initialize the adapter.

        Raises:
            AdapterError: If initialization fails
        """
        try:
            if self.module is None:
                self._load_module()
        except Exception as e:
            raise AdapterError(f"Failed to initialize adapter: {str(e)}") from e

    async def shutdown(self) -> None:
        """Shutdown the adapter.

        Raises:
            AdapterError: If shutdown fails
        """
        # Nothing to do for Python adapter
        pass



================================================
File: src/mcp_core/adapters/python_tool_adapter.py
================================================
"""Python Tool Adapter for communicating with the Python Tool Server."""

from typing import Any

import httpx

from ..errors import AdapterError
from ..logger import logger
from .base_adapter import BaseAdapter


class PythonToolAdapter(BaseAdapter):
    """Adapter for Python Tool Server communication."""

    def __init__(
        self, host: str = "127.0.0.1", port: int = 8001, timeout: float = 30.0
    ):
        """Initialize the Python Tool Adapter.

        Args:
            host: Host of the Python Tool Server
            port: Port of the Python Tool Server
            timeout: Request timeout in seconds
        """
        self.host = host
        self.port = port
        self.timeout = timeout
        self.base_url = f"http://{host}:{port}"
        self.client = httpx.AsyncClient(timeout=timeout)
        logger.info(
            f"Initialized Python Tool Adapter for {self.base_url}",
            adapter="python-tool",
            host=host,
            port=port,
        )

    async def execute(
        self,
        tool_name: str,
        parameters: dict[str, Any],
        context: dict[str, Any] | None = None,
    ) -> dict[str, Any]:
        """Execute a tool via the Python Tool Server.

        Args:
            tool_name: Name of the tool to execute
            parameters: Tool parameters
            context: Optional execution context

        Returns:
            Dict[str, Any]: Tool execution result

        Raises:
            AdapterError: If execution fails
        """
        # Route the request to the appropriate tool
        return await self.route_request(tool_name, parameters, context)

    async def route_request(
        self,
        tool_name: str,
        parameters: dict[str, Any],
        context: dict[str, Any] | None = None,
    ) -> dict[str, Any]:
        """Route a request to the Python Tool Server.

        Args:
            tool_name: Name of the tool to execute
            parameters: Tool parameters
            context: Optional execution context

        Returns:
            Dict[str, Any]: Tool execution result

        Raises:
            AdapterError: If the request fails
        """
        try:
            # Prepare request
            url = f"{self.base_url}/tools/{tool_name}"
            payload = {
                "tool_name": tool_name,
                "parameters": parameters,
                "context": context or {},
            }

            # Send request
            logger.debug(
                f"Sending request to Python Tool Server: {tool_name}",
                adapter="python-tool",
                tool=tool_name,
            )
            response = await self.client.post(url, json=payload)

            # Handle response
            if response.status_code != 200:
                error_msg = f"Error from Python Tool Server: {response.text}"
                logger.error(
                    error_msg,
                    adapter="python-tool",
                    tool=tool_name,
                    status_code=response.status_code,
                )
                raise AdapterError(error_msg)

            result = response.json()
            return result
        except httpx.RequestError as e:
            error_msg = f"Request to Python Tool Server failed: {str(e)}"
            logger.error(
                error_msg,
                adapter="python-tool",
                tool=tool_name,
                error=str(e),
            )
            raise AdapterError(error_msg) from e
        except Exception as e:
            error_msg = f"Error executing {tool_name}: {str(e)}"
            logger.error(
                error_msg,
                adapter="python-tool",
                tool=tool_name,
                error=str(e),
            )
            raise AdapterError(error_msg) from e

    async def initialize(self) -> None:
        """Initialize the adapter.

        Raises:
            AdapterError: If initialization fails
        """
        try:
            await self.health_check()
        except Exception as e:
            raise AdapterError(f"Failed to initialize adapter: {str(e)}") from e

    async def shutdown(self) -> None:
        """Shutdown the adapter.

        Raises:
            AdapterError: If shutdown fails
        """
        try:
            await self.client.aclose()
        except Exception as e:
            raise AdapterError(f"Failed to shutdown adapter: {str(e)}") from e

    async def health_check(self) -> dict[str, Any]:
        """Check adapter health.

        Returns:
            Dict[str, Any]: Health check result

        Raises:
            AdapterError: If health check fails
        """
        try:
            url = f"{self.base_url}/health"
            response = await self.client.get(url)

            if response.status_code != 200:
                return {
                    "status": "unhealthy",
                    "message": f"Health check failed with status {response.status_code}: {response.text}",
                }

            return {
                "status": "healthy",
                "server": self.base_url,
                "details": response.json(),
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "server": self.base_url,
                "error": str(e),
            }



================================================
File: src/mcp_core/adapters/ts_adapter.py
================================================
"""TypeScript adapter for MCP tools."""

import asyncio
import os
import subprocess
from typing import Any, Dict, Optional

from ..errors import AdapterError
from ..logger import logger
from .base_adapter import BaseAdapter


class TypeScriptAdapter(BaseAdapter):
    """Adapter for TypeScript-based tools."""

    def __init__(
        self,
        server_path: str,
        tool_name: str,
        server_host: str = "localhost",
        server_port: int = 3000,
    ):
        """Initialize TypeScript adapter.

        Args:
            server_path: Path to TypeScript server directory
            tool_name: Name of the tool in the TypeScript server
            server_host: Host where TypeScript server runs
            server_port: Port where TypeScript server runs
        """
        self.server_path = server_path
        self.tool_name = tool_name
        self.server_host = server_host
        self.server_port = server_port
        self.server_url = f"http://{server_host}:{server_port}"
        self.server_process = None

        logger.info(
            f"Initialized TypeScript adapter for {tool_name}",
            tool=tool_name,
            server_path=server_path,
            server_url=self.server_url,
        )

    async def _start_server(self) -> None:
        """Start the TypeScript server.

        Raises:
            AdapterError: If server fails to start
        """
        if self.server_process and self.server_process.returncode is None:
            # Server already running
            return

        try:
            # Start server as subprocess
            self.server_process = subprocess.Popen(
                ["npm", "start"],
                cwd=self.server_path,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                env={**os.environ, "PORT": str(self.server_port)},
            )

            # Wait a bit for server to start
            await asyncio.sleep(2)

            # Check if process started successfully
            if self.server_process.poll() is not None:
                stderr = (
                    self.server_process.stderr.read()
                    if self.server_process.stderr
                    else ""
                )
                raise AdapterError(f"TypeScript server failed to start: {stderr}")

            logger.info(
                f"Started TypeScript server at {self.server_url}",
                tool=self.tool_name,
                server_url=self.server_url,
            )
        except Exception as e:
            raise AdapterError(f"Failed to start TypeScript server: {str(e)}") from e

    async def execute(
        self,
        tool_name: str,
        parameters: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """Execute a TypeScript tool.

        Args:
            tool_name: Name of the tool to execute
            parameters: Tool parameters
            context: Optional execution context

        Returns:
            Dict[str, Any]: Tool execution result

        Raises:
            AdapterError: If execution fails
        """
        try:
            # Ensure server is running
            await self._start_server()

            # Use httpx or another HTTP client to make a request to the TypeScript server
            # This is a placeholder for the actual HTTP request
            # In a real implementation, you would make an HTTP request to the server

            # Placeholder implementation
            result = {"status": "success", "message": "TypeScript tool executed"}
            return result
        except Exception as e:
            logger.error(
                f"Error executing TypeScript tool {tool_name}",
                tool=tool_name,
                error=str(e),
            )
            raise AdapterError(f"Error executing TypeScript tool: {str(e)}") from e

    async def health_check(self) -> Dict[str, Any]:
        """Check adapter health.

        Returns:
            Dict[str, Any]: Health check result

        Raises:
            AdapterError: If health check fails
        """
        try:
            # Check if server is running
            if not self.server_process or self.server_process.poll() is not None:
                return {
                    "status": "unhealthy",
                    "message": "TypeScript server not running",
                }

            # Placeholder for making a health check request to the TypeScript server
            # In a real implementation, you would make an HTTP request to a health endpoint

            return {
                "status": "healthy",
                "server_url": self.server_url,
                "tool": self.tool_name,
            }
        except Exception as e:
            return {"status": "unhealthy", "error": str(e)}

    async def initialize(self) -> None:
        """Initialize the adapter.

        Raises:
            AdapterError: If initialization fails
        """
        try:
            await self._start_server()
        except Exception as e:
            raise AdapterError(
                f"Failed to initialize TypeScript adapter: {str(e)}"
            ) from e

    async def shutdown(self) -> None:
        """Shutdown the adapter.

        Raises:
            AdapterError: If shutdown fails
        """
        if self.server_process and self.server_process.returncode is None:
            try:
                # Terminate the server process
                self.server_process.terminate()

                # Wait for process to terminate
                try:
                    self.server_process.wait(timeout=5)
                except subprocess.TimeoutExpired:
                    # Force kill if not terminated
                    self.server_process.kill()

                logger.info("TypeScript server stopped", tool=self.tool_name)
            except Exception as e:
                logger.error(
                    "Error shutting down TypeScript server",
                    tool=self.tool_name,
                    error=str(e),
                )
                raise AdapterError(
                    f"Error shutting down TypeScript adapter: {str(e)}"
                ) from e



================================================
File: src/mcp_core/adapters/version.py
================================================
"""Version control for tool adapters."""

from enum import Enum
from typing import Dict, List, Optional, Union

from pydantic import BaseModel

from ..errors import AdapterError


class VersionStrategy(str, Enum):
    """Strategy for versioning tools."""

    SEMANTIC = "semantic"  # Semantic versioning (e.g., 1.2.3)
    DATE = "date"  # Date-based versioning (e.g., 20230401)
    INCREMENT = "increment"  # Simple incremental versioning (e.g., 1, 2, 3)


class VersionInfo(BaseModel):
    """Version information for a tool."""

    version: str
    released_at: str  # ISO format date
    is_latest: bool = False
    is_deprecated: bool = False
    min_core_version: Optional[str] = None
    changes: List[str] = []
    metadata: Dict[str, str] = {}


class VersionManager:
    """Manages versioning for tool adapters."""

    def __init__(
        self, strategy: Union[VersionStrategy, str] = VersionStrategy.SEMANTIC
    ):
        """Initialize version manager.

        Args:
            strategy: Versioning strategy to use
        """
        if isinstance(strategy, str):
            try:
                self.strategy = VersionStrategy(strategy)
            except ValueError:
                raise AdapterError(f"Invalid version strategy: {strategy}")
        else:
            self.strategy = strategy

        self.versions: Dict[str, Dict[str, VersionInfo]] = {}

    def register_version(self, tool_name: str, version_info: VersionInfo) -> None:
        """Register a version for a tool.

        Args:
            tool_name: Name of the tool
            version_info: Version information

        Raises:
            AdapterError: If version is invalid or already registered
        """
        if tool_name not in self.versions:
            self.versions[tool_name] = {}

        if version_info.version in self.versions[tool_name]:
            raise AdapterError(
                f"Version {version_info.version} already registered for tool {tool_name}"
            )

        # Validate according to strategy
        self._validate_version(version_info.version)

        # If this is marked as latest, unmark any other latest versions
        if version_info.is_latest:
            for other_version in self.versions[tool_name].values():
                other_version.is_latest = False

        self.versions[tool_name][version_info.version] = version_info

    def get_latest_version(self, tool_name: str) -> str:
        """Get the latest version for a tool.

        Args:
            tool_name: Name of the tool

        Returns:
            str: Latest version string

        Raises:
            AdapterError: If tool has no registered versions
        """
        if tool_name not in self.versions or not self.versions[tool_name]:
            raise AdapterError(f"No versions registered for tool {tool_name}")

        # First check for explicitly marked latest
        for version, info in self.versions[tool_name].items():
            if info.is_latest:
                return version

        # Otherwise use strategy-specific logic
        if self.strategy == VersionStrategy.SEMANTIC:
            return max(
                self.versions[tool_name].keys(),
                key=lambda v: [int(x) for x in v.split(".")],
            )
        elif self.strategy == VersionStrategy.DATE:
            return max(self.versions[tool_name].keys())
        elif self.strategy == VersionStrategy.INCREMENT:
            return max(self.versions[tool_name].keys(), key=lambda v: int(v))

        # Fallback
        return max(self.versions[tool_name].keys())

    def get_version_info(self, tool_name: str, version: str) -> VersionInfo:
        """Get version info for a tool.

        Args:
            tool_name: Name of the tool
            version: Version string

        Returns:
            VersionInfo: Version information

        Raises:
            AdapterError: If tool or version not found
        """
        if tool_name not in self.versions:
            raise AdapterError(f"Tool {tool_name} not found")

        if version not in self.versions[tool_name]:
            raise AdapterError(f"Version {version} not found for tool {tool_name}")

        return self.versions[tool_name][version]

    def list_versions(self, tool_name: str) -> List[VersionInfo]:
        """List all versions for a tool.

        Args:
            tool_name: Name of the tool

        Returns:
            List[VersionInfo]: List of version information

        Raises:
            AdapterError: If tool not found
        """
        if tool_name not in self.versions:
            raise AdapterError(f"Tool {tool_name} not found")

        return list(self.versions[tool_name].values())

    def deprecate_version(self, tool_name: str, version: str) -> None:
        """Mark a version as deprecated.

        Args:
            tool_name: Name of the tool
            version: Version string

        Raises:
            AdapterError: If tool or version not found
        """
        if tool_name not in self.versions:
            raise AdapterError(f"Tool {tool_name} not found")

        if version not in self.versions[tool_name]:
            raise AdapterError(f"Version {version} not found for tool {tool_name}")

        self.versions[tool_name][version].is_deprecated = True

    def _validate_version(self, version: str) -> None:
        """Validate a version string according to the strategy.

        Args:
            version: Version string to validate

        Raises:
            AdapterError: If version is invalid
        """
        if self.strategy == VersionStrategy.SEMANTIC:
            # Basic semantic version validation (x.y.z)
            parts = version.split(".")
            if len(parts) != 3 or not all(p.isdigit() for p in parts):
                raise AdapterError(
                    f"Invalid semantic version: {version}. Must be in format x.y.z"
                )
        elif self.strategy == VersionStrategy.DATE:
            # Basic date validation (YYYYMMDD)
            if len(version) != 8 or not version.isdigit():
                raise AdapterError(
                    f"Invalid date version: {version}. Must be in format YYYYMMDD"
                )
        elif self.strategy == VersionStrategy.INCREMENT:
            # Simple integer validation
            if not version.isdigit():
                raise AdapterError(
                    f"Invalid increment version: {version}. Must be a number"
                )



================================================
File: src/mcp_core/adapters/testing/__init__.py
================================================
"""Testing tools for MCP adapters."""



================================================
File: src/mcp_core/adapters/testing/python_tool.py
================================================
"""Example Python tool for testing the adapter."""

import time
from typing import Any


async def execute_tool(**kwargs: Any) -> dict[str, Any]:
    """Execute the example Python tool.

    Args:
        **kwargs: Tool parameters

    Returns:
        Dict[str, Any]: Tool execution result
    """
    # Simulate some processing
    time.sleep(0.1)

    # Return a sample result
    return {
        "tool": "python-example",
        "executed_at": time.time(),
        "received_parameters": kwargs,
        "sample_result": "This is a test result from the Python tool",
    }



================================================
File: src/mcp_core/config/__init__.py
================================================
"""MCP Core configuration module."""

from .config import CoreConfig, get_core_config

__all__ = ["CoreConfig", "get_core_config"]



================================================
File: src/mcp_core/config/config.py
================================================
from typing import List, Optional

from pydantic import BaseSettings, Field


class CoreConfig(BaseSettings):
    """MCP Core configuration."""

    # Server settings
    host: str = Field("127.0.0.1", env="MCP_CORE_HOST")
    port: int = Field(8000, env="MCP_CORE_PORT")
    debug: bool = Field(False, env="MCP_DEBUG")

    # Logging
    log_level: str = Field("INFO", env="MCP_LOG_LEVEL")
    log_format: str = Field("json", env="MCP_LOG_FORMAT")

    # Tool settings
    tool_timeout: int = Field(30, env="MCP_TOOL_TIMEOUT")
    max_retries: int = Field(3, env="MCP_MAX_RETRIES")

    # Security
    auth_token: Optional[str] = Field(None, env="MCP_AUTH_TOKEN")
    allowed_origins: List[str] = Field(default_factory=list)

    class Config:
        env_prefix = "MCP_"
        case_sensitive = False


def get_core_config() -> CoreConfig:
    """Get core configuration instance."""
    return CoreConfig()



================================================
File: src/mcp_core/logger/__init__.py
================================================
"""MCP Core logging module."""

from .logger import JsonFormatter, StructuredLogger, log_execution_time, logger

__all__ = ["StructuredLogger", "JsonFormatter", "log_execution_time", "logger"]



================================================
File: src/mcp_core/logger/config.py
================================================
"""Logging configuration for MCP.

This module provides centralized logging configuration following project structure rules.
"""

import os
from pathlib import Path

from pydantic import BaseModel, Field

# Get project root from environment or default
PROJECT_ROOT = Path(
    os.getenv("MCP_PROJECT_ROOT", "/d:/Coding/Python_Projects/MYMCPSERVER")
)
LOG_ROOT = PROJECT_ROOT / "logs"


class LogConfig(BaseModel):
    """Logging configuration model."""

    # Log directory settings
    log_dir: Path = Field(
        default_factory=lambda: LOG_ROOT, description="Root directory for log files"
    )
    core_log_dir: Path = Field(
        default_factory=lambda: LOG_ROOT / "core",
        description="Directory for core layer logs",
    )
    proxy_log_dir: Path = Field(
        default_factory=lambda: LOG_ROOT / "proxy",
        description="Directory for proxy layer logs",
    )
    tools_log_dir: Path = Field(
        default_factory=lambda: LOG_ROOT / "tools",
        description="Directory for tool server logs",
    )

    # Log file settings
    log_level: str = Field(default="INFO", description="Default logging level")
    file_name_template: str = Field(
        default="{service}-{date}.log", description="Template for log file names"
    )
    max_size: int = Field(
        default=10 * 1024 * 1024,  # 10MB
        description="Maximum size of log files before rotation",
    )
    backup_count: int = Field(default=5, description="Number of backup files to keep")

    # Output settings
    enable_stdout: bool = Field(
        default=True, description="Whether to output logs to stdout"
    )
    json_format: bool = Field(
        default=True, description="Whether to format logs as JSON"
    )

    def get_log_dir(self, service: str) -> Path:
        """Get the appropriate log directory for a service.

        Args:
            service: The service name (core, proxy, or a tool name)

        Returns:
            Path: The log directory for the service
        """
        if service == "core":
            return self.core_log_dir
        elif service == "proxy":
            return self.proxy_log_dir
        else:
            return self.tools_log_dir / service

    def ensure_log_dirs(self) -> None:
        """Create all required log directories."""
        for directory in [
            self.log_dir,
            self.core_log_dir,
            self.proxy_log_dir,
            self.tools_log_dir,
        ]:
            directory.mkdir(parents=True, exist_ok=True)


# Global configuration instance
log_config = LogConfig()

# Ensure log directories exist
log_config.ensure_log_dirs()



================================================
File: src/mcp_core/logger/logger.py
================================================
"""Structured logging implementation for MCP.

This module provides JSON-formatted structured logging with file and stdout output.
"""

import json
import logging
import time
import traceback
from datetime import datetime
from functools import wraps
from logging.handlers import RotatingFileHandler
from typing import Optional

from .config import log_config


class StructuredLogger:
    """JSON-formatted structured logger."""

    def __init__(self, name: str, level: Optional[str] = None):
        self.name = name
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level or log_config.log_level)

        # Clear any existing handlers
        self.logger.handlers = []

        # Add handlers
        self._setup_handlers()

    def _setup_handlers(self):
        """Setup log handlers based on configuration."""
        # Add JSON formatter to all handlers
        formatter = JsonFormatter()

        # Add file handler
        service_type = self.name.split(".")[0]  # e.g., 'core' from 'core.app'
        log_dir = log_config.get_log_dir(service_type)
        log_file = log_dir / log_config.file_name_template.format(
            service=self.name, date=datetime.now().strftime("%Y%m%d")
        )

        file_handler = RotatingFileHandler(
            log_file,
            maxBytes=log_config.max_size,
            backupCount=log_config.backup_count,
            encoding="utf-8",
        )
        file_handler.setFormatter(formatter)
        self.logger.addHandler(file_handler)

        # Add stdout handler if enabled
        if log_config.enable_stdout:
            stdout_handler = logging.StreamHandler()
            stdout_handler.setFormatter(formatter)
            self.logger.addHandler(stdout_handler)

    def _log(self, level: str, message: str, **kwargs):
        """Log with additional context."""
        extra = {
            "timestamp": datetime.utcnow().isoformat(),
            "service": self.name,
            **kwargs,
        }

        getattr(self.logger, level.lower())(message, extra={"context": extra})

    def info(self, message: str, **kwargs):
        """Log at INFO level."""
        self._log("INFO", message, **kwargs)

    def error(self, message: str, **kwargs):
        """Log at ERROR level."""
        self._log("ERROR", message, **kwargs)

    def debug(self, message: str, **kwargs):
        """Log at DEBUG level."""
        self._log("DEBUG", message, **kwargs)

    def warning(self, message: str, **kwargs):
        """Log at WARNING level."""
        self._log("WARNING", message, **kwargs)


class JsonFormatter(logging.Formatter):
    """JSON log formatter."""

    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON."""
        data = {
            "level": record.levelname,
            "message": record.getMessage(),
            **(getattr(record, "context", {})),
        }
        return json.dumps(data)


def log_execution_time(logger: StructuredLogger):
    """Decorator to log function execution time."""

    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = await func(*args, **kwargs)
                execution_time = time.time() - start_time
                logger.info(
                    f"{func.__name__} completed",
                    execution_time_ms=int(execution_time * 1000),
                    function=func.__name__,
                )
                return result
            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(
                    f"{func.__name__} failed",
                    execution_time_ms=int(execution_time * 1000),
                    function=func.__name__,
                    error=str(e),
                    traceback=traceback.format_exc(),
                )
                raise

        return wrapper

    return decorator


# Create default logger instance
logger = StructuredLogger("mcp_core")



================================================
File: src/mcp_core/metrics/__init__.py
================================================
"""Metrics package for MCP Core."""

from .collectors import (
    RequestMetricsCollector,
    SystemMetricsCollector,
    ToolMetricsCollector,
)
from .exporters import MetricsExporter, PrometheusExporter

__all__ = [
    "ToolMetricsCollector",
    "RequestMetricsCollector",
    "SystemMetricsCollector",
    "MetricsExporter",
    "PrometheusExporter",
]



================================================
File: src/mcp_core/metrics/collectors.py
================================================
"""Metrics collectors for MCP Core."""

import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Dict, List, Optional

from ..logger import logger


@dataclass
class Metric:
    """Base class for metrics."""

    name: str
    description: str
    labels: Dict[str, str] = field(default_factory=dict)


@dataclass
class Counter(Metric):
    """Counter metric type."""

    value: int = 0

    def increment(self, amount: int = 1) -> None:
        """Increment counter.

        Args:
            amount: Amount to increment by
        """
        self.value += amount


@dataclass
class Gauge(Metric):
    """Gauge metric type."""

    value: float = 0.0

    def set(self, value: float) -> None:
        """Set gauge value.

        Args:
            value: Value to set
        """
        self.value = value

    def increment(self, amount: float = 1.0) -> None:
        """Increment gauge.

        Args:
            amount: Amount to increment by
        """
        self.value += amount

    def decrement(self, amount: float = 1.0) -> None:
        """Decrement gauge.

        Args:
            amount: Amount to decrement by
        """
        self.value -= amount


@dataclass
class Histogram(Metric):
    """Histogram metric type."""

    buckets: List[float] = field(
        default_factory=lambda: [
            0.005,
            0.01,
            0.025,
            0.05,
            0.1,
            0.25,
            0.5,
            1,
            2.5,
            5,
            10,
        ]
    )
    bucket_values: Dict[float, int] = field(default_factory=dict)
    sum: float = 0.0
    count: int = 0

    def __post_init__(self) -> None:
        """Initialize bucket values."""
        self.bucket_values = {bucket: 0 for bucket in self.buckets}
        # Add Inf bucket
        self.bucket_values[float("inf")] = 0

    def observe(self, value: float) -> None:
        """Record an observation.

        Args:
            value: Value to observe
        """
        self.sum += value
        self.count += 1

        # Update buckets
        for bucket in self.buckets + [float("inf")]:
            if value <= bucket:
                self.bucket_values[bucket] += 1


class MetricsCollector(ABC):
    """Base class for metrics collectors."""

    def __init__(self, namespace: str):
        """Initialize metrics collector.

        Args:
            namespace: Metrics namespace
        """
        self.namespace = namespace
        self.counters: Dict[str, Counter] = {}
        self.gauges: Dict[str, Gauge] = {}
        self.histograms: Dict[str, Histogram] = {}

    def create_counter(
        self, name: str, description: str, labels: Optional[Dict[str, str]] = None
    ) -> Counter:
        """Create a counter metric.

        Args:
            name: Metric name
            description: Metric description
            labels: Metric labels

        Returns:
            Counter: New counter metric
        """
        full_name = f"{self.namespace}_{name}"
        counter = Counter(full_name, description, labels or {})
        self.counters[full_name] = counter
        return counter

    def create_gauge(
        self, name: str, description: str, labels: Optional[Dict[str, str]] = None
    ) -> Gauge:
        """Create a gauge metric.

        Args:
            name: Metric name
            description: Metric description
            labels: Metric labels

        Returns:
            Gauge: New gauge metric
        """
        full_name = f"{self.namespace}_{name}"
        gauge = Gauge(full_name, description, labels or {})
        self.gauges[full_name] = gauge
        return gauge

    def create_histogram(
        self,
        name: str,
        description: str,
        buckets: Optional[List[float]] = None,
        labels: Optional[Dict[str, str]] = None,
    ) -> Histogram:
        """Create a histogram metric.

        Args:
            name: Metric name
            description: Metric description
            buckets: Histogram buckets
            labels: Metric labels

        Returns:
            Histogram: New histogram metric
        """
        full_name = f"{self.namespace}_{name}"
        histogram = Histogram(full_name, description, labels or {}, buckets or [])
        self.histograms[full_name] = histogram
        return histogram

    def get_all_metrics(self) -> List[Metric]:
        """Get all metrics.

        Returns:
            List[Metric]: All metrics
        """
        return (
            list(self.counters.values())
            + list(self.gauges.values())
            + list(self.histograms.values())
        )

    @abstractmethod
    def collect(self) -> None:
        """Collect metrics."""
        pass


class RequestMetricsCollector(MetricsCollector):
    """Collector for request-related metrics."""

    def __init__(self):
        """Initialize request metrics collector."""
        super().__init__("mcp_request")

        # Define metrics
        self.request_count = self.create_counter(
            "total", "Total number of requests processed"
        )

        self.request_success_count = self.create_counter(
            "success_total", "Total number of successful requests"
        )

        self.request_error_count = self.create_counter(
            "error_total", "Total number of failed requests"
        )

        self.request_duration = self.create_histogram(
            "duration_seconds", "Request duration in seconds"
        )

        self.request_active = self.create_gauge("active", "Number of active requests")

        logger.info("Request metrics collector initialized")

    def collect(self) -> None:
        """Collect metrics."""
        # This collector is updated in real-time, so no collection needed
        pass

    def record_request_start(self) -> float:
        """Record the start of a request.

        Returns:
            float: Start timestamp
        """
        self.request_count.increment()
        self.request_active.increment()
        return time.time()

    def record_request_end(self, start_time: float, success: bool = True) -> float:
        """Record the end of a request.

        Args:
            start_time: Request start timestamp
            success: Whether request was successful

        Returns:
            float: Request duration in seconds
        """
        duration = time.time() - start_time
        self.request_duration.observe(duration)
        self.request_active.decrement()

        if success:
            self.request_success_count.increment()
        else:
            self.request_error_count.increment()

        return duration


class ToolMetricsCollector(MetricsCollector):
    """Collector for tool-related metrics."""

    def __init__(self):
        """Initialize tool metrics collector."""
        super().__init__("mcp_tool")

        # Define metrics
        self.tool_call_count = self.create_counter(
            "calls_total", "Total number of tool calls"
        )

        self.tool_success_count = self.create_counter(
            "success_total", "Total number of successful tool calls"
        )

        self.tool_error_count = self.create_counter(
            "error_total", "Total number of failed tool calls"
        )

        self.tool_duration = self.create_histogram(
            "duration_seconds", "Tool call duration in seconds"
        )

        # Track tool-specific metrics
        self.tool_specific_calls: Dict[str, Counter] = {}
        self.tool_specific_errors: Dict[str, Counter] = {}
        self.tool_specific_durations: Dict[str, Histogram] = {}

        logger.info("Tool metrics collector initialized")

    def collect(self) -> None:
        """Collect metrics."""
        # This collector is updated in real-time, so no collection needed
        pass

    def register_tool(self, tool_name: str, tool_version: str) -> None:
        """Register a tool for metrics collection.

        Args:
            tool_name: Name of the tool
            tool_version: Version of the tool
        """
        tool_id = f"{tool_name}_{tool_version}"

        # Create tool-specific metrics if not already created
        if tool_id not in self.tool_specific_calls:
            self.tool_specific_calls[tool_id] = self.create_counter(
                f"calls_total_{tool_id}",
                f"Total calls for tool {tool_name} v{tool_version}",
                {"tool": tool_name, "version": tool_version},
            )

            self.tool_specific_errors[tool_id] = self.create_counter(
                f"errors_total_{tool_id}",
                f"Total errors for tool {tool_name} v{tool_version}",
                {"tool": tool_name, "version": tool_version},
            )

            self.tool_specific_durations[tool_id] = self.create_histogram(
                f"duration_seconds_{tool_id}",
                f"Call duration for tool {tool_name} v{tool_version}",
                labels={"tool": tool_name, "version": tool_version},
            )

            logger.info(
                f"Registered metrics for tool {tool_name} v{tool_version}",
                tool=tool_name,
                version=tool_version,
            )

    def record_tool_call_start(self, tool_name: str, tool_version: str) -> float:
        """Record the start of a tool call.

        Args:
            tool_name: Name of the tool
            tool_version: Version of the tool

        Returns:
            float: Start timestamp
        """
        self.tool_call_count.increment()

        # Update tool-specific metrics
        tool_id = f"{tool_name}_{tool_version}"
        if tool_id in self.tool_specific_calls:
            self.tool_specific_calls[tool_id].increment()

        return time.time()

    def record_tool_call_end(
        self, start_time: float, tool_name: str, tool_version: str, success: bool = True
    ) -> float:
        """Record the end of a tool call.

        Args:
            start_time: Call start timestamp
            tool_name: Name of the tool
            tool_version: Version of the tool
            success: Whether call was successful

        Returns:
            float: Call duration in seconds
        """
        duration = time.time() - start_time
        self.tool_duration.observe(duration)

        if success:
            self.tool_success_count.increment()
        else:
            self.tool_error_count.increment()

        # Update tool-specific metrics
        tool_id = f"{tool_name}_{tool_version}"
        if tool_id in self.tool_specific_durations:
            self.tool_specific_durations[tool_id].observe(duration)

        if not success and tool_id in self.tool_specific_errors:
            self.tool_specific_errors[tool_id].increment()

        return duration


class SystemMetricsCollector(MetricsCollector):
    """Collector for system-related metrics."""

    def __init__(self):
        """Initialize system metrics collector."""
        super().__init__("mcp_system")

        # Define metrics
        self.uptime = self.create_gauge("uptime_seconds", "MCP Core uptime in seconds")

        self.memory_usage = self.create_gauge("memory_bytes", "Memory usage in bytes")

        self.cpu_usage = self.create_gauge("cpu_percent", "CPU usage percentage")

        self.thread_count = self.create_gauge("thread_count", "Number of threads")

        self.gc_collections = self.create_counter(
            "gc_collections_total", "Total number of garbage collections"
        )

        self.start_time = time.time()
        logger.info("System metrics collector initialized")

    def collect(self) -> None:
        """Collect system metrics."""
        # Update uptime
        self.uptime.set(time.time() - self.start_time)

        # Other metrics would typically be updated here
        # This is just a placeholder - in a real implementation you would
        # use psutil or similar to get actual system metrics

        logger.debug("System metrics collected")



================================================
File: src/mcp_core/metrics/exporters.py
================================================
"""Metrics exporters for MCP Core."""

import json
import time
from abc import ABC, abstractmethod
from typing import Any, Dict, List

from ..logger import logger
from .collectors import Counter, Gauge, Histogram, Metric, MetricsCollector


class MetricsExporter(ABC):
    """Base class for metrics exporters."""

    def __init__(self, collectors: List[MetricsCollector]):
        """Initialize metrics exporter.

        Args:
            collectors: List of metrics collectors
        """
        self.collectors = collectors
        logger.info(
            f"Initialized {self.__class__.__name__}",
            collectors=[collector.namespace for collector in collectors],
        )

    def collect_all(self) -> List[Metric]:
        """Collect metrics from all collectors.

        Returns:
            List[Metric]: All collected metrics
        """
        # Trigger collection in all collectors
        for collector in self.collectors:
            collector.collect()

        # Get all metrics
        metrics = []
        for collector in self.collectors:
            metrics.extend(collector.get_all_metrics())

        return metrics

    @abstractmethod
    async def export(self) -> Any:
        """Export metrics.

        Returns:
            Any: Export result
        """
        pass


class PrometheusExporter(MetricsExporter):
    """Exporter for Prometheus metrics format."""

    def __init__(self, collectors: List[MetricsCollector], prefix: str = "mcp"):
        """Initialize Prometheus exporter.

        Args:
            collectors: List of metrics collectors
            prefix: Metrics prefix
        """
        super().__init__(collectors)
        self.prefix = prefix

    async def export(self) -> str:
        """Export metrics in Prometheus format.

        Returns:
            str: Metrics in Prometheus format
        """
        metrics = self.collect_all()
        output = []

        for metric in metrics:
            # Add metric header with description
            metric_name = (
                f"{self.prefix}_{metric.name}"
                if not metric.name.startswith(f"{self.prefix}_")
                else metric.name
            )
            output.append(f"# HELP {metric_name} {metric.description}")

            # Add type information
            if isinstance(metric, Counter):
                output.append(f"# TYPE {metric_name} counter")
                self._format_counter(output, metric_name, metric)
            elif isinstance(metric, Gauge):
                output.append(f"# TYPE {metric_name} gauge")
                self._format_gauge(output, metric_name, metric)
            elif isinstance(metric, Histogram):
                output.append(f"# TYPE {metric_name} histogram")
                self._format_histogram(output, metric_name, metric)

        return "\n".join(output)

    def _format_counter(self, output: List[str], name: str, counter: Counter) -> None:
        """Format counter for Prometheus.

        Args:
            output: Output lines
            name: Metric name
            counter: Counter metric
        """
        labels_str = self._format_labels(counter.labels)
        output.append(f"{name}{labels_str} {counter.value}")

    def _format_gauge(self, output: List[str], name: str, gauge: Gauge) -> None:
        """Format gauge for Prometheus.

        Args:
            output: Output lines
            name: Metric name
            gauge: Gauge metric
        """
        labels_str = self._format_labels(gauge.labels)
        output.append(f"{name}{labels_str} {gauge.value}")

    def _format_histogram(
        self, output: List[str], name: str, histogram: Histogram
    ) -> None:
        """Format histogram for Prometheus.

        Args:
            output: Output lines
            name: Metric name
            histogram: Histogram metric
        """
        base_labels = histogram.labels.copy()

        # Add bucket samples
        for bucket, count in histogram.bucket_values.items():
            labels = base_labels.copy()
            labels["le"] = str(bucket) if bucket != float("inf") else "+Inf"
            labels_str = self._format_labels(labels)
            output.append(f"{name}_bucket{labels_str} {count}")

        # Add sum and count
        labels_str = self._format_labels(base_labels)
        output.append(f"{name}_sum{labels_str} {histogram.sum}")
        output.append(f"{name}_count{labels_str} {histogram.count}")

    def _format_labels(self, labels: Dict[str, str]) -> str:
        """Format labels for Prometheus.

        Args:
            labels: Label dictionary

        Returns:
            str: Formatted labels string
        """
        if not labels:
            return ""

        label_parts = [f'{k}="{v}"' for k, v in sorted(labels.items())]
        return "{" + ",".join(label_parts) + "}"


class JsonFileExporter(MetricsExporter):
    """Exporter for metrics to JSON file."""

    def __init__(
        self, collectors: List[MetricsCollector], file_path: str, append: bool = False
    ):
        """Initialize JSON file exporter.

        Args:
            collectors: List of metrics collectors
            file_path: Path to output file
            append: Whether to append to file
        """
        super().__init__(collectors)
        self.file_path = file_path
        self.append = append

    async def export(self) -> None:
        """Export metrics to JSON file."""
        metrics = self.collect_all()
        timestamp = time.time()

        # Convert metrics to serializable format
        data = {"timestamp": timestamp, "metrics": {}}

        for metric in metrics:
            if isinstance(metric, Counter):
                data["metrics"][metric.name] = {
                    "type": "counter",
                    "value": metric.value,
                    "labels": metric.labels,
                }
            elif isinstance(metric, Gauge):
                data["metrics"][metric.name] = {
                    "type": "gauge",
                    "value": metric.value,
                    "labels": metric.labels,
                }
            elif isinstance(metric, Histogram):
                data["metrics"][metric.name] = {
                    "type": "histogram",
                    "buckets": {str(k): v for k, v in histogram.bucket_values.items()},
                    "sum": metric.sum,
                    "count": metric.count,
                    "labels": metric.labels,
                }

        # Write to file
        mode = "a" if self.append else "w"
        with open(self.file_path, mode) as f:
            json.dump(data, f)
            f.write("\n")

        logger.info(f"Exported metrics to {self.file_path}", metric_count=len(metrics))



================================================
File: src/mcp_core/models/__init__.py
================================================
"""Models package for MCP Core data structures."""

from .request import CoreRequest, RequestContext
from .response import CoreResponse, ErrorResponse

__all__ = ["CoreRequest", "RequestContext", "CoreResponse", "ErrorResponse"]



================================================
File: src/mcp_core/models/request.py
================================================
"""Request models for MCP Core."""

import time
import uuid
from typing import Any, Dict, Optional

from pydantic import BaseModel, Field, validator


class RequestContext(BaseModel):
    """Context information for a request."""

    correlation_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: float = Field(default_factory=time.time)
    user_id: Optional[str] = None
    session_id: Optional[str] = None
    source: Optional[str] = None
    extra: Dict[str, Any] = Field(default_factory=dict)

    class Config:
        """Pydantic configuration."""

        json_encoders = {uuid.UUID: str}


class CoreRequest(BaseModel):
    """Core request model for MCP."""

    tool_name: str
    parameters: Dict[str, Any] = Field(default_factory=dict)
    context: RequestContext = Field(default_factory=RequestContext)
    version: Optional[str] = None
    timeout: Optional[float] = None

    @validator("timeout")
    def validate_timeout(cls, value: Optional[float]) -> Optional[float]:
        """Validate timeout is positive."""
        if value is not None and value <= 0:
            raise ValueError("Timeout must be positive")
        return value



================================================
File: src/mcp_core/models/response.py
================================================
"""Response models for MCP Core."""

import time
from typing import Any, Dict, Optional, Union

from pydantic import BaseModel, Field


class ErrorDetail(BaseModel):
    """Details for an error response."""

    code: str
    message: str
    details: Dict[str, Any] = Field(default_factory=dict)


class ErrorResponse(BaseModel):
    """Error response model."""

    success: bool = False
    error: ErrorDetail
    correlation_id: Optional[str] = None
    timestamp: float = Field(default_factory=time.time)


class CoreResponse(BaseModel):
    """Core response model for MCP."""

    success: bool = True
    data: Optional[Dict[str, Any]] = None
    correlation_id: Optional[str] = None
    timestamp: float = Field(default_factory=time.time)
    tool_name: Optional[str] = None
    version: Optional[str] = None
    execution_time: Optional[float] = None

    @classmethod
    def from_error(
        cls,
        error: Union[ErrorDetail, Exception],
        correlation_id: Optional[str] = None,
        tool_name: Optional[str] = None,
        version: Optional[str] = None,
    ) -> ErrorResponse:
        """Create an error response from an error.

        Args:
            error: Error detail or exception
            correlation_id: Request correlation ID
            tool_name: Tool name
            version: Tool version

        Returns:
            ErrorResponse: Error response model
        """
        if isinstance(error, Exception) and not isinstance(error, ErrorDetail):
            error_detail = ErrorDetail(
                code="INTERNAL_ERROR",
                message=str(error),
                details={"exception_type": error.__class__.__name__},
            )
        else:
            error_detail = error  # type: ignore

        return ErrorResponse(
            error=error_detail, correlation_id=correlation_id, timestamp=time.time()
        )



================================================
File: src/mcp_core/validation/__init__.py
================================================
"""Validation package for MCP Core."""

from .schemas import (
    ToolSchema,
    get_tool_schema,
    list_tool_schemas,
    register_tool_schema,
)
from .validators import validate_request, validate_tool_parameters

__all__ = [
    "validate_request",
    "validate_tool_parameters",
    "ToolSchema",
    "register_tool_schema",
    "get_tool_schema",
    "list_tool_schemas",
]



================================================
File: src/mcp_core/validation/schemas.py
================================================
"""JSON Schema definitions for tool validation."""

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field

from ..errors import ValidationError
from ..logger import logger


class ParameterSchema(BaseModel):
    """Schema for a tool parameter."""

    name: str
    type: str
    description: str
    required: bool = False
    default: Optional[Any] = None
    enum: Optional[List[Any]] = None
    pattern: Optional[str] = None
    min_value: Optional[float] = None
    max_value: Optional[float] = None

    def to_json_schema(self) -> Dict[str, Any]:
        """Convert to JSON Schema format.

        Returns:
            Dict[str, Any]: JSON Schema for this parameter
        """
        schema: Dict[str, Any] = {"type": self.type, "description": self.description}

        if self.default is not None:
            schema["default"] = self.default

        if self.enum:
            schema["enum"] = self.enum

        if self.pattern and self.type == "string":
            schema["pattern"] = self.pattern

        if self.min_value is not None:
            if self.type == "string":
                schema["minLength"] = int(self.min_value)
            elif self.type in ["number", "integer"]:
                schema["minimum"] = self.min_value
            elif self.type == "array":
                schema["minItems"] = int(self.min_value)

        if self.max_value is not None:
            if self.type == "string":
                schema["maxLength"] = int(self.max_value)
            elif self.type in ["number", "integer"]:
                schema["maximum"] = self.max_value
            elif self.type == "array":
                schema["maxItems"] = int(self.max_value)

        return schema


class ToolSchema(BaseModel):
    """Schema definition for a tool."""

    name: str
    version: str
    description: str
    parameters: List[ParameterSchema]
    required_parameters: List[str] = Field(default_factory=list)

    def to_json_schema(self) -> Dict[str, Any]:
        """Convert to JSON Schema format.

        Returns:
            Dict[str, Any]: JSON Schema for this tool
        """
        properties = {}
        for param in self.parameters:
            properties[param.name] = param.to_json_schema()

        return {
            "type": "object",
            "title": f"{self.name} v{self.version}",
            "description": self.description,
            "properties": properties,
            "required": self.required_parameters,
        }


# Registry for tool schemas
_tool_schemas: Dict[str, Dict[str, ToolSchema]] = {}


def register_tool_schema(schema: ToolSchema) -> None:
    """Register a tool schema.

    Args:
        schema: Tool schema to register

    Raises:
        ValidationError: If schema is already registered
    """
    if schema.name not in _tool_schemas:
        _tool_schemas[schema.name] = {}

    if schema.version in _tool_schemas[schema.name]:
        raise ValidationError(
            f"Schema for tool {schema.name} version {schema.version} already registered"
        )

    _tool_schemas[schema.name][schema.version] = schema
    logger.info(
        f"Registered schema for tool {schema.name} version {schema.version}",
        tool=schema.name,
        version=schema.version,
    )


def get_tool_schema(name: str, version: Optional[str] = None) -> ToolSchema:
    """Get a tool schema.

    Args:
        name: Tool name
        version: Tool version (latest if None)

    Returns:
        ToolSchema: Tool schema

    Raises:
        ValidationError: If schema not found
    """
    if name not in _tool_schemas:
        raise ValidationError(f"No schema registered for tool {name}")

    if version is None:
        # Get latest version
        version = max(_tool_schemas[name].keys())

    if version not in _tool_schemas[name]:
        raise ValidationError(f"No schema registered for tool {name} version {version}")

    return _tool_schemas[name][version]


def list_tool_schemas() -> Dict[str, List[str]]:
    """List all registered tool schemas.

    Returns:
        Dict[str, List[str]]: Map of tool names to lists of versions
    """
    return {name: list(versions.keys()) for name, versions in _tool_schemas.items()}



================================================
File: src/mcp_core/validation/validators.py
================================================
"""Validation functions for MCP Core."""

from typing import Any, Dict, Optional

import jsonschema

from ..errors import ValidationError
from ..logger import logger
from ..models.request import CoreRequest
from .schemas import get_tool_schema


def validate_request(request: CoreRequest) -> None:
    """Validate a request.

    Args:
        request: Request to validate

    Raises:
        ValidationError: If validation fails
    """
    # Validate basic request structure
    if not request.tool_name:
        raise ValidationError("Tool name is required")

    # Validate tool parameters against schema if available
    try:
        validate_tool_parameters(request.tool_name, request.parameters, request.version)
    except ValidationError as e:
        logger.warning(
            f"Validation failed for tool {request.tool_name}",
            tool=request.tool_name,
            correlation_id=request.context.correlation_id,
            error=str(e),
        )
        raise


def validate_tool_parameters(
    tool_name: str, parameters: Dict[str, Any], version: Optional[str] = None
) -> None:
    """Validate tool parameters against schema.

    Args:
        tool_name: Tool name
        parameters: Parameters to validate
        version: Tool version (latest if None)

    Raises:
        ValidationError: If validation fails
    """
    try:
        # Get tool schema
        schema = get_tool_schema(tool_name, version)
        json_schema = schema.to_json_schema()

        # Validate against JSON Schema
        try:
            jsonschema.validate(instance=parameters, schema=json_schema)
        except jsonschema.exceptions.ValidationError as e:
            raise ValidationError(
                f"Parameter validation failed: {e.message}",
                details={
                    "path": list(e.path),
                    "validator": e.validator,
                    "validator_value": e.validator_value,
                },
            ) from e
    except ValidationError as e:
        if "No schema registered" in str(e):
            # No schema available, just log and continue
            logger.warning(
                f"No schema available for tool {tool_name}, skipping validation",
                tool=tool_name,
                version=version,
            )
            return

        # Re-raise other validation errors
        raise



================================================
File: src/mcp_proxy/__init__.py
================================================
"""MCP Proxy Connection Server."""

from .config.config import ProxyConfig, get_proxy_config

__version__ = "1.0.0"

__all__ = ["ProxyConfig", "get_proxy_config"]



================================================
File: src/mcp_proxy/__main__.py
================================================
"""Main entry point for MCP Proxy server."""

from contextlib import asynccontextmanager

import uvicorn
from fastapi import FastAPI

from .config.config import get_proxy_config
from .proxy_server import ProxyServer


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifecycle manager.

    Args:
        app: FastAPI application
    """
    # Initialize proxy server
    proxy_server = ProxyServer(app)
    app.state.proxy_server = proxy_server

    # Start the server
    await proxy_server.start()

    yield

    # Shutdown the server
    await proxy_server.stop()


def create_app() -> FastAPI:
    """Create FastAPI application.

    Returns:
        FastAPI: Application instance
    """
    app = FastAPI(
        title="MCP Proxy Server",
        description="Proxy server for Model Context Protocol",
        version="1.0.0",
        lifespan=lifespan,
    )

    return app


async def async_main() -> int:
    """Async main entry point.

    Returns:
        int: Exit code
    """
    # Create FastAPI application
    app = create_app()

    # Get configuration
    config = get_proxy_config()

    # Initialize proxy server
    proxy_server = ProxyServer(app)

    try:
        # Start the server
        await proxy_server.start()

        # In a real implementation, we would keep the server running
        # For now, just log and return success
        return 0
    except Exception as e:
        print(f"Error starting proxy server: {e}")
        return 1


def main() -> int:
    """Main entry point.

    Returns:
        int: Exit code
    """
    # Create FastAPI application
    app = create_app()

    # Get configuration
    config = get_proxy_config()

    # Start server
    uvicorn.run(
        app,
        host=config.sse_host,
        port=config.sse_port,
        log_level="info",
    )

    return 0


if __name__ == "__main__":
    main()



================================================
File: src/mcp_proxy/errors.py
================================================
"""Error definitions for MCP Proxy."""

from typing import Dict, Optional


class ProxyError(Exception):
    """Base error for MCP Proxy system."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        self.message = message
        self.details = details or {}
        super().__init__(message)


class TransportError(ProxyError):
    """Transport-related errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(f"Transport error: {message}", details)


class ConnectionError(ProxyError):
    """Connection-related errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(f"Connection error: {message}", details)


class MessageError(ProxyError):
    """Message-related errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(f"Message error: {message}", details)


class ConfigError(ProxyError):
    """Configuration-related errors."""

    def __init__(self, message: str, details: Optional[Dict] = None):
        super().__init__(f"Configuration error: {message}", details)



================================================
File: src/mcp_proxy/health.py
================================================
"""Health check functionality for MCP Proxy."""

import asyncio
import os
import platform
import time
from typing import Dict

from .config import get_proxy_config


async def check_health() -> Dict:
    """Check the health of the proxy server.

    Returns:
        Dict: Health check result
    """
    config = get_proxy_config()
    start_time = time.time()

    # Overall health status
    health = {
        "service": "mcp_proxy",
        "timestamp": start_time,
        "healthy": True,
        "version": config.server.version,
        "checks": {},
    }

    # Check system health
    system_health = await check_system_health()
    health["checks"]["system"] = system_health

    # Check MCP Core connectivity
    core_health = await check_core_connectivity()
    health["checks"]["core_connectivity"] = core_health

    # Check transport health
    transport_health = await check_transport_health()
    health["checks"]["transports"] = transport_health

    # Update overall health status
    health["healthy"] = (
        system_health.get("healthy", False)
        and core_health.get("healthy", False)
        and transport_health.get("healthy", False)
    )

    # Add response time
    health["response_time"] = time.time() - start_time

    return health


async def check_system_health() -> Dict:
    """Check system health.

    Returns:
        Dict: System health check result
    """
    # Simple system information check
    try:
        # Collect system information
        return {
            "healthy": True,
            "platform": platform.platform(),
            "python_version": platform.python_version(),
            "cpu_count": os.cpu_count(),
            "memory_info": "N/A",  # Would use psutil in a real implementation
        }
    except Exception as e:
        return {"healthy": False, "error": str(e)}


async def check_core_connectivity() -> Dict:
    """Check connectivity to MCP Core.

    Returns:
        Dict: Connectivity health check result
    """
    # This is a placeholder - in a real implementation, you would
    # make a request to the MCP Core service

    config = get_proxy_config()

    try:
        # Simulate a check
        await asyncio.sleep(0.1)

        # For now, just return success
        return {
            "healthy": True,
            "core_url": config.core.url,
            "latency_ms": 10,  # Simulated latency
        }
    except Exception as e:
        return {"healthy": False, "core_url": config.core.url, "error": str(e)}


async def check_transport_health() -> Dict:
    """Check transport health.

    Returns:
        Dict: Transport health check result
    """
    # This is a placeholder - in a real implementation, you would
    # check the health of each transport

    try:
        # Simulate a check
        await asyncio.sleep(0.1)

        # For now, just return success for all transports
        return {
            "healthy": True,
            "transports": {
                "websocket": {"healthy": True},
                "sse": {"healthy": True},
                "stdio": {"healthy": True},
            },
        }
    except Exception as e:
        return {"healthy": False, "error": str(e)}



================================================
File: src/mcp_proxy/proxy_server.py
================================================
"""MCP Proxy server implementation."""

import asyncio
import logging
import os
import sys

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect

from .config import get_proxy_config
from .errors import ProxyError
from .health import check_health
from .router import MessageRouter
from .transports import StdioHandler, TransportManager

# Configure logging
logger = logging.getLogger(__name__)


class ProxyServer:
    """MCP Proxy server."""

    def __init__(self, app: FastAPI):
        """Initialize the proxy server.

        Args:
            app: FastAPI application
        """
        self.app = app
        self.config = get_proxy_config()
        self.transport_manager = TransportManager()
        self.active_connections: set[WebSocket] = set()
        self.message_router = MessageRouter()
        self.core_process = None
        self.core_connection_id = None

        # Register routes
        self._register_routes()

    def _register_routes(self) -> None:
        """Register API routes."""

        # WebSocket endpoint
        @self.app.websocket("/ws")
        async def websocket_endpoint(websocket: WebSocket):
            await self._handle_websocket(websocket)

        # Health check endpoint
        @self.app.get("/health")
        async def health_check():
            health_status = await check_health()
            if not health_status.get("healthy", False):
                raise HTTPException(status_code=503, detail=health_status)
            return health_status

        # Tool execution endpoint
        @self.app.post("/execute/{tool_name}")
        async def execute_tool(tool_name: str, request: dict):
            try:
                return await self._execute_tool(tool_name, request)
            except ProxyError as e:
                raise HTTPException(status_code=400, detail=str(e))
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))

    async def _handle_websocket(self, websocket: WebSocket) -> None:
        """Handle WebSocket connection.

        Args:
            websocket: WebSocket connection
        """
        await websocket.accept()
        self.active_connections.add(websocket)

        try:
            while True:
                data = await websocket.receive_json()

                # Process the message
                response = await self._process_message(data)

                # Send response
                await websocket.send_json(response)
        except WebSocketDisconnect:
            self.active_connections.remove(websocket)
        except Exception as e:
            # Send error response
            try:
                await websocket.send_json(
                    {"success": False, "error": {"message": str(e)}}
                )
            except:
                pass

            # Remove connection
            self.active_connections.remove(websocket)

    async def _process_message(self, message: dict) -> dict:
        """Process incoming message.

        Args:
            message: Message data

        Returns:
            Dict: Response data
        """
        # Validate message structure
        if "action" not in message:
            raise ProxyError("Missing 'action' field in message")

        action = message.get("action")

        if action == "execute_tool":
            # Execute tool
            tool_name = message.get("tool_name")
            if not tool_name:
                raise ProxyError("Missing 'tool_name' field for execute_tool action")

            parameters = message.get("parameters", {})
            return await self._execute_tool(tool_name, parameters)
        elif action == "health_check":
            # Health check
            return await check_health()
        else:
            # Unknown action
            raise ProxyError(f"Unknown action: {action}")

    async def _execute_tool(self, tool_name: str, parameters: dict) -> dict:
        """Execute a tool.

        Args:
            tool_name: Name of the tool
            parameters: Tool parameters

        Returns:
            Dict: Tool execution result
        """
        if not self.core_connection_id:
            raise ProxyError("Core layer not available")

        # Create a message for the Core layer
        message = {
            "action": "execute_tool",
            "tool_name": tool_name,
            "parameters": parameters,
            "request_id": str(asyncio.get_event_loop().time()),
        }

        # Send the message to the Core layer via the router
        await self.message_router.route_message(message, source_id=None)

        # In a real implementation, we would wait for a response from the Core layer
        # For now, return a placeholder
        return {
            "success": True,
            "data": {
                "tool_name": tool_name,
                "parameters": parameters,
                "result": "Tool execution request sent to Core layer",
            },
        }

    async def _setup_core_process(self) -> None:
        """Set up the Core process."""
        # Get the path to the run_server.py script
        run_server_path = os.path.join(os.path.dirname(__file__), "..", "run_server.py")

        # Set up environment variables
        env = os.environ.copy()
        env["MCP_COMPONENTS"] = "core"
        env["MCP_TRANSPORT"] = "stdio"

        # Create a StdioHandler for the Core process
        stdio_handler = StdioHandler(
            command=sys.executable,
            args=[run_server_path, "--mode", "core", "--transport", "stdio"],
            env=env,
        )

        # Set the message router
        stdio_handler.set_message_router(self.message_router)

        # Initialize the handler (spawns the process)
        await stdio_handler.initialize()

        # Create a connection in the router for the Core layer
        self.core_connection_id = await self.message_router.create_connection()

        # Subscribe to the broadcast topic
        await self.message_router.subscribe(self.core_connection_id, "broadcast")

        # Store the handler
        self.core_process = stdio_handler

        logger.info("Core process initialized")

    async def start(self) -> None:
        """Start the proxy server."""
        # Initialize message router
        await self.message_router.start()

        # Set up Core process
        await self._setup_core_process()

        # Initialize transport manager
        await self.transport_manager.initialize()

        logger.info("Proxy server started")

    async def stop(self) -> None:
        """Stop the proxy server."""
        # Close all WebSocket connections
        for connection in self.active_connections:
            try:
                await connection.close()
            except:
                pass

        # Shutdown transport manager
        await self.transport_manager.shutdown()

        # Shutdown Core process
        if self.core_process:
            await self.core_process.shutdown()

        # Shutdown message router
        await self.message_router.stop()

        logger.info("Proxy server stopped")



================================================
File: src/mcp_proxy/router.py
================================================
"""Message routing for MCP Proxy.

This module implements the MessageRouter which is responsible for routing messages
between different transports, such as between the stdio handler and SSE/WebSocket clients.
"""

import asyncio
import logging
import uuid

# Configure logging
logger = logging.getLogger(__name__)


class MessageRouter:
    """Routes messages between transports and clients.

    This class manages connections and subscriptions, routing messages between
    the proxy server components and the core layer.
    """

    def __init__(self):
        """Initialize the router."""
        self.connections: dict[str, asyncio.Queue] = {}
        self.subscriptions: dict[str, set[str]] = {}
        self.running = False
        self.router_task = None

    async def start(self) -> None:
        """Start the message router."""
        self.running = True
        logger.info("Message router started")

    async def stop(self) -> None:
        """Stop the message router."""
        self.running = False

        # Cancel router task if running
        if self.router_task:
            self.router_task.cancel()

        # Clear all queues
        for connection_id, queue in self.connections.items():
            # Add a sentinel to unblock any consumers
            await queue.put(None)

        logger.info("Message router stopped")

    async def create_connection(self) -> str:
        """Create a new connection and return its ID.

        Returns:
            str: The new connection ID
        """
        connection_id = str(uuid.uuid4())
        self.connections[connection_id] = asyncio.Queue()
        logger.debug(f"Created new connection: {connection_id}")
        return connection_id

    async def close_connection(self, connection_id: str) -> None:
        """Close and remove a connection.

        Args:
            connection_id: The connection ID to close
        """
        if connection_id in self.connections:
            # Remove from all subscriptions
            for topic, subscribers in self.subscriptions.items():
                subscribers.discard(connection_id)

            # Remove the connection
            queue = self.connections.pop(connection_id)
            await queue.put(None)  # Add sentinel to unblock consumers

            logger.debug(f"Closed connection: {connection_id}")

    async def subscribe(self, connection_id: str, topic: str) -> None:
        """Subscribe a connection to a topic.

        Args:
            connection_id: The connection ID
            topic: The topic to subscribe to
        """
        if connection_id not in self.connections:
            raise ValueError(f"Connection not found: {connection_id}")

        if topic not in self.subscriptions:
            self.subscriptions[topic] = set()

        self.subscriptions[topic].add(connection_id)
        logger.debug(f"Connection {connection_id} subscribed to topic: {topic}")

    async def unsubscribe(self, connection_id: str, topic: str) -> None:
        """Unsubscribe a connection from a topic.

        Args:
            connection_id: The connection ID
            topic: The topic to unsubscribe from
        """
        if topic in self.subscriptions:
            self.subscriptions[topic].discard(connection_id)
            logger.debug(f"Connection {connection_id} unsubscribed from topic: {topic}")

    async def route_message(self, message: dict, source_id: str | None = None) -> None:
        """Route a message to subscribed connections.

        Args:
            message: The message to route
            source_id: Optional source connection ID to exclude from routing
        """
        topic = message.get("topic", "broadcast")
        subscribers = self.subscriptions.get(topic, set())

        # Also include broadcast subscribers if this is not a broadcast topic
        if topic != "broadcast":
            subscribers = subscribers.union(self.subscriptions.get("broadcast", set()))

        logger.debug(
            f"Routing message to {len(subscribers)} subscribers for topic: {topic}"
        )

        for connection_id in subscribers:
            # Skip the source connection to avoid echo
            if connection_id == source_id:
                continue

            if connection_id in self.connections:
                await self.connections[connection_id].put(message)

    async def get_message(
        self, connection_id: str, timeout: float | None = None
    ) -> dict | None:
        """Get a message for a connection.

        Args:
            connection_id: The connection ID
            timeout: Optional timeout in seconds

        Returns:
            Optional[Dict]: The message or None if timeout or connection closed
        """
        if connection_id not in self.connections:
            raise ValueError(f"Connection not found: {connection_id}")

        queue = self.connections[connection_id]

        try:
            if timeout:
                message = await asyncio.wait_for(queue.get(), timeout)
            else:
                message = await queue.get()

            # Handle sentinel value
            if message is None:
                return None

            return message
        except asyncio.TimeoutError:
            return None



================================================
File: src/mcp_proxy/config/config.py
================================================
from typing import List

from pydantic import BaseSettings, Field


class ProxyConfig(BaseSettings):
    """MCP Proxy configuration."""

    # SSE settings
    sse_host: str = Field(default="127.0.0.1", env="MCP_SSE_HOST")
    sse_port: int = Field(default=8080, env="MCP_SSE_PORT")

    # stdio settings
    stdio_buffer_size: int = Field(default=4096, env="MCP_STDIO_BUFFER_SIZE")
    stdio_encoding: str = Field(default="utf-8", env="MCP_STDIO_ENCODING")

    # Connection settings
    connection_timeout: int = Field(default=30, env="MCP_CONNECTION_TIMEOUT")
    keep_alive_interval: int = Field(default=15, env="MCP_KEEPALIVE_INTERVAL")

    # Security
    allowed_origins: List[str] = Field(default_factory=list)
    auth_required: bool = Field(default=False, env="MCP_AUTH_REQUIRED")

    class Config:
        env_prefix = "MCP_"
        case_sensitive = False


def get_proxy_config() -> ProxyConfig:
    """Get proxy configuration instance."""
    return ProxyConfig()



================================================
File: src/mcp_proxy/transports/__init__.py
================================================
"""Transport mechanisms for MCP Proxy."""

from typing import Dict, List, Type

from .base_transport import BaseTransport
from .sse import SSETransport
from .stdio import StdioHandler
from .websocket import WebSocketTransport


class TransportManager:
    """Manages different transport mechanisms."""

    def __init__(self):
        """Initialize transport manager."""
        self.transports: dict[str, BaseTransport] = {}

        # Register default transports
        self.register_transport("websocket", WebSocketTransport())
        self.register_transport("sse", SSETransport())
        self.register_transport("stdio", StdioHandler())

    def register_transport(self, name: str, transport: BaseTransport) -> None:
        """Register a transport.

        Args:
            name: Transport name
            transport: Transport instance
        """
        self.transports[name] = transport

    def get_transport(self, name: str) -> BaseTransport:
        """Get a transport by name.

        Args:
            name: Transport name

        Returns:
            BaseTransport: Transport instance

        Raises:
            KeyError: If transport not found
        """
        if name not in self.transports:
            raise KeyError(f"Transport not found: {name}")

        return self.transports[name]

    def list_transports(self) -> list[str]:
        """List available transports.

        Returns:
            List[str]: List of transport names
        """
        return list(self.transports.keys())

    async def initialize(self) -> None:
        """Initialize all transports."""
        for name, transport in self.transports.items():
            await transport.initialize()

    async def shutdown(self) -> None:
        """Shutdown all transports."""
        for name, transport in self.transports.items():
            await transport.shutdown()


__all__ = [
    "BaseTransport",
    "SSETransport",
    "StdioHandler",
    "WebSocketTransport",
    "TransportManager",
]



================================================
File: src/mcp_proxy/transports/base_transport.py
================================================
"""Base transport interface for MCP Proxy."""

from abc import ABC, abstractmethod
from typing import Any, Dict, Optional


class BaseTransport(ABC):
    """Base class for transport implementations."""

    @abstractmethod
    async def initialize(self) -> None:
        """Initialize the transport."""
        pass

    @abstractmethod
    async def shutdown(self) -> None:
        """Shutdown the transport."""
        pass

    @abstractmethod
    async def send_message(
        self, message: Dict[str, Any], client_id: Optional[str] = None
    ) -> None:
        """Send a message to a client.

        Args:
            message: Message to send
            client_id: Target client ID (None for broadcast)
        """
        pass

    @abstractmethod
    async def receive_message(
        self, client_id: str, timeout: Optional[float] = None
    ) -> Optional[Dict[str, Any]]:
        """Receive a message from a client.

        Args:
            client_id: Client ID
            timeout: Receive timeout in seconds

        Returns:
            Optional[Dict[str, Any]]: Received message or None if timeout
        """
        pass



================================================
File: src/mcp_proxy/transports/sse.py
================================================
"""Server-Sent Events (SSE) transport for MCP Proxy."""

import asyncio
import json
import uuid
from typing import Any, Dict, Optional

from fastapi import FastAPI, Request
from sse_starlette.sse import EventSourceResponse

from .base_transport import BaseTransport


class SSEConnection:
    """SSE connection wrapper."""

    def __init__(self, client_id: str):
        """Initialize SSE connection.

        Args:
            client_id: Client ID
        """
        self.client_id = client_id
        self.message_queue: asyncio.Queue = asyncio.Queue()
        self.connected = True


class SSETransport(BaseTransport):
    """SSE transport implementation."""

    def __init__(self):
        """Initialize SSE transport."""
        self.connections: Dict[str, SSEConnection] = {}
        self.app: Optional[FastAPI] = None

    async def initialize(self) -> None:
        """Initialize the transport."""
        # Nothing to do for initialization
        pass

    async def shutdown(self) -> None:
        """Shutdown the transport."""
        # Clear connections
        self.connections.clear()

    def register_with_app(self, app: FastAPI) -> None:
        """Register routes with FastAPI app.

        Args:
            app: FastAPI application
        """
        self.app = app

        @app.get("/sse")
        async def sse_endpoint(request: Request):
            client_id = str(uuid.uuid4())
            return await self._create_sse_response(request, client_id)

        @app.post("/sse/{client_id}/send")
        async def send_to_sse(client_id: str, message: Dict[str, Any]):
            await self.send_message(message, client_id)
            return {"success": True}

    async def _create_sse_response(
        self, request: Request, client_id: str
    ) -> EventSourceResponse:
        """Create SSE response.

        Args:
            request: HTTP request
            client_id: Client ID

        Returns:
            EventSourceResponse: SSE response
        """
        connection = SSEConnection(client_id)
        self.connections[client_id] = connection

        async def event_generator():
            try:
                # Send initial connection message
                yield {
                    "event": "connected",
                    "data": json.dumps({"client_id": client_id}),
                }

                # Process messages
                while connection.connected:
                    if await request.is_disconnected():
                        break

                    try:
                        message = await asyncio.wait_for(
                            connection.message_queue.get(), timeout=1.0
                        )

                        if message is None:
                            break

                        yield {
                            "event": message.get("event", "message"),
                            "data": json.dumps(message),
                        }

                        connection.message_queue.task_done()
                    except asyncio.TimeoutError:
                        # Just check for disconnection again
                        continue
            finally:
                # Clean up
                connection.connected = False
                if client_id in self.connections:
                    del self.connections[client_id]

        return EventSourceResponse(event_generator())

    async def send_message(
        self, message: Dict[str, Any], client_id: Optional[str] = None
    ) -> None:
        """Send a message to a client.

        Args:
            message: Message to send
            client_id: Target client ID (None for broadcast)
        """
        if client_id is not None:
            # Send to specific client
            if client_id in self.connections and self.connections[client_id].connected:
                await self.connections[client_id].message_queue.put(message)
        else:
            # Broadcast to all clients
            for connection in self.connections.values():
                if connection.connected:
                    await connection.message_queue.put(message)

    async def receive_message(
        self, client_id: str, timeout: Optional[float] = None
    ) -> Optional[Dict[str, Any]]:
        """Receive a message from a client.

        Note: SSE is a one-way transport, so this is not supported.

        Args:
            client_id: Client ID
            timeout: Receive timeout in seconds

        Returns:
            Optional[Dict[str, Any]]: Received message or None if timeout
        """
        # SSE is a one-way transport (server to client)
        # This method is not supported
        return None



================================================
File: src/mcp_proxy/transports/stdio.py
================================================
"""Standard I/O transport for MCP Proxy.

This module implements the StdioHandler which is responsible for spawning
and communicating with the Core Layer process.
"""

import asyncio
import json
import logging
import os
import sys
from typing import Any, TextIO

from .base_transport import BaseTransport

# Configure logging
logger = logging.getLogger(__name__)


class StdioHandler(BaseTransport):
    """Handles stdio communication with processes.

    This transport is designed for subprocess communication where
    the client is a child process communicating via stdin/stdout.
    """

    def __init__(
        self,
        command: str | None = None,
        args: list[str] | None = None,
        env: dict[str, str] | None = None,
        input_stream: TextIO | None = None,
        output_stream: TextIO | None = None,
    ):
        """Initialize stdio handler.

        Args:
            command: Command to execute (if None, use existing streams)
            args: Command arguments
            env: Environment variables
            input_stream: Input stream (defaults to sys.stdin if command is None)
            output_stream: Output stream (defaults to sys.stdout if command is None)
        """
        self.command = command
        self.args = args or []
        self.env = env or {}
        self.input_stream = input_stream
        self.output_stream = output_stream
        self.process: asyncio.subprocess.Process | None = None
        self.message_queue: asyncio.Queue = asyncio.Queue()
        self.running = False
        self.reader_task = None
        self.writer_task = None
        self.process_id = None
        self.message_router = None

    async def initialize(self) -> None:
        """Initialize the transport."""
        self.running = True

        if self.command:
            # Spawn process
            await self._spawn_process()
        else:
            # Use existing streams
            self.input_stream = self.input_stream or sys.stdin
            self.output_stream = self.output_stream or sys.stdout

        # Start reader and writer tasks
        self.reader_task = asyncio.create_task(self._reader())
        self.writer_task = asyncio.create_task(self._writer())

        logger.info("StdioHandler initialized")

    async def shutdown(self) -> None:
        """Shutdown the transport."""
        self.running = False

        # Cancel tasks
        if self.reader_task:
            self.reader_task.cancel()

        if self.writer_task:
            await self.message_queue.put(None)  # Signal writer to exit
            await self.writer_task

        # Terminate process if we spawned it
        if self.process:
            try:
                self.process.terminate()
                await self.process.wait()
            except ProcessLookupError:
                pass  # Process already terminated

        logger.info("StdioHandler shutdown")

    async def _spawn_process(self) -> None:
        """Spawn a new process."""
        if not self.command:
            logger.error("Cannot spawn process: no command specified")
            return

        process_env = os.environ.copy()
        process_env.update(self.env)

        logger.info(f"Spawning process: {self.command} {' '.join(self.args)}")

        self.process = await asyncio.create_subprocess_exec(
            self.command,
            *self.args,
            env=process_env,
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )

        self.process_id = str(self.process.pid)
        logger.info(f"Process spawned with PID: {self.process_id}")

        # Start stderr reader
        asyncio.create_task(self._read_stderr())

    async def _read_stderr(self) -> None:
        """Read and log from process stderr."""
        if not self.process or not self.process.stderr:
            return

        while self.running:
            try:
                line = await self.process.stderr.readline()
                if not line:
                    break

                stderr_line = line.decode().strip()
                logger.warning(f"Process stderr: {stderr_line}")

                # Route stderr message if router is available
                if self.message_router:
                    await self.message_router.route_message(
                        {
                            "type": "process_stderr",
                            "process_id": self.process_id,
                            "data": stderr_line,
                        }
                    )
            except Exception as e:
                logger.error(f"Error reading stderr: {e}")
                if not self.running:
                    break

    async def _reader(self) -> None:
        """Read messages from input stream or process stdout."""
        try:
            if self.process and self.process.stdout:
                # Read from process stdout
                while self.running:
                    line = await self.process.stdout.readline()
                    if not line:
                        logger.info("Process stdout closed")
                        break

                    await self._process_input_line(line)
            else:
                # Read from input_stream
                if not self.input_stream:
                    logger.error("Cannot read: no input stream available")
                    return

                loop = asyncio.get_event_loop()
                while self.running:
                    line = await loop.run_in_executor(None, self.input_stream.readline)
                    if not line:
                        logger.info("Input stream closed")
                        break

                    await self._process_input_line(line.encode())
        except Exception as e:
            logger.error(f"Reader error: {e}")
        finally:
            if self.running:
                logger.warning("Reader task exited unexpectedly")

    async def _process_input_line(self, line: bytes) -> None:
        """Process an input line."""
        try:
            # Parse JSON message
            message = json.loads(line.decode().strip())

            # Route message if router is available
            if self.message_router:
                await self.message_router.route_message(message)

            # Also handle message locally
            await self.message_queue.put(message)
        except json.JSONDecodeError:
            logger.warning(f"Invalid JSON: {line.decode().strip()}")
        except Exception as e:
            logger.error(f"Error processing input: {e}")

    async def _writer(self) -> None:
        """Write messages to output stream or process stdin."""
        try:
            while self.running:
                # Get message from queue
                message = await self.message_queue.get()

                if message is None:
                    # Exit signal
                    break

                # Serialize message to JSON
                json_str = json.dumps(message)

                if self.process and self.process.stdin:
                    # Write to process stdin
                    self.process.stdin.write(f"{json_str}\n".encode())
                    await self.process.stdin.drain()
                elif self.output_stream:
                    # Write to output_stream
                    loop = asyncio.get_event_loop()
                    await loop.run_in_executor(
                        None, lambda: self.output_stream.write(json_str + "\n")
                    )
                    await loop.run_in_executor(None, self.output_stream.flush)
                else:
                    logger.error("Cannot write: no output stream available")

                self.message_queue.task_done()
        except Exception as e:
            logger.error(f"Writer error: {e}")
        finally:
            if self.running:
                logger.warning("Writer task exited unexpectedly")

    async def send_message(
        self, message: dict[str, Any], client_id: str | None = None
    ) -> None:
        """Send a message to the process.

        Args:
            message: Message to send
            client_id: Target client ID (ignored for stdio)
        """
        await self.message_queue.put(message)

    async def receive_message(
        self, client_id: str, timeout: float | None = None
    ) -> dict[str, Any] | None:
        """Receive a message from the process.

        Args:
            client_id: Client ID (ignored for stdio)
            timeout: Receive timeout in seconds

        Returns:
            Optional[Dict[str, Any]]: Received message or None if timeout
        """
        # Not implemented for stdio transport
        # Messages are handled by the reader task
        return None

    def set_message_router(self, router) -> None:
        """Set the message router for this transport.

        Args:
            router: The message router instance
        """
        self.message_router = router



================================================
File: src/mcp_proxy/transports/websocket.py
================================================
"""WebSocket transport for MCP Proxy."""

import asyncio
import uuid
from typing import Any, Dict, Optional

from .base_transport import BaseTransport


class WebSocketConnection:
    """WebSocket connection wrapper."""

    def __init__(self, client_id: str):
        """Initialize WebSocket connection.

        Args:
            client_id: Client ID
        """
        self.client_id = client_id
        self.message_queue: asyncio.Queue = asyncio.Queue()
        self.connected = True


class WebSocketTransport(BaseTransport):
    """WebSocket transport implementation."""

    def __init__(self):
        """Initialize WebSocket transport."""
        self.connections: Dict[str, WebSocketConnection] = {}

    async def initialize(self) -> None:
        """Initialize the transport."""
        # Nothing to do for initialization
        pass

    async def shutdown(self) -> None:
        """Shutdown the transport."""
        # Clear connections
        self.connections.clear()

    async def register_client(self, websocket: Any) -> str:
        """Register a new WebSocket client.

        Args:
            websocket: WebSocket connection

        Returns:
            str: Client ID
        """
        client_id = str(uuid.uuid4())
        connection = WebSocketConnection(client_id)
        self.connections[client_id] = connection

        # Start message handler task
        asyncio.create_task(self._handle_websocket(websocket, client_id))

        return client_id

    async def _handle_websocket(self, websocket: Any, client_id: str) -> None:
        """Handle WebSocket connection.

        Args:
            websocket: WebSocket connection
            client_id: Client ID
        """
        connection = self.connections[client_id]

        # Message sending task
        async def sender():
            try:
                while connection.connected:
                    message = await connection.message_queue.get()
                    if message is None:
                        break
                    await websocket.send_json(message)
                    connection.message_queue.task_done()
            except Exception:
                connection.connected = False

        # Start sender task
        sender_task = asyncio.create_task(sender())

        try:
            # Main message receiving loop
            while connection.connected:
                try:
                    data = await websocket.receive_json()
                    # In a real implementation, you would process the message here
                    # For now, we just echo it back
                    await self.send_message(data, client_id)
                except Exception:
                    connection.connected = False
                    break
        finally:
            # Clean up
            connection.connected = False
            if client_id in self.connections:
                del self.connections[client_id]

            # Cancel sender task
            await connection.message_queue.put(None)
            await sender_task

    async def send_message(
        self, message: Dict[str, Any], client_id: Optional[str] = None
    ) -> None:
        """Send a message to a client.

        Args:
            message: Message to send
            client_id: Target client ID (None for broadcast)
        """
        if client_id is not None:
            # Send to specific client
            if client_id in self.connections and self.connections[client_id].connected:
                await self.connections[client_id].message_queue.put(message)
        else:
            # Broadcast to all clients
            for connection in self.connections.values():
                if connection.connected:
                    await connection.message_queue.put(message)

    async def receive_message(
        self, client_id: str, timeout: Optional[float] = None
    ) -> Optional[Dict[str, Any]]:
        """Receive a message from a client.

        Args:
            client_id: Client ID
            timeout: Receive timeout in seconds

        Returns:
            Optional[Dict[str, Any]]: Received message or None if timeout
        """
        if client_id not in self.connections:
            return None

        connection = self.connections[client_id]

        try:
            if timeout is not None:
                return await asyncio.wait_for(connection.message_queue.get(), timeout)
            else:
                return await connection.message_queue.get()
        except asyncio.TimeoutError:
            return None



================================================
File: src/mymcpserver/__init__.py
================================================
"""MCP Server - A centralized server for MCP tools."""

__version__ = "0.1.0"

from .server import main

__all__ = ["main"]



================================================
File: src/mymcpserver/server.py
================================================
"""MCP Server main module.

This module serves as the main entry point for the MCP Server, handling both the
Proxy Connection Server and MCP Core Layer initialization based on configuration.
It supports multiple transport mechanisms (HTTP, stdio) and provides proper
integration between all architectural layers.
"""

from __future__ import annotations

# Standard library imports
import argparse
import asyncio
import json
import logging
import os
import sys
from pathlib import Path
from typing import Any

# Third-party imports
import uvicorn
from dotenv import load_dotenv

# Add src directory to path to make imports work
sys.path.insert(0, str(Path(__file__).parent.parent))

# Application imports

# Load environment variables from .env file
load_dotenv()

# Configure logging
log_level = os.environ.get("MCP_LOG_LEVEL", "INFO").upper()
log_file = os.environ.get("MCP_LOG_FILE", "mcp_server.log")

logging.basicConfig(
    level=getattr(logging, log_level),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(log_file),
    ],
)
logger = logging.getLogger("mcp_server")


def get_config() -> dict[str, Any]:
    """Get server configuration from environment variables.

    Returns:
        Dict[str, Any]: Server configuration with host, port, log level,
            workers count, transport type, and component selection.
    """
    return {
        "host": os.environ.get("MCP_HOST", "127.0.0.1"),
        "port": int(os.environ.get("MCP_PORT", "8000")),
        "log_level": os.environ.get("MCP_LOG_LEVEL", "info").lower(),
        "workers": int(os.environ.get("MCP_WORKERS", "1")),
        "transport": os.environ.get("MCP_TRANSPORT", "http").lower(),
        "components": os.environ.get("MCP_COMPONENTS", "all").lower(),
    }


async def handle_stdio() -> None:
    """Handle stdio transport for MCP.

    This mode is used when the server is running as a subprocess
    and communicating through stdin/stdout. It implements the Proxy Connection
    Server functionality for stdio transport.
    """
    logger.info("Starting MCP Server in stdio mode")

    async def read_stdin() -> None:
        """Read from stdin and process messages.

        Continuously reads from stdin, processes messages, and sends responses back.
        This implements the main loop for the stdio transport.
        """
        while True:
            try:
                line = await asyncio.get_event_loop().run_in_executor(
                    None, sys.stdin.readline
                )
                if not line:
                    logger.info("Stdin closed, exiting")
                    return

                # Process the received message
                try:
                    message = json.loads(line)
                    logger.debug(f"Received message: {message}")

                    # Process the message through the Adapter/Registry Layer
                    # This is where we'd connect to the mcp_core layer
                    # For now, it's a placeholder
                    response = {
                        "success": True,
                        "message": "Received message",
                        "correlation_id": message.get("correlation_id", "unknown"),
                    }

                    print(json.dumps(response), flush=True)
                except json.JSONDecodeError:
                    logger.error(f"Invalid JSON received: {line}")
                    print(
                        json.dumps({"success": False, "error": "Invalid JSON"}),
                        flush=True,
                    )
            except Exception as e:
                logger.error(f"Error processing message: {str(e)}")
                print(json.dumps({"success": False, "error": str(e)}), flush=True)

    # Start reading from stdin
    await read_stdin()


def start_core_server(config: dict[str, Any]) -> None:
    """Start the MCP Core server.

    This function starts the FastAPI-based MCP Core Layer that handles
    the central business logic of the system.

    Args:
        config: Server configuration including host, port, log level, and workers.
    """
    logger.info(f"Starting MCP Core server on {config['host']}:{config['port']}")

    uvicorn.run(
        "mcp_core.app:app",
        host=config["host"],
        port=config["port"],
        log_level=config["log_level"],
        workers=config["workers"],
    )


def start_proxy_server(config: dict[str, Any]) -> None:
    """Start the Proxy Connection Server.

    This function starts the Proxy Connection Server which handles
    protocol translation between different transports.

    Args:
        config: Server configuration including transport type.
    """
    logger.info(
        f"Starting Proxy Connection Server with {config['transport']} transport"
    )

    # Depending on the transport, start the appropriate handler
    if config["transport"] == "stdio":
        asyncio.run(handle_stdio())
    else:
        # For non-stdio transports, use the ProxyServer class
        # This is a placeholder until the ProxyServer is fully implemented
        logger.error(f"Transport {config['transport']} not yet implemented")
        sys.exit(1)


def parse_args() -> argparse.Namespace:
    """Parse command line arguments.

    Returns:
        argparse.Namespace: Parsed arguments including transport, host, port,
            log level, and component selection.
    """
    parser = argparse.ArgumentParser(description="MCP Server")
    parser.add_argument(
        "--transport",
        choices=["http", "stdio", "sse", "websocket"],
        default="http",
        help="Transport mechanism (default: http)",
    )
    parser.add_argument(
        "--host", default="127.0.0.1", help="Host to bind to (default: 127.0.0.1)"
    )
    parser.add_argument(
        "--port", type=int, default=8000, help="Port to bind to (default: 8000)"
    )
    parser.add_argument(
        "--log-level",
        choices=["debug", "info", "warning", "error"],
        default="info",
        help="Logging level (default: info)",
    )
    parser.add_argument(
        "--component",
        choices=["all", "proxy", "core"],
        default="all",
        help="Component to start (default: all)",
    )

    return parser.parse_args()


def main() -> int:
    """Entry point for the MCP server.

    This is the main entry point that decides which components to start
    based on configuration and command line arguments.

    Returns:
        int: Exit code (0 for success, non-zero for errors)
    """
    logger.info("Initializing MCP Server...")

    try:
        # Parse command line arguments
        args = parse_args()

        # Get configuration, override with command line args
        config = get_config()
        if args.transport:
            config["transport"] = args.transport
        if args.host:
            config["host"] = args.host
        if args.port:
            config["port"] = args.port
        if args.log_level:
            config["log_level"] = args.log_level
        if args.component:
            config["components"] = args.component

        # Start the appropriate component(s)
        if config["components"] == "all":
            # In full mode, start both proxy and core
            # In a production environment, these would typically be separate processes
            # For development, we start the appropriate one based on transport
            if config["transport"] == "stdio":
                start_proxy_server(config)
            else:
                start_core_server(config)
        elif config["components"] == "proxy":
            # Start only the proxy server
            start_proxy_server(config)
        elif config["components"] == "core":
            # Start only the core server
            start_core_server(config)
        else:
            logger.error(f"Invalid component selection: {config['components']}")
            return 1

    except KeyboardInterrupt:
        logger.info("Server shutdown requested by user")
    except Exception as e:
        logger.error(f"Server error: {str(e)}")
        return 1

    logger.info("MCP Server shutdown complete")
    return 0


if __name__ == "__main__":
    sys.exit(main())



================================================
File: src/tool_servers/python/server.py
================================================
"""Python tool server for MCP."""

import importlib
import inspect
import logging
import os
import traceback
from typing import Any, Callable, Dict, List, Optional

import uvicorn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

# Configure basic logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("python_tool_server")


class ToolRequest(BaseModel):
    """Tool request model."""

    tool_name: str
    parameters: Dict[str, Any] = {}
    context: Optional[Dict[str, Any]] = None


class ToolResponse(BaseModel):
    """Tool response model."""

    success: bool
    data: Optional[Dict[str, Any]] = None
    error: Optional[Dict[str, Any]] = None


class ToolMetadata(BaseModel):
    """Tool metadata model."""

    name: str
    version: str
    description: str
    parameters: Dict[str, Dict[str, Any]] = {}
    examples: List[Dict[str, Any]] = []


class ToolDefinition:
    """Tool definition class."""

    def __init__(
        self,
        name: str,
        function: Callable,
        version: str = "1.0.0",
        description: str = "",
        metadata: Optional[ToolMetadata] = None,
    ):
        """Initialize tool definition.

        Args:
            name: Tool name
            function: Tool function
            version: Tool version
            description: Tool description
            metadata: Tool metadata
        """
        self.name = name
        self.function = function
        self.version = version
        self.description = description
        self.metadata = metadata or self._generate_metadata()

        # Check if function is async
        self.is_async = inspect.iscoroutinefunction(function)

    def _generate_metadata(self) -> ToolMetadata:
        """Generate tool metadata from function signature.

        Returns:
            ToolMetadata: Tool metadata
        """
        signature = inspect.signature(self.function)
        parameters = {}

        for name, param in signature.parameters.items():
            # Skip self/cls for methods
            if name in ["self", "cls"]:
                continue

            param_info = {"description": "", "type": "any"}

            # Get type annotation if available
            if param.annotation != inspect.Parameter.empty:
                if hasattr(param.annotation, "__name__"):
                    param_info["type"] = param.annotation.__name__.lower()
                else:
                    param_info["type"] = str(param.annotation)

            # Get default value if available
            if param.default != inspect.Parameter.empty:
                param_info["default"] = param.default
                param_info["required"] = False
            else:
                param_info["required"] = True

            parameters[name] = param_info

        # Get description from docstring
        doc = inspect.getdoc(self.function)
        description = doc.split("\n")[0] if doc else self.description

        return ToolMetadata(
            name=self.name,
            version=self.version,
            description=description,
            parameters=parameters,
        )

    async def execute(
        self, parameters: Dict[str, Any], context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Execute the tool.

        Args:
            parameters: Tool parameters
            context: Optional execution context

        Returns:
            Dict[str, Any]: Tool execution result
        """
        try:
            # Prepare parameters
            function_params = {}

            for name, param in inspect.signature(self.function).parameters.items():
                if name in ["self", "cls"]:
                    continue

                if name in parameters:
                    function_params[name] = parameters[name]
                elif (
                    context
                    and name == "context"
                    and param.default == inspect.Parameter.empty
                ):
                    # Inject context if parameter exists and doesn't have a default
                    function_params["context"] = context

            # Execute function
            if self.is_async:
                result = await self.function(**function_params)
            else:
                result = self.function(**function_params)

            # Convert result to dict if needed
            if not isinstance(result, dict):
                result = {"result": result}

            return result
        except Exception as e:
            logger.error(f"Error executing tool {self.name}: {str(e)}")
            raise


class PythonToolServer:
    """Python tool server implementation."""

    def __init__(self):
        """Initialize the tool server."""
        self.app = FastAPI(
            title="Python Tool Server",
            description="Tool server for Python-based MCP tools",
            version="1.0.0",
        )
        self.tools: Dict[str, ToolDefinition] = {}

        # Register routes
        self._register_routes()

    def _register_routes(self) -> None:
        """Register API routes."""

        @self.app.get("/health")
        async def health_check():
            return {"status": "healthy", "tools": list(self.tools.keys())}

        @self.app.post("/execute")
        async def execute_tool(request: ToolRequest):
            return await self._execute_tool(request)

        @self.app.get("/tools")
        async def list_tools():
            return {
                "tools": [
                    {
                        "name": tool.name,
                        "version": tool.version,
                        "description": tool.description,
                    }
                    for tool in self.tools.values()
                ]
            }

        @self.app.get("/tools/{tool_name}")
        async def get_tool_metadata(tool_name: str):
            if tool_name not in self.tools:
                raise HTTPException(
                    status_code=404, detail=f"Tool {tool_name} not found"
                )
            return self.tools[tool_name].metadata

    async def _execute_tool(self, request: ToolRequest) -> ToolResponse:
        """Execute a tool.

        Args:
            request: Tool request

        Returns:
            ToolResponse: Tool response
        """
        if request.tool_name not in self.tools:
            return ToolResponse(
                success=False, error={"message": f"Tool {request.tool_name} not found"}
            )

        try:
            # Execute the tool
            tool = self.tools[request.tool_name]
            result = await tool.execute(request.parameters, request.context)

            return ToolResponse(success=True, data=result)
        except Exception as e:
            logger.error(f"Error executing tool {request.tool_name}: {str(e)}")
            return ToolResponse(
                success=False,
                error={"message": str(e), "traceback": traceback.format_exc()},
            )

    def register_tool(
        self,
        name: str,
        function: Callable,
        version: str = "1.0.0",
        description: str = "",
        metadata: Optional[ToolMetadata] = None,
    ) -> None:
        """Register a tool.

        Args:
            name: Tool name
            function: Tool function
            version: Tool version
            description: Tool description
            metadata: Tool metadata
        """
        tool = ToolDefinition(
            name=name,
            function=function,
            version=version,
            description=description,
            metadata=metadata,
        )

        self.tools[name] = tool
        logger.info(f"Registered tool: {name} v{version}")

    def load_tools_from_module(self, module_name: str) -> None:
        """Load tools from a module.

        Args:
            module_name: Module name
        """
        try:
            module = importlib.import_module(module_name)

            # Look for tool definitions
            for name, obj in inspect.getmembers(module):
                if hasattr(obj, "__mcp_tool__") and obj.__mcp_tool__:
                    # Get tool metadata
                    tool_name = getattr(obj, "__mcp_tool_name__", name)
                    tool_version = getattr(obj, "__mcp_tool_version__", "1.0.0")
                    tool_description = getattr(obj, "__mcp_tool_description__", "")

                    # Register the tool
                    self.register_tool(
                        name=tool_name,
                        function=obj,
                        version=tool_version,
                        description=tool_description,
                    )

            logger.info(f"Loaded tools from module: {module_name}")
        except ImportError as e:
            logger.error(f"Error loading module {module_name}: {str(e)}")

    def start(self, host: str = "0.0.0.0", port: int = 8000) -> None:
        """Start the server.

        Args:
            host: Server host
            port: Server port
        """
        logger.info(f"Starting Python Tool Server on {host}:{port}")
        uvicorn.run(self.app, host=host, port=port)


def mcp_tool(
    name: Optional[str] = None, version: str = "1.0.0", description: str = ""
) -> Callable:
    """Decorator to mark a function as an MCP tool.

    Args:
        name: Tool name (defaults to function name)
        version: Tool version
        description: Tool description

    Returns:
        Callable: Decorated function
    """

    def decorator(func: Callable) -> Callable:
        func.__mcp_tool__ = True
        func.__mcp_tool_name__ = name or func.__name__
        func.__mcp_tool_version__ = version
        func.__mcp_tool_description__ = description
        return func

    return decorator


def main() -> None:
    """Main entry point."""
    # Create the server
    server = PythonToolServer()

    # Load tools from environment variable
    tool_modules = os.environ.get("MCP_TOOL_MODULES", "").split(",")
    for module in tool_modules:
        if module:
            server.load_tools_from_module(module)

    # Start the server
    host = os.environ.get("MCP_HOST", "0.0.0.0")
    port = int(os.environ.get("MCP_PORT", "8000"))
    server.start(host=host, port=port)


if __name__ == "__main__":
    main()



================================================
File: src/tool_servers/python_tool_server/__init__.py
================================================
"""Python Tool Server implementation."""

from .health import ToolHealth
from .server import ToolServer

__version__ = "1.0.0"

__all__ = ["ToolServer", "ToolHealth"]



================================================
File: src/tool_servers/python_tool_server/health.py
================================================
"""Tool server health monitoring."""

from typing import Dict, List

from mcp_core import HealthCheck, HealthStatus, logger


class ToolHealth(HealthCheck):
    """Tool server health check implementation."""

    def __init__(self):
        self.tools = {}

    async def check_health(self) -> Dict:
        """Check tool server health."""
        try:
            # Check tool availability
            tools = await self.check_tools()

            return {
                "status": HealthStatus.HEALTHY,
                "details": {"active_tools": len(tools), "tools": tools},
            }
        except Exception as e:
            logger.error("Tool health check failed", error=str(e))
            return {"status": HealthStatus.UNHEALTHY, "error": str(e)}

    async def check_tools(self) -> List[str]:
        """Check available tools."""
        return list(self.tools.keys())

    def register_tool(self, name: str):
        """Register a tool for health monitoring."""
        self.tools[name] = {"status": "registered", "last_check": None}



================================================
File: src/tool_servers/python_tool_server/requirements.txt
================================================
mcp-sdk>=0.1.0
fastapi>=0.104.0
uvicorn>=0.23.2
pydantic>=2.4.2
python-dotenv>=1.0.0
httpx>=0.25.0


================================================
File: src/tool_servers/python_tool_server/server.py
================================================
"""Python Tool Server implementation using MCP SDK."""

import os

try:
    import mcp
    from mcp import ToolContext, ToolResponse, create_server
except ImportError:
    print("MCP SDK not installed. Please install it using 'pip install mcp-sdk'")
    raise

# Import tools
from .n1.tool import obsidian_list_notes, obsidian_save_note, obsidian_search_notes
from .n2.tool import (
    aichemist_calculate_property,
    aichemist_get_molecule,
    aichemist_list_molecules,
)

# Configure logging
try:
    from mcp.logger import configure_logging

    configure_logging(level=os.environ.get("LOG_LEVEL", "INFO"))
except ImportError:
    import logging

    logging.basicConfig(level=os.environ.get("LOG_LEVEL", "INFO"))

# Create MCP server
server = create_server(
    name="python-tool-server", description="Python Tool Server for MCP", version="0.1.0"
)

# Register Obsidian tools
server.register_tool(obsidian_list_notes)
server.register_tool(obsidian_search_notes)
server.register_tool(obsidian_save_note)

# Register AIChemist tools
server.register_tool(aichemist_get_molecule)
server.register_tool(aichemist_list_molecules)
server.register_tool(aichemist_calculate_property)


# Configure server transport
def start_server():
    """Start the Python Tool Server."""
    host = os.environ.get("HOST", "127.0.0.1")
    port = int(os.environ.get("PORT", "8001"))

    # Start server with HTTP transport
    server.start_http(host=host, port=port)


if __name__ == "__main__":
    start_server()



================================================
File: src/tool_servers/python_tool_server/n1/models.py
================================================
"""Models for Obsidian tool implementation.

This module defines the data models used by the Obsidian tool for representing
notes and configuration.
"""

from __future__ import annotations

__all__ = ["Note", "ObsidianConfig"]

# Standard library imports
import os
from datetime import datetime
from pathlib import Path
from typing import Set

# Third-party imports
from pydantic import BaseModel, Field, field_validator

# Application imports
from mcp_core.logger import logger


class Note(BaseModel):
    """Represents a note in the vault.

    Attributes:
        title: The title of the note
        content: The content of the note
        created_at: When the note was created
        updated_at: When the note was last updated
        tags: Tags associated with the note
    """

    title: str = Field(..., description="The title of the note")
    content: str = Field(..., description="The content of the note")
    created_at: datetime = Field(
        default_factory=datetime.now, description="When the note was created"
    )
    updated_at: datetime = Field(
        default_factory=datetime.now, description="When the note was last updated"
    )
    tags: Set[str] = Field(
        default_factory=set, description="Tags associated with the note"
    )

    model_config = {"json_encoders": {datetime: lambda v: v.isoformat()}}


class ObsidianConfig(BaseModel):
    """Configuration model for Obsidian integration.

    Attributes:
        vault_path: Path to the Obsidian vault
        excluded_folders: Folders to exclude from processing
        supported_extensions: File extensions to process
        template_folder: Folder containing note templates
    """

    vault_path: Path = Field(
        default_factory=lambda: Path(
            os.path.expandvars(os.environ.get("VAULT_PATH", "docs-obsidian"))
        ).resolve()
    )
    excluded_folders: Set[str] = Field(
        default_factory=lambda: {".git", ".obsidian", "node_modules"}
    )
    supported_extensions: Set[str] = Field(default_factory=lambda: {"md", "markdown"})
    template_folder: str = Field(default="templates")

    @field_validator("vault_path")
    def validate_vault_path(cls, v: Path) -> Path:
        """Validate that the vault path exists and is a directory.

        Args:
            v: The path to validate

        Returns:
            Path: The validated path

        Raises:
            ValueError: If the path is not a directory
        """
        path = Path(v)
        if not path.exists():
            logger.warning(f"Vault path does not exist: {path}")
            path.mkdir(parents=True, exist_ok=True)
            logger.info(f"Created vault directory: {path}")
        elif not path.is_dir():
            raise ValueError(f"Vault path is not a directory: {path}")

        logger.info(f"Using vault path: {path}")
        return path



================================================
File: src/tool_servers/python_tool_server/n1/tool.py
================================================
"""Obsidian tool implementation for MCP."""

from __future__ import annotations

import json
import logging
import os
from datetime import datetime
from pathlib import Path

try:
    from mcp import ToolContext, ToolResponse, tool
except ImportError:
    print("MCP SDK not installed. Please install it using 'pip install mcp-sdk'")

    # Create stub classes/functions for development without the SDK
    class ToolContext:
        pass

    class ToolResponse:
        def __init__(self, content=None, error=None):
            self.content = content
            self.error = error

    def tool(*args, **kwargs):
        def decorator(func):
            return func

        return decorator


from pydantic import BaseModel, Field, field_validator

# Configure logging
logger = logging.getLogger("mcp.tools.obsidian")


class Note(BaseModel):
    """Represents a note in the vault."""

    title: str = Field(..., description="The title of the note")
    content: str = Field(..., description="The content of the note")
    created_at: datetime = Field(
        default_factory=datetime.now, description="When the note was created"
    )
    updated_at: datetime = Field(
        default_factory=datetime.now, description="When the note was last updated"
    )
    tags: set[str] = Field(
        default_factory=set, description="Tags associated with the note"
    )

    model_config = {"json_encoders": {datetime: lambda v: v.isoformat()}}


class ObsidianConfig(BaseModel):
    """Configuration model for Obsidian integration."""

    vault_path: Path = Field(
        default_factory=lambda: Path(
            os.path.expandvars(os.environ.get("VAULT_PATH", "docs-obsidian"))
        ).resolve()
    )
    excluded_folders: set[str] = Field(
        default_factory=lambda: {".git", ".obsidian", "node_modules"}
    )
    supported_extensions: set[str] = Field(default_factory=lambda: {"md", "markdown"})
    template_folder: str = Field(default="templates")

    @field_validator("vault_path")
    def validate_vault_path(cls, v: Path) -> Path:
        """Validate that the vault path exists and is a directory."""
        path = Path(v)
        if not path.exists():
            logger.warning(f"Vault path does not exist: {path}")
            path.mkdir(parents=True, exist_ok=True)
            logger.info(f"Created vault directory: {path}")
        elif not path.is_dir():
            raise ValueError(f"Vault path is not a directory: {path}")

        logger.info(f"Using vault path: {path}")
        return path


class ObsidianTool:
    """Tool for interacting with Obsidian vault."""

    def __init__(self):
        self.config = ObsidianConfig()
        self.notes: dict[str, Note] = {}
        self._load_notes()

    def _load_notes(self) -> None:
        """Load notes from the vault."""
        try:
            vault_path = self.config.vault_path
            logger.debug(f"Loading notes from vault: {vault_path}")

            if not vault_path.exists():
                logger.warning(f"Vault path does not exist: {vault_path}")
                return

            for file in vault_path.rglob("*"):
                if file.suffix[1:] in self.config.supported_extensions:
                    relative_path = str(file.relative_to(vault_path))
                    if not any(
                        excluded in relative_path
                        for excluded in self.config.excluded_folders
                    ):
                        try:
                            with open(file, encoding="utf-8") as f:
                                content = f.read()
                                self.notes[relative_path] = Note(
                                    title=file.stem,
                                    content=content,
                                    created_at=datetime.fromtimestamp(
                                        file.stat().st_ctime
                                    ),
                                    updated_at=datetime.fromtimestamp(
                                        file.stat().st_mtime
                                    ),
                                )
                                logger.debug(f"Loaded note: {relative_path}")
                        except Exception as e:
                            logger.error(f"Error loading note {file}: {e}")
                            continue

            logger.info(f"Loaded {len(self.notes)} notes from vault")
        except Exception as e:
            logger.error(f"Error loading notes: {e}", exc_info=True)

    async def _read_file(self, path: Path) -> str:
        """Read file contents."""
        with open(path, encoding="utf-8") as f:
            return f.read()


# Create singleton instance
obsidian_instance = ObsidianTool()


@tool(
    name="obsidian.list_notes",
    description="Get contents of specified Obsidian notes",
    schema={
        "type": "object",
        "properties": {
            "paths": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of note paths to retrieve",
            }
        },
        "required": ["paths"],
    },
)
async def obsidian_list_notes(context: ToolContext, paths: list[str]) -> ToolResponse:
    """Get contents of specified notes."""
    try:
        results = {}
        for path in paths:
            if path in obsidian_instance.notes:
                results[path] = obsidian_instance.notes[path].model_dump()
            else:
                note_path = obsidian_instance.config.vault_path / path
                if note_path.exists() and note_path.is_file():
                    content = await obsidian_instance._read_file(note_path)
                    note = Note(title=note_path.stem, content=content)
                    obsidian_instance.notes[path] = note
                    results[path] = note.model_dump()

        return ToolResponse(
            content=[{"type": "text", "text": json.dumps(results, indent=2)}]
        )
    except Exception as e:
        logger.error(f"Error reading notes: {e}")
        return ToolResponse(error=str(e))


@tool(
    name="obsidian.search_notes",
    description="Search for notes by name or content",
    schema={
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "Search query to find in note titles or content",
            }
        },
        "required": ["query"],
    },
)
async def obsidian_search_notes(context: ToolContext, query: str) -> ToolResponse:
    """Search for notes by name or content."""
    try:
        results = []
        for path, note in obsidian_instance.notes.items():
            if (
                query.lower() in note.title.lower()
                or query.lower() in note.content.lower()
            ):
                results.append({"path": path, **note.model_dump()})

        return ToolResponse(
            content=[{"type": "text", "text": json.dumps(results, indent=2)}]
        )
    except Exception as e:
        logger.error(f"Error searching notes: {e}")
        return ToolResponse(error=str(e))


@tool(
    name="obsidian.save_note",
    description="Save a note to the Obsidian vault",
    schema={
        "type": "object",
        "properties": {
            "path": {
                "type": "string",
                "description": "Path to save the note to",
            },
            "content": {
                "type": "string",
                "description": "Content of the note",
            },
            "tags": {
                "type": "array",
                "items": {"type": "string"},
                "description": "Tags to associate with the note",
            },
        },
        "required": ["path", "content"],
    },
)
async def obsidian_save_note(
    context: ToolContext, path: str, content: str, tags: list[str] | None = None
) -> ToolResponse:
    """Save a note to the vault."""
    try:
        note_path = obsidian_instance.config.vault_path / path
        note_path.parent.mkdir(parents=True, exist_ok=True)

        with open(note_path, "w", encoding="utf-8") as f:
            f.write(content)

        note = Note(title=note_path.stem, content=content, tags=set(tags or []))
        obsidian_instance.notes[path] = note

        return ToolResponse(
            content=[{"type": "text", "text": f"Note saved successfully: {path}"}]
        )
    except Exception as e:
        logger.error(f"Error saving note: {e}")
        return ToolResponse(error=str(e))



================================================
File: src/tool_servers/python_tool_server/n2/tool.py
================================================
"""AIChemist tool implementation for MCP."""

from __future__ import annotations

import json
import logging
from typing import Any

try:
    from mcp import ToolContext, ToolResponse, tool
except ImportError:
    print("MCP SDK not installed. Please install it using 'pip install mcp-sdk'")

    # Create stub classes/functions for development without the SDK
    class ToolContext:
        pass

    class ToolResponse:
        def __init__(self, content=None, error=None):
            self.content = content
            self.error = error

    def tool(*args, **kwargs):
        def decorator(func):
            return func

        return decorator


from pydantic import BaseModel, Field

# Configure logging
logger = logging.getLogger("mcp.tools.aichemist")


class Molecule(BaseModel):
    """Represents a molecule."""

    name: str = Field(..., description="Name of the molecule")
    formula: str = Field(..., description="Chemical formula")
    properties: dict[str, Any] = Field(
        default_factory=dict, description="Molecular properties"
    )


class AIChemistTool:
    """Tool for molecular modeling and simulation."""

    def __init__(self):
        """Initialize the AIChemist tool."""
        self.molecules = {}
        self._load_sample_data()

    def _load_sample_data(self):
        """Load sample molecular data."""
        sample_molecules = [
            Molecule(
                name="Water",
                formula="H2O",
                properties={
                    "molecular_weight": 18.01528,
                    "boiling_point": 100.0,
                    "melting_point": 0.0,
                    "density": 1.0,
                },
            ),
            Molecule(
                name="Carbon Dioxide",
                formula="CO2",
                properties={
                    "molecular_weight": 44.01,
                    "boiling_point": -78.5,
                    "melting_point": -56.6,
                    "density": 1.977,
                },
            ),
            Molecule(
                name="Methane",
                formula="CH4",
                properties={
                    "molecular_weight": 16.04,
                    "boiling_point": -161.5,
                    "melting_point": -182.5,
                    "density": 0.657,
                },
            ),
        ]

        for molecule in sample_molecules:
            self.molecules[molecule.name.lower()] = molecule

        logger.info(f"Loaded {len(self.molecules)} sample molecules")


# Create singleton instance
aichemist_instance = AIChemistTool()


@tool(
    name="aichemist.get_molecule",
    description="Get information about a specific molecule",
    schema={
        "type": "object",
        "properties": {
            "name": {
                "type": "string",
                "description": "Name of the molecule to retrieve",
            }
        },
        "required": ["name"],
    },
)
async def aichemist_get_molecule(context: ToolContext, name: str) -> ToolResponse:
    """Get information about a specific molecule."""
    try:
        name_lower = name.lower()
        if name_lower in aichemist_instance.molecules:
            molecule = aichemist_instance.molecules[name_lower]
            return ToolResponse(
                content=[
                    {
                        "type": "text",
                        "text": json.dumps(molecule.model_dump(), indent=2),
                    }
                ]
            )
        else:
            return ToolResponse(
                content=[{"type": "text", "text": f"Molecule '{name}' not found."}]
            )
    except Exception as e:
        logger.error(f"Error getting molecule: {e}")
        return ToolResponse(error=str(e))


@tool(
    name="aichemist.list_molecules",
    description="List all available molecules",
    schema={
        "type": "object",
        "properties": {},
    },
)
async def aichemist_list_molecules(context: ToolContext) -> ToolResponse:
    """List all available molecules."""
    try:
        molecules = [
            {"name": mol.name, "formula": mol.formula}
            for mol in aichemist_instance.molecules.values()
        ]
        return ToolResponse(
            content=[{"type": "text", "text": json.dumps(molecules, indent=2)}]
        )
    except Exception as e:
        logger.error(f"Error listing molecules: {e}")
        return ToolResponse(error=str(e))


@tool(
    name="aichemist.calculate_property",
    description="Calculate a property for a given molecule",
    schema={
        "type": "object",
        "properties": {
            "name": {
                "type": "string",
                "description": "Name of the molecule",
            },
            "property": {
                "type": "string",
                "description": "Property to calculate",
                "enum": [
                    "molecular_weight",
                    "boiling_point",
                    "melting_point",
                    "density",
                ],
            },
        },
        "required": ["name", "property"],
    },
)
async def aichemist_calculate_property(
    context: ToolContext, name: str, property: str
) -> ToolResponse:
    """Calculate a property for a given molecule."""
    try:
        name_lower = name.lower()
        if name_lower in aichemist_instance.molecules:
            molecule = aichemist_instance.molecules[name_lower]
            if property in molecule.properties:
                value = molecule.properties[property]
                return ToolResponse(
                    content=[
                        {
                            "type": "text",
                            "text": f"The {property} of {molecule.name} ({molecule.formula}) is {value}",
                        }
                    ]
                )
            else:
                return ToolResponse(
                    content=[
                        {
                            "type": "text",
                            "text": f"Property '{property}' not available for {molecule.name}",
                        }
                    ]
                )
        else:
            return ToolResponse(
                content=[{"type": "text", "text": f"Molecule '{name}' not found."}]
            )
    except Exception as e:
        logger.error(f"Error calculating property: {e}")
        return ToolResponse(error=str(e))



================================================
File: src/tool_servers/typescript_tool_server/package.json
================================================
{
  "name": "mcp-typescript-tool-server",
  "version": "1.0.0",
  "description": "TypeScript Tool Server for MCP",
  "main": "dist/index.js",
  "scripts": {
    "build": "tsc",
    "start": "node dist/index.js",
    "dev": "ts-node-dev src/index.ts",
    "test": "jest"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.0.0",
    "express": "^4.18.2",
    "pino": "^8.0.0",
    "pino-http": "^8.0.0",
    "zod": "^3.22.0"
  },
  "devDependencies": {
    "@types/express": "^4.17.17",
    "@types/jest": "^29.5.0",
    "@types/node": "^18.15.0",
    "jest": "^29.5.0",
    "ts-jest": "^29.1.0",
    "ts-node-dev": "^2.0.0",
    "typescript": "^5.0.0"
  }
}



================================================
File: src/tool_servers/typescript_tool_server/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "commonjs",
    "lib": ["ES2020"],
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "declaration": true,
    "sourceMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "**/*.test.ts"]
}



================================================
File: src/tool_servers/typescript_tool_server/src/health.ts
================================================
import { HealthCheck } from '@modelcontextprotocol/sdk/types';
import { logger } from './logger';

export const healthCheck: HealthCheck = {
  async check() {
    try {
      // Check critical services
      await checkTools();

      return {
        status: 'healthy',
        details: {
          tools: 'available',
        },
      };
    } catch (error) {
      logger.error('Health check failed', { error });

      return {
        status: 'unhealthy',
        error: String(error),
      };
    }
  },
};

async function checkTools(): Promise<void> {
  // Implement tool availability check
  return Promise.resolve();
}



================================================
File: src/tool_servers/typescript_tool_server/src/index.ts
================================================
import { McpServer } from '@modelcontextprotocol/sdk/server/mcp';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio';
import { z } from 'zod';
import { thinkingTool } from './n3';
import { anotherTool } from './n4';
import { logger } from './logger';
import { healthCheck } from './health';

// Create MCP server
const server = new McpServer({
  name: 'TypeScript Tool Server',
  version: '1.0.0',
});

// Register tools
server.tool('thinking', thinkingTool.schema, thinkingTool.handler);

server.tool('another', anotherTool.schema, anotherTool.handler);

// Add health check
server.health(healthCheck);

// Start server
async function main() {
  try {
    logger.info('Starting TypeScript Tool Server');

    // Connect to transport
    const transport = new StdioServerTransport();
    await server.connect(transport);

    logger.info('Server started successfully');
  } catch (error) {
    logger.error('Failed to start server', { error });
    process.exit(1);
  }
}

main();



================================================
File: src/tool_servers/typescript_tool_server/src/logger.ts
================================================
import pino from 'pino';

export const logger = pino({
  name: 'typescript-tool-server',
  level: process.env.LOG_LEVEL || 'info',
  timestamp: true,
  formatters: {
    level(label) {
      return { level: label };
    },
  },
});



================================================
File: template/mcp.json
================================================
{
  "mcpServers": {
    "obsidian-integration": {
      "command": "python",
      "args": ["-m", "mymcpserver.server", "--transport", "stdio"],
      "env": {
        "VAULT_PATH": "${env:VAULT_PATH}",
        "PYTHONPATH": "${env:PYTHONPATH}",
        "LOGS_PATH": "${env:LOGS_PATH}",
        "PYTHONUNBUFFERED": "${env:PYTHONUNBUFFERED}",
        "MCP_TRANSPORT": "${env:MCP_TRANSPORT}",
        "MCP_LOG_LEVEL": "${env:MCP_LOG_LEVEL}",
        "MCP_ENABLE_RICH_LOGGING": "${env:MCP_ENABLE_RICH_LOGGING}"
      },
      "cwd": "${env:WORKSPACE_FOLDER}"
    }
  },
  "serverConfig": {
    "transport": "stdio",
    "settings": {
      "maxRequestSize": 10485760,
      "maxResponseSize": 10485760,
      "timeout": 30000
    }
  }
}



================================================
File: tests/test_server.py
================================================
"""Test script to verify the MCP server package."""

import sys

print(f"Python version: {sys.version}")
print(f"Python executable: {sys.executable}")

try:
    import mymcpserver

    print(f"Successfully imported mymcpserver version {mymcpserver.__version__}")
    print("Package is correctly installed and can be imported!")
except ImportError as e:
    print(f"Failed to import mymcpserver: {e}")
    sys.exit(1)

print("All tests passed!")



================================================
File: .cursor/mcp.json
================================================
{
  "mcpServers": {
    "personal-mcp": {
      "command": "powershell",
      "args": ["-Command", "uv run mymcpserver"],
      "env": {
        "VAULT_PATH": "${env:VAULT_PATH}",
        "LOGS_PATH": "${env:LOGS_PATH}",
        "PYTHONUNBUFFERED": "1",
        "MCP_TRANSPORT": "stdio",
        "MCP_LOG_LEVEL": "DEBUG",
        "MCP_ENABLE_RICH_LOGGING": "1"
      },
      "cwd": "${env:WORKSPACE_FOLDER}"
    },
    "mcp-sequentialthinking-tools": {
      "command": "powershell.exe",
      "args": [
        "-ExecutionPolicy",
        "Bypass",
        "-Command",
        "npx -y mcp-sequentialthinking-tools"
      ]
    }
  },
  "serverConfig": {
    "transport": "stdio",
    "settings": {
      "maxRequestSize": 10485760,
      "maxResponseSize": 10485760,
      "timeout": 30000
    }
  }
}



================================================
File: .cursor/rules/0000-global-knowledge-management.mdc
================================================
---
description: 
globs: 
alwaysApply: true
---
<aiDecision>
description: ALWAYS APPLY knowledge management principles WHEN working with documentation
globs: **/*
alwaysApply: true
</aiDecision>

# Global Knowledge Management System Rule

<context>
  <role>Knowledge Assistant</role>
  <purpose>Maintain knowledge organization best practices across all interactions</purpose>
</context>

<rulesIndex>
  <allwaysFollowRules>
  Always Follow The Rules Per Folder Space
  </allwaysFollowRules>
  <category name="GLOBAL">
    [0000-global-knowledge-management.mdc](mdc:.cursor/rules/0000-global-knowledge-management.mdc), [0100-mcp-server-layout.mdc](mdc:.cursor/rules/0100-mcp-server-layout.mdc), [0150-Read-module-docs.mdc](mdc:.cursor/rules/0150-Read-module-docs.mdc), [9000-rule-crafting.mdc](mdc:.cursor/rules/9000-rule-crafting.mdc), [0010-Plan-ACT.mdc](mdc:.cursor/rules/0010-Plan-ACT.mdc)
  </category>
  <category name="DOCS" = @ docs-obsidian/>
    [4000-docs-obsidian-organization.mdc](mdc:.cursor/rules/4000-docs-obsidian-organization.mdc), [4100-obsidian-note-structure.mdc](mdc:.cursor/rules/4100-obsidian-note-structure.mdc), [4200-obsidian-linking.mdc](mdc:.cursor/rules/4200-obsidian-linking.mdc)
  </category>
  <category name="MCP" = @ src/>
    [801-python-environment.mdc](mdc:.cursor/rules/801-python-environment.mdc), [1001-python-imports.mdc](mdc:.cursor/rules/1001-python-imports.mdc), [1002-python-style-guide.mdc](mdc:.cursor/rules/1002-python-style-guide.mdc), [1002-python-type-hinting.mdc](mdc:.cursor/rules/1002-python-type-hinting.mdc)
  </category>
</rulesIndex>

<requirements>
  <requirement>ALWAYS ORGANIZE knowledge into atomic, interconnected notes</requirement>
  <requirement>MAINTAIN hierarchical structure with MOCs at the top level</requirement>
  <requirement>WHEN creating new content, prioritize linking to existing knowledge</requirement>
  <requirement>ENSURE all knowledge is accessible through the Home page</requirement>
  <requirement>USE meaningful, descriptive titles for all notes</requirement>
  <requirement>CREATE notes in appropriate folders based on their content type</requirement>
  <requirement>LINK each note to at least one Map of Content (MOC)</requirement>
  <requirement>PROVIDE contextual explanations with links between notes</requirement>
  <requirement>ADD bidirectional links between related notes</requirement>
  <requirement>INCLUDE metadata (creation date, tags, parent MOC) in all notes</requirement>
</requirements>

<principles>
  <principle>Knowledge should be interconnected, not isolated</principle>
  <principle>Organization should reduce friction, not create it</principle>
  <principle>Structure should emerge organically from content</principle>
  <principle>Notes should be atomic but connected</principle>
  <principle>All knowledge should be discoverable through navigation</principle>
  <principle>Consistency in structure improves comprehension</principle>
</principles>


================================================
File: .cursor/rules/0010-Plan-ACT.mdc
================================================
---
description: 
globs: 
alwaysApply: true
---
<aiDecision>
description: ALWAYS follow this protocol WHEN assisting with code tasks
globs: **/*.{py,js,ts,java,c,cpp,cs,go,rb,php,html,css,sql}
alwaysApply: true
</aiDecision>

# Code Assistant Agent Protocol

<context>
  <role>Specialized Code Assistant</role>
  <purpose>Deliver working, functional code through a systematic approach</purpose>
</context>

<methodology>
  <phase name="PLAN">
    <principle>Thoroughly plan before writing a single line of code</principle>
    <steps>
      1. UNDERSTAND the problem completely before proposing solutions
      2. CLARIFY requirements through questions if necessary
      3. DECOMPOSE complex tasks into smaller, manageable components
      4. ANTICIPATE edge cases, potential errors, and performance concerns
      5. OUTLINE approach with pseudocode or high-level design
      6. VALIDATE approach against requirements before implementation
    </steps>
  </phase>

  <phase name="EXECUTE">
    <principle>Write code methodically with error awareness</principle>
    <steps>
      1. START with minimal working implementation (base functionality first)
      2. PRIORITIZE readability and maintainability over cleverness
      3. DOCUMENT code with clear comments explaining purpose and logic
      4. WHEN errors occur during execution:
         a. STOP immediately and capture full error details
         b. ANALYZE root cause (not just symptoms)
         c. FIX underlying issues before proceeding
         d. VERIFY fix with test cases
         e. NEVER stack new commands on unresolved errors
      5. IMPLEMENT error handling for anticipated failure scenarios
      6. TEST code with representative inputs, edge cases, and error conditions
    </steps>
    <errorProtocol>
      1. READ error messages completely before attempting resolution
      2. TRACE exact line/location where error occurs
      3. UNDERSTAND error type and classification
      4. RESEARCH common causes for this specific error
      5. APPLY smallest necessary fix that addresses root cause
      6. VERIFY with minimal reproducible test case
      7. DOCUMENT solution for future reference
    </errorProtocol>
  </phase>

  <phase name="REFLECT">
    <principle>Review and enhance code once base functionality works</principle>
    <steps>
      1. CRITIQUE your own implementation objectively
      2. IDENTIFY potential improvements in:
         a. Performance optimization
         b. Code organization
         c. Error handling
         d. Documentation
      3. REFACTOR code to improve quality while maintaining functionality
      4. CONSIDER edge cases not covered in initial implementation
      5. DOCUMENT design decisions and tradeoffs
    </steps>
  </phase>

  <phase name="ITERATE">
    <principle>Improve through incremental enhancement</principle>
    <steps>
      1. ENHANCE code with additional features once core functionality works
      2. IMPLEMENT creative solutions that extend basic functionality
      3. OPTIMIZE for performance, readability, or other metrics
      4. SUGGEST potential extensions or alternative approaches
    </steps>
  </phase>
</methodology>

<guidelines>
  <guideline>ALWAYS provide working base code before suggesting optimizations</guideline>
  <guideline>NEVER ignore error messages or attempt to code around them</guideline>
  <guideline>PREFER established patterns and libraries over custom implementations for common tasks</guideline>
  <guideline>EXPLAIN key design decisions and tradeoffs</guideline>
  <guideline>INCLUDE error handling in all code</guideline>
  <guideline>DOCUMENT assumptions about inputs and execution environment</guideline>
  <guideline>CITE sources for techniques, algorithms, or code snippets</guideline>
  <guideline>FOCUS on solving the specific problem before generalizing</guideline>
</guidelines>

<toolUse>
  <tool name="Documentation">
    <purpose>Access language/framework specifics for accurate implementation</purpose>
    <usage>Consult official documentation for proper syntax and best practices</usage>
  </tool>
  <tool name="CodeExecution">
    <purpose>Verify code functionality</purpose>
    <usage>Execute code to test for errors and validate output</usage>
  </tool>
  <tool name="StaticAnalysis">
    <purpose>Identify potential issues before runtime</purpose>
    <usage>Analyze code for bugs, anti-patterns, and optimization opportunities</usage>
  </tool>
</toolUse>

<successCriteria>
  <criterion>Code functions correctly according to requirements</criterion>
  <criterion>Errors are properly handled and documented</criterion>
  <criterion>Code is readable and maintainable</criterion>
  <criterion>Implementation follows language/framework best practices</criterion>
  <criterion>Solution is appropriately optimized for performance needs</criterion>
</successCriteria>


================================================
File: .cursor/rules/0020-windows-powershell.mdc
================================================
---
description: 
globs: 
alwaysApply: true
---
<aiDecision>
  Description: CRITICAL: USER is on WINDOWS ALL TOOL CALLS to reflect
  globs: **/*
  alwaysApply: always
</aiDecision>

# USER SYSTEM WINDOWS TOOL CALLS REFLECT

<context>
  <role>AGENT TOOL CALL</role>
  <purpose>When using tools for file handling calling or terminal use all Calls are for windows & powershell</purpose>
</context>

<requirements>
  <requirement>Always Use WINDOWS Tool Calls</requirement>
  <requirement>This is TOOL CALLS ONLY writing code may be different</reuirement>
</requirements>




================================================
File: .cursor/rules/0100-mcp-server-layout.mdc
================================================
---
description: 
globs: src/**,src/**/*
alwaysApply: false
---
<IMPORTANT>
CRITICAL: ALWAYS Follow the the architecture laid out in [filetree.md](mdc:docs-obsidian/user added for indexing later/mcpPlanning/final/filetree.md), [flowchart.md](mdc:docs-obsidian/user added for indexing later/mcpPlanning/final/flowchart/flowchart.md) when working in the project files
fileTree [filetree.md](mdc:docs-obsidian/user added for indexing later/mcpPlanning/final/filetree.md) shows the rest of the server including test
flowChart [flowchart.md](mdc:docs-obsidian/user added for indexing later/mcpPlanning/final/flowchart/flowchart.md) shows the overall flow of the project
</IMPORTANT>

<fileTreeMAINSRC>
├── src/                            # All source code lives here
│   ├── mcp_proxy/                  # Proxy Connection Server (stdio ⇄ SSE)
│   │   ├── __init__.py
│   │   ├── __main__.py             # Entry point for proxy server
│   │   ├── proxy_server.py         # Core proxy server logic
│   │   ├── transports/             # Transport layer implementations
│   │   │   ├── __init__.py
│   │   │   ├── sse.py              # SSE transport
│   │   │   ├── stdio.py            # stdio transport
│   │   │   └── websocket.py        # WebSocket transport (future)
│   │   ├── health.py               # Health check endpoints
│   │   └── errors.py               # Proxy-specific error handling
│   ├── mcp_core/                   # MCP Core Layer (Python)
│   │   ├── __init__.py
│   │   ├── app.py                  # Main entry point for MCP core
│   │   ├── config.py               # Configuration management
│   │   ├── registry.py             # Tool registry management
│   │   ├── errors.py               # Error handling framework
│   │   ├── logger.py               # Structured logging system
│   │   ├── health.py               # Health monitoring
│   │   ├── metrics/                # Metrics collection
│   │   │   ├── __init__.py
│   │   │   ├── collectors.py       # Metric collectors
│   │   │   └── exporters.py        # Metric exporters
│   │   ├── validation/             # Request/response validation
│   │   │   ├── __init__.py
│   │   │   ├── schemas.py          # JSON schemas
│   │   │   └── validators.py       # Validation logic
│   │   ├── models/                 # Data models for MCP
│   │   │   ├── __init__.py
│   │   │   ├── request.py          # Request model definitions
│   │   │   └── response.py         # Response model definitions
│   │   └── adapters/               # Adapter/Registry Layer
│   │       ├── __init__.py
│   │       ├── base_adapter.py     # Abstract adapter interface
│   │       ├── python_adapter.py   # Python tool server adapter
│   │       ├── ts_adapter.py       # TypeScript tool server adapter
│   │       ├── version.py          # Tool versioning support
│   │       └── circuit_breaker.py  # Circuit breaker implementation
│   └── tool_servers/               # Tool Server implementations
│       ├── python_tool_server/     # Python-based MCP tool server
│       │   ├── __init__.py
│       │   ├── server.py           # Python tool server entry point
│       │   ├── health.py           # Tool server health checks
│       │   ├── errors.py           # Tool-specific error handling
│       │   ├── hot_reload.py       # Hot reload support
│       │   ├── n1/                 # Obsidian Tool
│       │   │   ├── __init__.py
│       │   │   ├── tool.py         # Tool implementation
│       │   │   └── models.py       # Tool-specific data models
│       │   ├── n2/                 # AIChemist Tool
│       │   │   ├── __init__.py
│       │   │   ├── tool.py         # Tool implementation
│       │   │   └── models.py       # Tool-specific data models
│       │   └── requirements.txt    # Python tool server dependencies
│       └── typescript_tool_server/ # TypeScript-based tool server
│           ├── package.json        # Node.js project file
│           ├── tsconfig.json       # TypeScript configuration
│           ├── jest.config.js      # Test configuration
│           └── src/
│               ├── index.ts        # Main entry point
│               ├── health.ts       # Health check implementation
│               ├── errors.ts       # Error handling utilities
│               ├── logger.ts       # Structured logging
│               ├── hot-reload.ts   # Hot reload implementation
│               ├── n3/             # Thinking Tool
│               │   ├── index.ts    # Tool implementation
│               │   └── models.ts   # Tool-specific data models
│               └── n4/             # Another Tool
│                   ├── index.ts    # Tool implementation
│                   └── models.ts   # Tool-specific data models
</fileTreeMAINSRC>


================================================
File: .cursor/rules/0150-Read-module-docs.mdc
================================================
---
description: 
globs: src/**,src/**/*
alwaysApply: false
---
<IMPORTANT>
ALWAYS READ AND UPDATE DOCS AS YOU WORK IN SRC folder
you will find the docs in D:\Coding\Python_Projects\MYMCPSERVER\docs-obsidian\user added for indexing later\mcpPlanning\final
</IMPORTANT>

<Requirements>
  <Requirement>Make sure you have the most current context reading the docs in the location - 
  given before writing code</Requirement>
  <Requirement>Follow the workflow defined in [filetree.md](mdc:docs-obsidian/user added for indexing later/mcpPlanning/final/filetree.md), [flowchart.md](mdc:docs-obsidian/user added for indexing later/mcpPlanning/final/flowchart/flowchart.md)</requirement>
  <Requirement>ALWAYS BE sure to add functional code to files already created before making new</requirement>
  <Requirement>Please follow the pytho
</Requirements>


================================================
File: .cursor/rules/0200-project-locations.mdc
================================================
# Project Locations and Structure Rule

<aiDecision>
description: ALWAYS follow these project location rules when working with the codebase
globs: src/**/*
alwaysApply: true
</aiDecision>

<context>
  <role>Project Structure Guardian</role>
  <purpose>Maintain consistent project structure and file locations</purpose>
</context>

<projectRoot>
  <path>/d:/Coding/Python_Projects/MYMCPSERVER</path>
  <structure>
    ├── src/                           # Source code root
    │   ├── mcp_core/                  # Core MCP functionality
    │   ├── mcp_proxy/                 # Proxy Connection Server
    │   └── tool_servers/              # Tool implementations
    ├── logs/                          # Log files directory
    │   ├── core/                      # Core layer logs
    │   ├── proxy/                     # Proxy layer logs
    │   └── tools/                     # Tool server logs
    ├── config/                        # Configuration files
    │   ├── core/                      # Core configuration
    │   ├── proxy/                     # Proxy configuration
    │   └── tools/                     # Tool configuration
    ├── tests/                         # Test files
    │   ├── unit/                      # Unit tests
    │   ├── integration/               # Integration tests
    │   └── fixtures/                  # Test fixtures
    └── docs-obsidian/                 # Documentation
  </structure>
</projectRoot>

<requirements>
  <requirement>ALWAYS use absolute paths from project root for file operations</requirement>
  <requirement>MAINTAIN logs in the logs/ directory with appropriate subdirectories</requirement>
  <requirement>STORE all configuration files in config/ directory</requirement>
  <requirement>KEEP all source code under src/ directory</requirement>
  <requirement>PLACE all tests in tests/ directory</requirement>
  <requirement>USE docs-obsidian/ for all documentation</requirement>
</requirements>

<constants>
  <paths>
    <LOG_ROOT>logs</LOG_ROOT>
    <CONFIG_ROOT>config</CONFIG_ROOT>
    <SOURCE_ROOT>src</SOURCE_ROOT>
    <TEST_ROOT>tests</TEST_ROOT>
    <DOCS_ROOT>docs-obsidian</DOCS_ROOT>
  </paths>
  <defaults>
    <LOG_LEVEL>INFO</LOG_LEVEL>
    <CONFIG_ENV>development</CONFIG_ENV>
    <ENCODING>utf-8</ENCODING>
  </defaults>
</constants>

<guidelines>
  <guideline>Use Path from pathlib for all file operations</guideline>
  <guideline>Create directories if they don't exist when needed</guideline>
  <guideline>Use appropriate file permissions</guideline>
  <guideline>Follow naming conventions for each directory</guideline>
</guidelines>


================================================
File: .cursor/rules/1001-python-imports.mdc
================================================
---
description: 
globs: *src/**/*.py,src/**/*.py,**/*.py
alwaysApply: false
---
---
description: Organize Python imports in the recommended order with proper grouping and formatting
globs: *src/**/*.py
---

<cursor-rule>
  <title>Python Import Organization</title>
  <version>1.0.0</version>

  <context>
    Use when importing modules in Python files to maintain consistent organization
  </context>

  <requirements>
    <requirement>Group imports into sections: standard library, third-party, application-specific</requirement>
    <requirement>Sort imports alphabetically within each section</requirement>
    <requirement>Use absolute imports for cross-domain boundaries</requirement>
    <requirement>Use relative imports only for closely related modules within same domain</requirement>
    <requirement>Avoid wildcard imports (from module import *)</requirement>
    <requirement>Include type hints when importing types</requirement>
    <requirement>Avoid circular dependencies between modules</requirement>
    <requirement>Place imports after docstrings but before module-level code</requirement>
  </requirements>

  <examples>
    <good-example>
      <title>Properly Organized Imports with Type Hints</title>
      <code>
"""Module for handling file metadata extraction and analysis.

This module provides utilities to extract and analyze metadata from different
file types in the Aichemist Codex system.
"""

from __future__ import annotations

__all__ = ['MetadataExtractor', 'FileTypeDetector']
__version__ = '0.1.0'

# Standard library imports
import json
import logging
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Protocol, Set, Tuple, Union, TypeVar, cast

# Third-party imports
import magic
import yaml
from pydantic import BaseModel, Field, validator

# Application imports (absolute)
from the_aichemist_codex.backend.domain.models.file import File, FileType
from the_aichemist_codex.backend.domain.repositories.metadata_repository import MetadataRepository

# Local/related imports (relative)
from .analyzers import ContentAnalyzer
from ..common.utils import generate_hash, safe_read_file
      </code>
    </good-example>

    <bad-example>
      <title>Problematic Import Organization</title>
      <code>
import json, yaml, os, sys  # Imports on same line
from pathlib import Path
import logging
from .utils import *  # Wildcard import
from the_aichemist_codex.backend.file_manager import FileMover
import magic  # Third-party mixed with standard library

# Circular dependency
from .other_module import process_file  # other_module imports from this file
      </code>
    </bad-example>
  </examples>

  <guidance>
    <step>Start with any __future__ imports</step>
    <step>Add any module-level dunder attributes (__all__, __version__, etc.)</step>
    <step>Group standard library imports alphabetically</step>
    <step>Add a blank line, then group third-party library imports alphabetically</step>
    <step>Add a blank line, then add application imports (absolute paths)</step>
    <step>Add a blank line, then add local/related imports (relative paths)</step>
    <step>Use type hints in imports when importing for type annotations</step>
    <step>Ensure no circular dependencies exist between modules</step>
  </guidance>

  <rationale>
    <point>Consistent import organization improves readability and maintainability</point>
    <point>Proper import structure helps prevent circular dependencies</point>
    <point>Type hints in imports improve static type checking</point>
    <point>Explicit imports make dependencies clear and aid tooling</point>
    <point>Following PEP 8 standards ensures code consistency</point>
  </rationale>
</cursor-rule>


================================================
File: .cursor/rules/1002-python-style-guide.mdc
================================================
---
description: 
globs: src/**/*.py,*src/**/*.py,**/*.py
alwaysApply: false
---
---
description: Maintain consistent Python code style with proper docstrings, typing, and indentation
globs: src/**/*.py
---

<cursor-rule>
  <title>Python Code Style Guidelines</title>
  <version>1.0.0</version>

  <context>
    Apply to all Python files to ensure consistent style across the codebase
  </context>

  <requirements>
    <requirement>Use Google-style docstrings for all modules, classes, and functions</requirement>
    <requirement>Include type hints for all parameters and return values</requirement>
    <requirement>Use 4-space indentation (no tabs)</requirement>
    <requirement>Use f-strings for string formatting (not %-formatting or .format())</requirement>
    <requirement>Follow PEP 8 naming conventions (snake_case for functions/variables, PascalCase for classes)</requirement>
    <requirement>Include informative docstrings with Args, Returns, and Raises sections as needed</requirement>
    <requirement>Keep line length to a maximum of 88 characters</requirement>
    <requirement>Use proper type annotations for optional parameters</requirement>
  </requirements>

  <examples>
    <good-example>
      <title>Well-Formatted Python Class with Proper Style</title>
      <code>
class FileReader:
    """Main class for reading and parsing files with MIME type detection.

    This class provides functionality to read files, detect their MIME types,
    and extract content for further processing.
    """

    def __init__(
        self,
        max_workers: int = 2,
        preview_length: int = 100,
        cache_manager: CacheManager | None = None,
    ) -> None:
        """Initialize FileReader.

        Args:
            max_workers: Maximum number of worker threads for
                concurrent operations
            preview_length: Maximum length of file previews
            cache_manager: Cache manager for caching extraction results
        """
        self.max_workers = max_workers
        self.preview_length = preview_length
        self.logger = logging.getLogger(__name__)

        # Initialize the magic library for file type detection
        self._magic_instance = None

        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.cache_manager = cache_manager

        # Initialize the metadata manager
        self.metadata_manager = MetadataManager(cache_manager)

    def get_mime_type(self, file_path: str | Path) -> str:
        """Get the MIME type of a file.

        Args:
            file_path: Path to the file

        Returns:
            MIME type of the file

        Raises:
            FileNotFoundError: If the file does not exist
        """
        path = Path(file_path)
        if not path.exists():
            raise FileNotFoundError(f"{path} does not exist.")

        if magic is None:
            self.logger.warning("Magic library not available, using default MIME type")
            return "application/octet-stream"

        # Implementation details...
        return self._fallback_mime_type(path)
      </code>
    </good-example>

    <bad-example>
      <title>Poor Python Formatting Style</title>
      <code>
class file_reader:  # Incorrect class naming (should be PascalCase)
    '''Class that reads files''' # Incomplete docstring

    def __init__(self, max_workers=2, preview_length=100, cache_manager=None):  # Missing type hints
        # No docstring for method
        self.max_workers=max_workers  # Missing space around operator
        self.preview_length = preview_length
        self.logger = logging.getLogger(__name__)

        self._magic_instance = None

        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.cache_manager=cache_manager  # Missing space around operator
        self.metadata_manager = MetadataManager(cache_manager)

    def get_mime_type(self, file_path):  # Missing type hints
        # Docstring should be more descriptive
        """Get MIME type."""
        path = Path(file_path)
        if not path.exists():
            raise FileNotFoundError("Path %s does not exist." % path)  # Using %-formatting instead of f-string

        if magic == None:  # Should use "is None" not "== None"
            logger.warning('Magic library not available, using default MIME type')  # Using undefined logger variable
            return "application/octet-stream"
      </code>
    </bad-example>
  </examples>

  <guidance>
    <step>Start each file with a module-level docstring explaining its purpose</step>
    <step>Use Google-style docstrings for all public classes and methods</step>
    <step>Include type hints for parameters, return values, and attributes</step>
    <step>Follow naming conventions: snake_case for variables/functions, PascalCase for classes</step>
    <step>Use proper spacing around operators and after commas</step>
    <step>Use f-strings for string interpolation</step>
    <step>Use consistent 4-space indentation</step>
    <step>Prefix private attributes/methods with a single underscore</step>
    <step>Include detailed docstrings with Args, Returns, and Raises sections</step>
    <step>Break long parameter lists or function calls into multiple lines with consistent indentation</step>
  </guidance>

  <rationale>
    <point>Consistent code style improves readability and maintainability</point>
    <point>Type hints enable better IDE support and catch errors early</point>
    <point>Proper docstrings make the code self-documenting</point>
    <point>Following established Python conventions makes the code more accessible to new contributors</point>
    <point>Proper error handling with descriptive messages improves debugging</point>
  </rationale>
</cursor-rule>


================================================
File: .cursor/rules/1002-python-type-hinting.mdc
================================================
---
description: 
globs: src/**/*.py,*src/**/*.py,**/*.py
alwaysApply: false
---
---
description: WHEN writing Python code ALWAYS use type hints for functions, methods, and variables
globs: src/**/*.py
---

<python-typing-rule>
  <version>1.0.0</version>

  <context>
    The AIchemist Codex codebase follows strict typing practices to improve code quality, IDE support, and maintainability.
    All Python modules must include proper type hints.
  </context>

  <requirements>
    <requirement>Add type hints to all function and method parameters</requirement>
    <requirement>Add return type annotations to all functions and methods</requirement>
    <requirement>Use type hints for class attributes when declared</requirement>
    <requirement>Import necessary typing classes (Dict, List, Optional, Union, etc.)</requirement>
    <requirement>Use appropriate typing constructs for complex types</requirement>
    <requirement>Add docstrings with parameter and return value descriptions</requirement>
  </requirements>

  <typing-imports>
    <basic-types>
      <type>Dict</type>
      <type>List</type>
      <type>Set</type>
      <type>Tuple</type>
      <type>Optional</type>
      <type>Union</type>
      <type>Any</type>
      <type>Callable</type>
      <type>TypeVar</type>
      <type>Generic</type>
      <type>Iterable</type>
    </basic-types>
    <import-statement>from typing import Dict, List, Optional, Set, Tuple, Union, Any, Callable, TypeVar, Generic, Iterable</import-statement>
  </typing-imports>

  <docstring-format>
    <function>
      <template>
      """
      {function_description}

      Args:
          {parameter_name} ({parameter_type}): {parameter_description}

      Returns:
          {return_type}: {return_description}

      Raises:
          {exception_type}: {exception_description}
      """
      </template>
    </function>

    <class>
      <template>
      """
      {class_description}

      Attributes:
          {attribute_name} ({attribute_type}): {attribute_description}
      """
      </template>
    </class>
  </docstring-format>

  <examples>
    <good-example>
      <description>Function with proper type hints and docstring</description>
      <code>
def process_document(
    document: Document,
    tags: Optional[List[str]] = None,
    max_length: int = 1000
) -> Dict[str, Any]:
    """
    Process a document and apply tags if provided.

    Args:
        document (Document): The document to process
        tags (Optional[List[str]]): Tags to apply to the document
        max_length (int): Maximum length to process

    Returns:
        Dict[str, Any]: Processed document data with applied tags

    Raises:
        ValueError: If document is empty or invalid
    """
    if not document.content:
        raise ValueError("Document content cannot be empty")

    result: Dict[str, Any] = {
        "id": document.id,
        "content": document.content[:max_length],
        "processed_at": datetime.now()
    }

    if tags:
        document.tags.update(tags)
        result["tags"] = list(document.tags)

    return result
      </code>
    </good-example>

    <good-example>
      <description>Class with typed attributes and methods</description>
      <code>
class DocumentProcessor:
    """
    Processes documents and applies transformations.

    Attributes:
        max_length (int): Maximum content length to process
        supported_formats (Set[str]): Document formats supported by this processor
    """

    def __init__(self, max_length: int = 1000) -> None:
        """
        Initialize the document processor.

        Args:
            max_length (int): Maximum content length to process
        """
        self.max_length: int = max_length
        self.supported_formats: Set[str] = {"txt", "md", "pdf"}

    def process(self, document: Document) -> ProcessedDocument:
        """
        Process a document into a standardized format.

        Args:
            document (Document): Document to process

        Returns:
            ProcessedDocument: The processed document

        Raises:
            UnsupportedFormatError: If document format is not supported
        """
        # Processing logic
        return ProcessedDocument(document.id, document.content[:self.max_length])
      </code>
    </good-example>

    <bad-example>
      <description>Function missing type hints</description>
      <code>
# Missing type hints
def process_document(document, tags=None, max_length=1000):
    """Process a document."""
    # Implementation
    return {"processed": True}
      </code>
    </bad-example>

    <bad-example>
      <description>Incomplete type hints</description>
      <code>
# Incomplete type hints (missing return type)
def extract_metadata(document: Document, fields: List[str]):
    """Extract metadata from document."""
    # Implementation
    return {field: getattr(document, field) for field in fields}
      </code>
    </bad-example>
  </examples>

  <module-specific-types>
    <file-system>
      <type-imports>from pathlib import Path</type-imports>
      <common-types>
        <type name="file_path">Union[str, Path]</type>
        <type name="directory_path">Union[str, Path]</type>
        <type name="file_content">Union[str, bytes]</type>
      </common-types>
    </file-system>

    <parsing>
      <type-imports>from typing import BinaryIO, TextIO</type-imports>
      <common-types>
        <type name="parser_result">Dict[str, Any]</type>
        <type name="document_content">str</type>
      </common-types>
    </parsing>

    <tagging>
      <common-types>
        <type name="tags">Set[str]</type>
        <type name="tag_hierarchy">Dict[str, List[str]]</type>
      </common-types>
    </tagging>
  </module-specific-types>
</python-typing-rule>


================================================
File: .cursor/rules/4000-docs-obsidian-organization.mdc
================================================
---
description: 
globs: docs-obsidian/**/*
alwaysApply: false
---
 <aiDecision>
description: IMPORTANT MAINTAIN folder structure WHEN working with docs-obsidian content
globs: docs-obsidian/**/*
alwaysApply: true
</aiDecision>

# Obsidian Documentation Organization Rule

<context>
  <role>Documentation System</role>
  <purpose>Maintain consistent folder structure and organization</purpose>
</context>

<requirements>
  <requirement>KEEP all MOC files at the top level of docs-obsidian folder</requirement>
  <requirement>PLACE all concept notes in the concepts/ folder</requirement>
  <requirement>PLACE all process notes in the processes/ folder</requirement>
  <requirement>PLACE all reference material in the reference/ folder</requirement>
  <requirement>STORE all templates in the templates/ folder</requirement>
  <requirement>WHEN creating a new category, CREATE a dedicated folder</requirement>
</requirements>

<structure>
  <folder name="docs-obsidian">
    <file>Home.md</file>
    <file>Concepts MOC.md</file>
    <file>Processes MOC.md</file>
    <file>Reference MOC.md</file>
    <file>Fleeting MOC.md</file>
    <folder>concepts/</folder>
    <folder>processes/</folder>
    <folder>reference/</folder>
    <folder>templates/</folder>
  </folder>
</structure>


================================================
File: .cursor/rules/4100-obsidian-note-structure.mdc
================================================
---
description: 
globs: docs-obsidian/**/*.md
alwaysApply: false
---
<aiDecision>
description: CRITICAL STRUCTURE all notes WHEN creating content in Obsidian to follow template format
globs: docs-obsidian/**/*.md
alwaysApply: true
</aiDecision>

# Obsidian Note Structure Rule

<context>
  <role>Knowledge Management System</role>
  <purpose>Ensure consistent structure across all notes</purpose>
</context>

<requirements>
  <requirement>ALWAYS BEGIN notes with metadata (tags, parent MOC)</requirement>
  <requirement>INCLUDE sections for Overview, Key Points, Details, Related Notes, and References</requirement>
  <requirement>ALWAYS LINK each note to at least one MOC through parent metadata</requirement>
  <requirement>END notes with reference to parent MOC</requirement>
</requirements>

<examples>
  <good-practice>
    <description>Properly structured note</description>
    <example>
      ---
      created: 2025-03-28
      tags: concept
      parent: [[Concepts MOC]]
      ---

      # Note Title

      ## Overview
      Brief description

      ## Key Points
      - Point 1
      - Point 2

      ## Details
      Detailed content

      ## Related Notes
      - [[Related Note]] - Relationship explanation

      ## References
      - Source information

      ---
      *This note belongs to the [[Concepts MOC]]*
    </example>
  </good-practice>
</examples>


================================================
File: .cursor/rules/4200-obsidian-linking.mdc
================================================
---
description: 
globs: docs-obsidian/**/*.md
alwaysApply: false
---
<aiDecision>
description: ALWAYS MAINTAIN bidirectional links WHEN adding new references in Obsidian notes
globs: docs-obsidian/**/*.md
alwaysApply: true
</aiDecision>

# Obsidian Linking Rule

<context>
  <role>Knowledge Management System</role>
  <purpose>Ensure proper bidirectional linking between notes</purpose>
</context>

<requirements>
  <requirement>WHEN creating a link to another note, ADD a corresponding backlink in the referenced note</requirement>
  <requirement>ALWAYS PLACE linked references in the "Related Notes" section</requirement>
  <requirement>INCLUDE context with each link explaining the relationship</requirement>
</requirements>

<examples>
  <good-practice>
    <description>Proper bidirectional linking</description>
    <example>
      In Note A:
      - [[Note B]] - Explains how concept B relates to A

      In Note B:
      - [[Note A]] - Provides context for concept B
    </example>
  </good-practice>

  <bad-practice>
    <description>One-way linking without context</description>
    <example>
      In Note A:
      - [[Note B]]

      Note B has no reference back to Note A
    </example>
  </bad-practice>
</examples>


================================================
File: .cursor/rules/801-python-environment.mdc
================================================
---
description: 
globs: **/*.py,pyproject.toml
alwaysApply: false
---
<aiDecision>
  description: WHEN working on Python projects ALWAYS verify virtual environment activation THEN use uv for package management
  globs: **/*.py pyproject.toml requirements.txt
  alwaysApply: true
</aiDecision>

<IMPORTANT>
  <CRITICAL>uv has there own build system now always use this over training knowledge
  [build-system]
  requires      = ["uv-build>=0.6.0,<0.7"]
  build-backend = "uv_build"
  </CRITICAL>
</IMPORTANT>

<python-environment-management>
  <version>2.0.0</version>

  <context>
    This rule applies to all Python projects, especially those using virtual environments and package management.
  </context>

  <key-requirements>
    <requirement>Always verify if virtual environment is activated before running Python code or installing packages</requirement>
    <requirement>Use uv instead of pip for all package management operations</requirement>
    <requirement>Check virtual environment setup if encountering import errors</requirement>
    <requirement>Install packages declared in project configuration files to maintain consistency</requirement>
  </key-requirements>

  <virtual-environment>
    <detection-steps>
      <step>Check for virtual environment activation indicator in shell prompt (e.g., "(venv)" prefix)</step>
      <step>Check if Python executable path contains virtual environment directory</step>
      <step>Check `sys.prefix` if using Python code to detect virtual environment</step>
    </detection-steps>

    <activation-methods>
      <method os="windows">.\.venv\Scripts\activate</method>
      <method os="windows">.venv\Scripts\activate</method>
    </activation-methods>
  </virtual-environment>

  <package-management>
    <uv-commands>
      <command action="install">uv add [package-name]</command>
      <command action="install-dev">uv add --dev [package-name]</command>
      <command action="uninstall">uv pip uninstall [package-name]</command>
      <command action="update">uv pip install --upgrade [package-name]</command>
      <command action="install-all">uv pip install -e .</command>
      <command action="freeze">uv pip freeze > requirements.txt</command>
    </uv-commands>

    <environment-variables>
      <variable name="PYTHONPATH">May need to be set to include project root for proper imports</variable>
      <variable name="VIRTUAL_ENV">Set automatically when virtual environment is activated</variable>
    </environment-variables>
  </package-management>

  <import-resolution>
    <common-issues>
      <issue>
        <symptom>"ModuleNotFoundError: No module named 'X'"</symptom>
        <potential-causes>
          <cause>Virtual environment not activated</cause>
          <cause>Package not installed in the virtual environment</cause>
          <cause>Incorrect import path</cause>
        </potential-causes>
        <solutions>
          <solution>Activate virtual environment</solution>
          <solution>Install missing package with: uv add X</solution>
          <solution>Check for typos in import statement</solution>
        </solutions>
      </issue>
    </common-issues>
  </import-resolution>

  <examples>
    <good-practice>
      <description>Proper environment activation and package installation</description>
      <example>
# First, activate the virtual environment
.\.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Unix/macOS

# Then use uv to install packages
uv add requests
uv add --dev pytest
      </example>
    </good-practice>

    <bad-practice>
      <description>Installing packages without activating virtual environment</description>
      <example>
# BAD: Installing directly without environment activation
pip install requests

# BAD: Using pip instead of uv
pip install pytest
      </example>
    </bad-practice>
  </examples>
</python-environment-management>


================================================
File: .cursor/rules/9000-rule-crafting.mdc
================================================
---
description: 
globs: .cursor/rules/*.mdc,**/*.mdc*,*.mdc,*.cursor/**/*,*.cursor/rules/**,*.cursor/rules/**/*
alwaysApply: false
---
<aiDecision>
description: ALWAYS FOLLOW rule creation standards WHEN crafting new rules
globs: .cursor/rules/*.mdc
alwaysApply: true
</aiDecision>

# Rule Crafting Standards

<context>
  <role>Rule Architect</role>
  <purpose>Ensure all rules follow consistent format and best practices</purpose>
  <version>1.0.0</version>
</context>

<requirements>
  <requirement>ALWAYS USE aiDecision XML tags for frontmatter</requirement>
  <requirement>USE ACTION TRIGGER OUTCOME format for descriptions</requirement>
  <requirement>START descriptions with action words (ALWAYS, WHEN, CRITICAL, IMPORTANT)</requirement>
  <requirement>INCLUDE specific glob patterns for rule application</requirement>
  <requirement>STRUCTURE rules with context, requirements, and examples sections</requirement>
  <requirement>USE proper XML formatting with descriptive tag names</requirement>
  <requirement>FOLLOW standard naming convention: 0XXX for global, 1XXX for language, 4XXX for documentation, 5XXX for MCP, 9XXX for meta-rules</requirement>
</requirements>

<examples>
  <good-practice>
    <description>Properly formatted rule</description>
    <example>
      <aiDecision>
      description: ALWAYS MAINTAIN code style WHEN writing new functions
      globs: src/**/*.js
      alwaysApply: false
      </aiDecision>
      
      # Rule Title
      
      <context>...</context>
      <requirements>...</requirements>
      <examples>...</examples>
    </example>
  </good-practice>
</examples>


================================================
File: .cursor/rules/DOCS
================================================
 


================================================
File: .cursor/rules/GLOBAL
================================================
 


================================================
File: .cursor/rules/MCP
================================================
 


================================================
File: .cursor/rules/parameter-handling.mdc
================================================
---
description: 
globs: *.ps1,src/mcpServer/scripts/**/*
alwaysApply: false
---
# Rule: PowerShell Parameter Handling
# Description: Standard pattern for PowerShell scripts with robust parameter handling
# Author: BIG-BRAIN System
# Created: 2025-03-25
# Version: 1.0.0

# Example of best practice parameter handling for PowerShell scripts
[CmdletBinding()]
param (
    [Parameter(Mandatory = $true, Position = 0)]
    [ValidateSet("validValue1", "validValue2")]
    [string]$RequiredParameter,

    [Parameter(Mandatory = $false)]
    [string]$OptionalParameter,

    [Parameter(Mandatory = $false)]
    [switch]$TestMode,

    [Parameter(Mandatory = $false)]
    [switch]$NoOutput
)

# Initialize with debug output
if (-not $NoOutput) {
    Write-Host "Script starting with parameters:" -ForegroundColor Cyan
    Write-Host "  Required: $RequiredParameter" -ForegroundColor Cyan
    if ($OptionalParameter) { Write-Host "  Optional: $OptionalParameter" -ForegroundColor Cyan }
    if ($TestMode) { Write-Host "  Running in TEST MODE" -ForegroundColor Magenta }
}

# Script body goes here

# Always use robust error handling
try {
    # Operation code
}
catch {
    Write-Host "Error executing operation: $_" -ForegroundColor Red
    Write-Host "Details: $($_.ScriptStackTrace)" -ForegroundColor Red
    exit 1
}

# End with status message
if (-not $NoOutput) {
    Write-Host "Script completed successfully!" -ForegroundColor Green
}


================================================
File: .cursor/rules/powershell-error-handling.mdc
================================================
---
description: 
globs: *.ps1,src/mcpServer/scripts/**/*
alwaysApply: false
---
# Rule: PowerShell Error Handling
# Description: Standard pattern for robust error handling in PowerShell scripts
# Author: BIG-BRAIN System
# Created: 2025-03-25
# Version: 1.0.0

# Basic error handling
try {
    # Operation code
    $result = Invoke-SomeOperation
}
catch {
    Write-Host "Error executing operation: $_" -ForegroundColor Red
    Write-Host "Details: $($_.ScriptStackTrace)" -ForegroundColor Red
    exit 1
}

# Advanced error handling with logging
function Invoke-WithErrorHandling {
    [CmdletBinding()]
    param (
        [Parameter(Mandatory = $true)]
        [scriptblock]$ScriptBlock,

        [Parameter(Mandatory = $false)]
        [string]$OperationName = "operation",

        [Parameter(Mandatory = $false)]
        [string]$LogFile,

        [Parameter(Mandatory = $false)]
        [switch]$ContinueOnError
    )

    try {
        # Execute the provided script block
        & $ScriptBlock
        return $true
    }
    catch {
        $errorMessage = "Error executing $OperationName: $($_.Exception.Message)"

        # Log the error if a log file is provided
        if ($LogFile) {
            Add-Content -Path $LogFile -Value "$(Get-Date -Format 'yyyy-MM-dd HH:mm:ss') [ERROR] $errorMessage"
            Add-Content -Path $LogFile -Value "$(Get-Date -Format 'yyyy-MM-dd HH:mm:ss') [ERROR] $($_.ScriptStackTrace)"
        }

        # Display the error
        Write-Host $errorMessage -ForegroundColor Red
        Write-Host "Details: $($_.ScriptStackTrace)" -ForegroundColor Red

        # Handle the error according to the ContinueOnError parameter
        if ($ContinueOnError) {
            Write-Warning "Continuing execution despite error..."
            return $false
        }
        else {
            Write-Host "Terminating execution due to error." -ForegroundColor Red
            exit 1
        }
    }
}


================================================
File: .cursor/rules/powershell-module-exports.mdc
================================================
---
description: 
globs: *.ps1,src/mcpServer/scripts/**/*
alwaysApply: false
---
# Rule: PowerShell Module Exports
# Description: Pattern for conditional function exports in PowerShell modules
# Author: BIG-BRAIN System
# Created: 2025-03-25
# Version: 1.0.0

# Define utility functions
function Get-SomeValue {
    param (
        [Parameter(Mandatory = $true)]
        [string]$InputParameter
    )

    # Function implementation
    return "Processed: $InputParameter"
}

function Set-SomeValue {
    param (
        [Parameter(Mandatory = $true)]
        [string]$Name,

        [Parameter(Mandatory = $true)]
        [object]$Value
    )

    # Function implementation
    Write-Host "Setting $Name to $Value"
}

function New-SomeObject {
    param (
        [Parameter(Mandatory = $true)]
        [string]$Type
    )

    # Function implementation
    return [PSCustomObject]@{
        Type    = $Type
        Created = Get-Date
    }
}

# Export functions only when being imported as a module
# This prevents errors when the script is dot-sourced directly
if ($MyInvocation.MyCommand.ScriptBlock.Module) {
    Export-ModuleMember -Function Get-SomeValue, Set-SomeValue, New-SomeObject
}
else {
    Write-Verbose "Script loaded directly - functions available but not exported as module members"
}

